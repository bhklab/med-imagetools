{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Med-Imagetools: Transparent and Reproducible Medical Image Processing Pipelines in Python","text":""},{"location":"#med-imagetools-core-features","title":"Med-ImageTools core features","text":"<p>Med-Imagetools, a python package offers the perfect tool to transform messy medical dataset folders to deep learning ready format in few lines of code. It not only processes DICOMs consisting of different modalities (like CT, PET, RTDOSE and RTSTRUCTS), it also transforms them into deep learning ready subject based format taking the dependencies of these modalities into consideration.  </p>"},{"location":"#introduction","title":"Introduction","text":"<p>A medical dataset, typically contains multiple different types of scans for a single patient in a single study. As seen in the figure below, the different scans containing DICOM of different modalities are interdependent on each other. For making effective machine learning models, one ought to take different modalities into account.</p> <p></p> <p>Fig.1 - Different network topology for different studies of different patients</p> <p>Med-Imagetools is a unique tool, which focuses on subject based Machine learning. It crawls the dataset and makes a network by connecting different modalities present in the dataset. Based on the user defined modalities, med-imagetools, queries the graph and process the queried raw DICOMS. The processed DICOMS are saved as nrrds, which med-imagetools converts to torchio subject dataset and eventually torch dataloader for ML pipeline.</p>"},{"location":"#installing-med-imagetools","title":"Installing med-imagetools","text":"<pre><code>pip install med-imagetools\n</code></pre>"},{"location":"#repository-stars","title":"Repository Stars","text":""},{"location":"#license","title":"License","text":"<p>This project uses the following license: MIT License</p>"},{"location":"database_report/","title":"Database Report","text":""},{"location":"database_report/#number-of-patients-100","title":"Number of Patients: 100","text":""},{"location":"database_report/#number-of-studies-315","title":"Number of Studies: 315","text":""},{"location":"database_report/#number-of-series-3123","title":"Number of Series: 3123","text":""},{"location":"database_report/#modality-summary","title":"Modality Summary","text":"Modality Count MR 152 SEG 68 CT 138 OT 1 PT 10 RTSTRUCT 16 RTDOSE 16 RTPLAN 13 DX 8 SR 10 MG 5 NM 1 CR 11"},{"location":"database_report/#data-summary","title":"Data Summary","text":"Patient ID Number of Studies Number of Series Unique Modalities TCGA-06-0184 12 183 {'SEG', 'MR'} TCGA-06-0185 16 176 {'SEG', 'MR'} TCGA-BB-A5HY 11 121 {'CT', 'OT', 'MR'} TCGA-06-0188 9 110 {'SEG', 'MR'} TCGA-CV-7090 15 93 {'PT', 'CT', 'MR'} TCGA-06-0138 6 90 {'SEG', 'MR'} TCGA-06-1084 6 77 {'SEG', 'MR'} TCGA-06-0139 5 76 {'SEG', 'MR'} TCGA-CV-7243 15 72 {'RTDOSE', 'CT', 'RTSTRUCT'} TCGA-CV-A6K0 13 71 {'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-A6JY 14 68 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-DD-A4NG 8 58 {'PT', 'CT', 'MR'} TCGA-06-0238 3 54 {'SEG', 'MR'} TCGA-06-1802 3 51 {'SEG', 'MR'} TCGA-D1-A16D 9 43 {'PT', 'CT', 'MR'} TCGA-06-0164 3 36 {'SEG', 'MR'} TCGA-06-0137 2 34 {'SEG', 'MR'} TCGA-14-1794 4 34 {'CT', 'SEG', 'MR'} TCGA-06-0130 2 33 {'SEG', 'MR'} TCGA-CS-6186 2 33 {'CT', 'SEG', 'MR'} TCGA-CV-A6JO 8 32 {'RTPLAN', 'CT', 'RTDOSE', 'PT', 'RTSTRUCT'} TCGA-06-0154 1 32 {'SEG', 'MR'} TCGA-02-0075 1 31 {'SEG', 'MR'} TCGA-06-0190 2 31 {'SEG', 'MR'} TCGA-02-0087 1 30 {'SEG', 'MR'} TCGA-CV-A6K1 7 28 {'RTDOSE', 'CT', 'RTSTRUCT', 'RTPLAN'} TCGA-G2-A3IE 6 28 {'CT', 'DX', 'MR'} TCGA-AO-A0JB 3 26 {'SR', 'MG', 'MR'} TCGA-02-0064 1 25 {'SEG', 'MR'} TCGA-02-0059 1 25 {'SEG', 'MR'} TCGA-02-0034 1 25 {'SEG', 'MR'} TCGA-06-0122 1 25 {'SEG', 'MR'} TCGA-06-0644 1 25 {'SEG', 'MR'} TCGA-06-0646 1 25 {'SEG', 'MR'} TCGA-06-5413 1 25 {'SEG', 'MR'} TCGA-06-0192 2 25 {'SEG', 'MR'} TCGA-06-0179 1 25 {'SEG', 'MR'} TCGA-08-0359 1 25 {'SEG', 'MR'} TCGA-06-5417 1 25 {'SEG', 'MR'} TCGA-02-0069 1 24 {'SEG', 'MR'} TCGA-06-0119 1 24 {'SEG', 'MR'} TCGA-CV-A6K2 5 24 {'RTPLAN', 'CT', 'RTSTRUCT', 'RTDOSE'} TCGA-08-0389 1 24 {'SEG', 'MR'} TCGA-06-0149 1 24 {'SEG', 'MR'} TCGA-CR-7368 4 24 {'PT', 'CT', 'MR'} TCGA-06-0158 2 24 {'SEG', 'MR'} TCGA-02-0086 1 24 {'SEG', 'MR'} TCGA-08-0355 1 24 {'SEG', 'MR'} TCGA-06-2570 1 23 {'SEG', 'MR'} TCGA-02-0027 1 22 {'SEG', 'MR'} TCGA-B9-A44B 2 22 {'PT', 'CT', 'MR'} TCGA-06-6389 1 22 {'SEG', 'MR'} TCGA-50-5072 4 22 {'PT', 'CT', 'NM'} TCGA-08-0385 2 22 {'SEG', 'MR'} TCGA-06-0142 1 22 {'SEG', 'MR'} TCGA-02-0068 1 22 {'SEG', 'MR'} TCGA-06-0240 1 22 {'SEG', 'MR'} TCGA-08-0360 1 21 {'SEG', 'MR'} TCGA-06-0182 1 21 {'SEG', 'MR'} TCGA-G2-A2EK 11 21 {'CR', 'CT', 'DX'} TCGA-06-0187 1 21 {'SEG', 'MR'} TCGA-08-0392 1 21 {'SEG', 'MR'} TCGA-06-5408 1 21 {'SEG', 'MR'} TCGA-08-0390 1 20 {'SEG', 'MR'} TCGA-02-0070 1 20 {'SEG', 'MR'} TCGA-02-0054 1 19 {'SEG', 'MR'} TCGA-08-0356 1 19 {'SEG', 'MR'} TCGA-G2-A2EL 5 19 {'CR', 'CT', 'DX'} TCGA-AO-A0JF 5 19 {'SR', 'MG', 'MR'} TCGA-06-0177 1 19 {'SEG', 'MR'} TCGA-02-0011 1 18 {'SEG', 'MR'} TCGA-02-0033 1 18 {'SEG', 'MR'} TCGA-02-0047 1 18 {'SEG', 'MR'} TCGA-02-0037 1 18 {'SEG', 'MR'} TCGA-06-0162 1 18 {'SEG', 'MR'} TCGA-02-0106 1 18 {'SEG', 'MR'} TCGA-06-0145 1 18 {'SEG', 'MR'} TCGA-06-0176 1 17 {'SEG', 'MR'} TCGA-G2-AA3D 5 17 {'CR', 'CT', 'DX'} TCGA-G2-A2EO 7 17 {'CR', 'CT', 'DX'} TCGA-AO-A0JI 2 17 {'SR', 'MG', 'MR'} TCGA-02-0116 1 17 {'SEG', 'MR'} TCGA-02-0009 1 16 {'SEG', 'MR'} TCGA-02-0006 1 16 {'SEG', 'MR'} TCGA-02-0046 1 16 {'SEG', 'MR'} TCGA-G7-A8LD 3 16 {'PT', 'CT', 'MR'} TCGA-02-0102 1 16 {'SEG', 'MR'} TCGA-02-0085 1 16 {'SEG', 'MR'} TCGA-CR-6478 2 14 {'PT', 'CT', 'MR'} TCGA-CV-5973 2 13 {'RTPLAN', 'CT', 'RTSTRUCT', 'RTDOSE'} TCGA-CV-5977 2 13 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-7235 2 10 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-5976 2 10 {'RTDOSE', 'CT', 'RTSTRUCT', 'RTPLAN'} TCGA-CV-6433 2 9 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-08-0509 1 8 {'SEG', 'MR'} TCGA-CV-5966 2 8 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-5978 2 8 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-5970 2 7 {'RTPLAN', 'CT', 'RTSTRUCT', 'RTDOSE'} TCGA-CV-7236 2 7 {'RTDOSE', 'CT', 'RTSTRUCT'} TCGA-CV-7245 2 7 {'RTPLAN', 'CT', 'RTSTRUCT', 'RTDOSE'}"},{"location":"cli/imgtools/","title":"<code>imgtools</code> CLI","text":""},{"location":"cli/imgtools/#imgtools","title":"imgtools","text":"<p>A collection of tools for working with medical imaging data.</p> <p>Usage:</p> <pre><code>imgtools [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--quiet</code>, <code>-q</code> boolean Suppress all logging except errors, overrides verbosity options. <code>False</code> <code>--verbose</code>, <code>-v</code> integer range (<code>0</code> and above) Increase verbosity of logging, overrides environment variable. (0-3: ERROR, WARNING, INFO, DEBUG). <code>0</code> <code>--version</code> boolean Show the version and exit. <code>False</code> <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>autopipeline: </li> <li>dicomfind: A tool to find DICOM files.</li> <li>dicomsort: Sorts DICOM files into directories based on their tags.</li> <li>index: Crawl DICOM directory and create a database index.</li> </ul>"},{"location":"cli/imgtools/#imgtools-autopipeline","title":"imgtools autopipeline","text":"<p>Run the Autopipeline for processing medical images.</p> <p>This command allows you to process medical images in a directory structure, apply transformations, and save the results to a specified output directory.</p> <p>INPUT_DIRECTORY: Directory containing the input images. OUTPUT_DIRECTORY: Directory to save the processed images.</p> <p>The default filename format is: {SampleNumber}__{PatientID}/{Modality}_{SeriesInstanceUID}/{ImageID}.nii.gz where:     - SampleNumber: The identifier for the sample after querying.     - PatientID: The ID of the patient.     - Modality: The imaging modality (e.g., CT, MRI).     - SeriesInstanceUID: The unique identifier for the series.     - ImageID: The cutomized identifier for the image.         - By default, the modality of the image         - If RTSTRUCT or SEG, uses custom format based on the roi_strategy             roi_match_map and roi names.         TODO:: explain this in the docs?</p> <p>It is not recommended to change the default filename format to prevent overwriting files. The default format is designed to ensure that the output filenames are unique and informative. If you need to customize the output make sure to use a format that maintains uniqueness and clarity.</p> <p>Usage:</p> <pre><code>imgtools autopipeline [OPTIONS] INPUT_DIRECTORY OUTPUT_DIRECTORY\n</code></pre> <p>Options:</p> Name Type Description Default <code>--filename-format</code>, <code>-f</code> text Format string for output filenames with placeholders for metadata values <code>{SampleNumber}__{PatientID}/{Modality}_{SeriesInstanceUID}/{ImageID}.nii.gz</code> <code>--modalities</code>, <code>-m</code> text List of modalities to process, in hierarchical order. For example, '--modalities CT,PT,RTSTRUCT' or '--modalities MR,SEG' _required <code>--existing-file-mode</code> choice (<code>overwrite</code> | <code>skip</code> | <code>fail</code>) How to handle existing files <code>fail</code> <code>--update-crawl</code> boolean Force recrawling of the input directory <code>False</code> <code>--jobs</code>, <code>-j</code> integer Number of parallel jobs None <code>--spacing</code> text Resampling spacing as comma-separated values i.e '--spacing 1.0,1.0,1.0' <code>0.0,0.0,0.0</code> <code>--window-width</code> float Width of the window for intensity windowing None <code>--window-level</code> float Midpoint of the window for intensity windowing None <code>--roi-ignore-case</code> / <code>--roi-case-sensitive</code> boolean Perform case\u2011insensitive ROI matching (default: enabled) <code>True</code> <code>--roi-strategy</code> choice (<code>MERGE</code> | <code>KEEP_FIRST</code> | <code>SEPARATE</code>) Strategy for handling ROI matches <code>SEPARATE</code> <code>--roi-allow-multi-matches</code> / <code>--roi-disallow-multi-matches</code> boolean Allow one ROI to match multiple keys in the match map <code>True</code> <code>--roi-on-missing-regex</code> choice (<code>IGNORE</code> | <code>WARN</code> | <code>ERROR</code>) How to handle when no ROI matches any pattern <code>WARN</code> <code>--roi-match-map</code>, <code>-rmap</code> text ROI matching patterns in format 'key:pattern1,pattern2,...'. Can be used multiple times to specify multiple roi mappings. CLI arguments take precedence over entries in the YAML file, if common keys exist. None <code>--roi-match-yaml</code>, <code>-ryaml</code> file Path to YAML file containing ROI matching patterns. None <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/imgtools/#imgtools-dicomfind","title":"imgtools dicomfind","text":"<p>A tool to find DICOM files.</p> <p>PATH is the directory to search for DICOM files.</p> <p>SEARCH_INPUT is an optional list of substring(s) to search for in the DICOM files. If multiple substrings are provided, all substrings must match to return a result.</p> <p>i.e dicomfind /path/to/directory/ \"substring1\" \"substring2\" \"substring3\"</p> <p>Usage:</p> <pre><code>imgtools dicomfind [OPTIONS] PATH [SEARCH_INPUT]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>-e</code>, <code>--extension</code> text File extension to look for. <code>dcm</code> <code>-c</code>, <code>--count</code> boolean Whether to just print the count of files found. This is useful for scripts. <code>False</code> <code>-l</code>, <code>--limit</code> integer The limit of results to return. None <code>-ch</code>, <code>--check-header</code> boolean Whether to check DICOM header for \"DICM\" signature. <code>False</code> <code>-s</code>, <code>--sorted</code> boolean Sort the results alphabetically. <code>False</code> <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/imgtools/#imgtools-dicomsort","title":"imgtools dicomsort","text":"<p>Sorts DICOM files into directories based on their tags.</p> <p>Usage:</p> <pre><code>imgtools dicomsort [OPTIONS] SOURCE_DIRECTORY TARGET_DIRECTORY\n</code></pre> <p>Options:</p> Name Type Description Default <code>--action</code>, <code>-a</code> choice (<code>move</code> | <code>copy</code> | <code>symlink</code> | <code>hardlink</code>) Action to perform on the files. _required <code>-n</code>, <code>--dry-run</code> boolean Do not move or copy files, just print what would be done. Always recommended to use this first to confirm the operation! <code>False</code> <code>-j</code>, <code>--num-workers</code> integer Number of worker processes to use for sorting. <code>1</code> <code>--truncate-uids</code>, <code>-t</code> integer Truncate the UIDs in the DICOM files to the specified length. Set to 0 to disable truncation. <code>5</code> <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/imgtools/#imgtools-index","title":"imgtools index","text":"<p>Crawl DICOM directory and create a database index.</p> <ul> <li> <p>looks for all DICOM files in the specified directory, extracts metadata,      and builds a comprehensive index of the dataset.</p> </li> <li> <p>The index includes information about the series, modalities, and other     relevant details, making it easier to manage and analyze the DICOM files.</p> </li> <li> <p>The output is saved in a structured format, including JSON and CSV files,     which can be used for further processing or analysis.</p> </li> <li> <p>By default, it saves the results in a \".imgtools\" folder right next to      your DICOM directory, but you can pick your own place to store them.</p> </li> </ul> <p>Usage:</p> <pre><code>imgtools index [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--dicom-dir</code> path Path to the DICOM directory. _required <code>--output-dir</code> path Path to the output directory. If not specified, a directory named '.imgtools' will be created in the parent directory of the DICOM directory. None <code>--dataset-name</code> text Name of the dataset. If not specified, the name of the DICOM directory will be used. None <code>--n-jobs</code> integer Number of jobs to use for parallel processing. <code>2</code> <code>--force</code> boolean Force overwrite existing files. <code>False</code> <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/shell-completion/","title":"Shell Completion","text":"<p>Shell completion is a feature that allows you to press the <code>Tab</code> key while typing a command to automatically complete command names, options, and arguments. This can significantly improve your productivity when working with the <code>imgtools</code> CLI.</p>"},{"location":"cli/shell-completion/#generating-completion-scripts","title":"Generating Completion Scripts","text":"<p>The <code>imgtools</code> CLI provides a built-in command to generate shell completion scripts for various shells:</p> <pre><code>imgtools shell-completion [SHELL]\n</code></pre> <p>Where <code>[SHELL]</code> is one of: <code>bash</code>, <code>zsh</code>, or <code>fish</code>.</p>"},{"location":"cli/shell-completion/#installation-instructions","title":"Installation Instructions","text":"BashZshFish <p>To enable completion for the current bash session:</p> <pre><code>source &lt;(imgtools shell-completion bash)\n</code></pre> <p>For permanent setup, add the completion script to a file in your bash completion directory:</p> <pre><code># Create the completions directory if it doesn't exist\nmkdir -p ~/.bash_completion.d\n\n# Save the completion script to a file\nimgtools shell-completion bash &gt; ~/.bash_completion.d/imgtools\n\n# Add the following to your ~/.bashrc file\necho 'source ~/.bash_completion.d/imgtools' &gt;&gt; ~/.bashrc\n\n# Reload your shell configuration\nsource ~/.bashrc\n</code></pre> <p>To enable completion for the current zsh session:</p> <pre><code>source &lt;(imgtools shell-completion zsh)\n</code></pre> <p>For permanent setup:</p> <pre><code># Create the completions directory if it doesn't exist\nmkdir -p ~/.zsh/completion\n\n# Save the completion script to a file\nimgtools shell-completion zsh &gt; ~/.zsh/completion/_imgtools\n\n# Add to your ~/.zshrc file\necho 'fpath=(~/.zsh/completion $fpath)' &gt;&gt; ~/.zshrc\necho 'autoload -U compinit &amp;&amp; compinit' &gt;&gt; ~/.zshrc\n\n# Reload your shell configuration\nsource ~/.zshrc\n</code></pre> <p>To enable completion for the current fish session:</p> <pre><code>imgtools shell-completion fish | source\n</code></pre> <p>For permanent setup:</p> <pre><code># Create the completions directory if it doesn't exist\nmkdir -p ~/.config/fish/completions\n\n# Save the completion script\nimgtools shell-completion fish &gt; ~/.config/fish/completions/imgtools.fish\n\n# Fish will automatically load the completions on next shell start\n</code></pre>"},{"location":"cli/shell-completion/#verifying-completion-works","title":"Verifying Completion Works","text":"<p>After setting up completion, you can verify it works by typing:</p> <pre><code>imgtools &lt;TAB&gt;\n</code></pre> <p>This should display available subcommands. You can also try:</p> <pre><code>imgtools dicomsort --&lt;TAB&gt;\n</code></pre> <p>This should show the <code>--</code>options available for the <code>dicomsort</code> command  (i.e <code>--action</code>, <code>--output</code>, etc.)</p>"},{"location":"cli/shell-completion/#troubleshooting","title":"Troubleshooting","text":"<p>If completions don't work after following these steps:</p> <ol> <li>Make sure you've reloaded your shell configuration or started a new terminal session</li> <li>Verify that the completion script was properly generated and saved</li> <li>Check if your shell supports tab completion (it should by default)</li> </ol>"},{"location":"reference/crawler/","title":"Crawler","text":""},{"location":"reference/crawler/#imgtools.dicom.crawl.crawler.Crawler","title":"Crawler  <code>dataclass</code>","text":"<pre><code>Crawler(\n    dicom_dir: pathlib.Path,\n    output_dir: pathlib.Path | None = None,\n    dataset_name: str | None = None,\n    n_jobs: int = 1,\n    force: bool = False,\n)\n</code></pre> <p>Crawl a DICOM directory and extract metadata.</p> <p>Methods:</p> Name Description <code>crawl</code> <p>Crawl the DICOM directory and extract metadata.</p> <code>get_folder</code> <p>Get the folder for a given series UID.</p> <code>get_modality</code> <p>Get the modality for a given series UID.</p>"},{"location":"reference/crawler/#imgtools.dicom.crawl.crawler.Crawler.crawl_db","title":"crawl_db  <code>property</code>","text":"<pre><code>crawl_db: list[dict[str, str]]\n</code></pre> <p>Return the crawl database.</p>"},{"location":"reference/crawler/#imgtools.dicom.crawl.crawler.Crawler.crawl_db_raw","title":"crawl_db_raw  <code>property</code>","text":"<pre><code>crawl_db_raw: (\n    imgtools.dicom.crawl.parse_dicoms.SeriesMetaMap\n)\n</code></pre> <p>Return the crawl database raw.</p>"},{"location":"reference/crawler/#imgtools.dicom.crawl.crawler.Crawler.crawl_results","title":"crawl_results  <code>property</code>","text":"<pre><code>crawl_results: (\n    imgtools.dicom.crawl.parse_dicoms.ParseDicomDirResult\n)\n</code></pre> <p>Get the crawl results, validating they're available first.</p>"},{"location":"reference/crawler/#imgtools.dicom.crawl.crawler.Crawler.index","title":"index  <code>property</code>","text":"<pre><code>index: pandas.DataFrame\n</code></pre> <p>Return the index of the crawl results.</p>"},{"location":"reference/crawler/#imgtools.dicom.crawl.crawler.Crawler.crawl","title":"crawl","text":"<pre><code>crawl() -&gt; None\n</code></pre> <p>Crawl the DICOM directory and extract metadata.</p> Source code in <code>src/imgtools/dicom/crawl/crawler.py</code> <pre><code>def crawl(self) -&gt; None:\n    \"\"\"Crawl the DICOM directory and extract metadata.\"\"\"\n    self.output_dir = (\n        self.output_dir or self.dicom_dir.parent / \".imgtools\"\n    )\n    self.output_dir.mkdir(parents=True, exist_ok=True)\n\n    logger.info(\n        \"Starting DICOM crawl.\",\n        dicom_dir=self.dicom_dir,\n        output_dir=self.output_dir,\n        dataset_name=self.dataset_name,\n    )\n\n    with tqdm_logging_redirect():\n        crawldb = parse_dicom_dir(\n            dicom_dir=self.dicom_dir,\n            output_dir=self.output_dir,\n            dataset_name=self.dataset_name,\n            n_jobs=self.n_jobs,\n            force=self.force,\n        )\n    self._crawl_results = crawldb\n</code></pre>"},{"location":"reference/crawler/#imgtools.dicom.crawl.crawler.Crawler.get_folder","title":"get_folder","text":"<pre><code>get_folder(series_uid: str) -&gt; str\n</code></pre> <p>Get the folder for a given series UID.</p> Source code in <code>src/imgtools/dicom/crawl/crawler.py</code> <pre><code>def get_folder(self, series_uid: str) -&gt; str:\n    \"\"\"Get the folder for a given series UID.\"\"\"\n    if series_uid not in self.crawl_results.crawl_db_raw:\n        msg = f\"Series UID {series_uid} not found in crawl results.\"\n        raise ValueError(msg)\n\n    data = self.crawl_results.crawl_db_raw[series_uid]\n    first_subseries = next(iter(data.values()))\n    return first_subseries[\"folder\"]\n</code></pre>"},{"location":"reference/crawler/#imgtools.dicom.crawl.crawler.Crawler.get_modality","title":"get_modality","text":"<pre><code>get_modality(series_uid: str) -&gt; str\n</code></pre> <p>Get the modality for a given series UID.</p> Source code in <code>src/imgtools/dicom/crawl/crawler.py</code> <pre><code>def get_modality(self, series_uid: str) -&gt; str:\n    \"\"\"Get the modality for a given series UID.\"\"\"\n    if series_uid not in self.crawl_results.crawl_db_raw:\n        msg = f\"Series UID {series_uid} not found in crawl results.\"\n        raise ValueError(msg)\n\n    data = self.crawl_results.crawl_db_raw[series_uid]\n    first_subseries = next(iter(data.values()))\n    return first_subseries[\"modality\"]\n</code></pre>"},{"location":"reference/dicom_metadata/","title":"DICOM Modality-Specific Metadata Extraction","text":""},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extract_metadata","title":"extract_metadata","text":"<pre><code>extract_metadata(\n    dicom: imgtools.dicom.DicomInput,\n    modality: str | None = None,\n    extra_tags: list[str] | None = None,\n) -&gt; dict[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedValue,\n]\n</code></pre> <p>Extract metadata from a DICOM file based on its modality.</p> <p>Parameters:</p> Name Type Description Default <code>imgtools.dicom.DicomInput</code> <p>DICOM input source (path, bytes, or pydicom Dataset)</p> required <code>str | None</code> <p>Explicitly specify the modality to use, by default None. If None, the modality is extracted from the DICOM file.</p> <code>None</code> <code>list[str] | None</code> <p>Additional DICOM tags to extract, by default None. If None, no extra tags are extracted.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]</code> <p>Dictionary of metadata fields with their values extracted from the DICOM.</p> Notes <p>Be aware that using extra_tags may lead to unexpected results if the extra tags are not compatible with the modality or if they are not present in the DICOM file. The extractor will not validate the extra tags against the modality, so it's the user's responsibility to ensure that the extra tags are relevant and valid for the given DICOM file.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/__init__.py</code> <pre><code>def extract_metadata(\n    dicom: DicomInput,\n    modality: str | None = None,\n    extra_tags: list[str] | None = None,\n) -&gt; dict[str, ComputedValue]:\n    \"\"\"\n    Extract metadata from a DICOM file based on its modality.\n\n    Parameters\n    ----------\n    dicom : DicomInput\n        DICOM input source (path, bytes, or pydicom Dataset)\n    modality : str | None, optional\n        Explicitly specify the modality to use, by default None.\n        If None, the modality is extracted from the DICOM file.\n    extra_tags : list[str] | None, optional\n        Additional DICOM tags to extract, by default None.\n        If None, no extra tags are extracted.\n\n    Returns\n    -------\n    dict[str, ComputedValue]\n        Dictionary of metadata fields with their values extracted from the DICOM.\n\n    Raises\n    ------\n    ValueError\n        If no modality can be determined.\n\n    Notes\n    -----\n    Be aware that using extra_tags may lead to unexpected results if the\n    extra tags are not compatible with the modality or if they are not\n    present in the DICOM file. The extractor will not validate the extra tags\n    against the modality, so it's the user's responsibility to ensure that\n    the extra tags are relevant and valid for the given DICOM file.\n    \"\"\"\n    ds = load_dicom(dicom)\n    modality = modality or ds.get(\"Modality\")\n    if not modality:\n        raise ValueError(\"No modality found in DICOM\")\n\n    extractor_cls = get_extractor(modality)\n    return extractor_cls.extract(ds, extra_tags=extra_tags)\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extract_metadata(dicom)","title":"<code>dicom</code>","text":""},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extract_metadata(modality)","title":"<code>modality</code>","text":""},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extract_metadata(extra_tags)","title":"<code>extra_tags</code>","text":""},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor","title":"ModalityMetadataExtractor","text":"<p>               Bases: <code>abc.ABC</code></p> <p>Abstract base class for modality-specific DICOM metadata extractors.</p> <p>This class supports both standard DICOM tag retrieval and more complex field computations based on the full DICOM dataset. Subclasses must specify the modality they support and define additional metadata fields either as DICOM tag names or as custom computation functions.</p> <p>Attributes:</p> Name Type Description <code>base_tags</code> <code>typing.ClassVar[set[str]]</code> <p>Standard DICOM tags to always extract, regardless of modality.</p> <code>modality_tags</code> <code>typing.ClassVar[set[str]]</code> <p>Tags specific to the subclass's modality. These are merged with <code>base_tags</code> to form the list of tags to retrieve directly from the dataset.</p> <code>computed_fields</code> <code>typing.ClassVar[collections.abc.Mapping[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedField]]</code> <p>A mapping of metadata field names to callables that compute values from the loaded <code>pydicom.Dataset</code>.</p> <p>Methods:</p> Name Description <code>metadata_keys</code> <p>Returns a predictable, sorted list of all metadata field names produced by this extractor.</p> <code>extract</code> <p>Extracts metadata tags and computed fields from a DICOM dataset. Returns a dictionary mapping metadata field names to values.</p> Notes <p>Subclasses MUST implement the following abstract methods/properties: - <code>modality() -&gt; str</code>: A class method that returns the DICOM modality string handled   (e.g., \"CT\", \"MR\", \"RTDOSE\"). - <code>modality_tags -&gt; set[str]</code>: A class property that defines the set of DICOM attribute   names (tags) specific to the modality. - <code>computed_fields -&gt; Mapping[str, Callable[[pydicom.Dataset], ComputedValue]]</code>: A class property   that defines a mapping of metadata field names to callables which compute their values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class CTExtractor(ModalityMetadataExtractor):\n&gt;&gt;&gt;     @classmethod\n&gt;&gt;&gt;     def modality(cls) -&gt; str:\n&gt;&gt;&gt;         return \"CT\"\n&gt;&gt;&gt;     @classproperty\n&gt;&gt;&gt;     def modality_tags(cls) -&gt; set[str]:\n&gt;&gt;&gt;         return {\"KVP\", \"ReconstructionAlgorithm\"}\n&gt;&gt;&gt;     @classproperty\n&gt;&gt;&gt;     def computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n&gt;&gt;&gt;         return {\n&gt;&gt;&gt;             \"CustomValue\": lambda ds: str(float(ds.SliceThickness) * 2),\n&gt;&gt;&gt;             \"DoublePatientAge\": lambda ds: str(ds.PatientAge * 2)\n&gt;&gt;&gt;         }\n</code></pre> <pre><code>&gt;&gt;&gt; # Using the extractor\n&gt;&gt;&gt; metadata = CTExtractor.extract(\"file.dcm\")\n&gt;&gt;&gt; # Returns: {'PatientID': '123', 'KVP': '120', 'CustomValue': '5.0', ...}\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor.computed_fields","title":"computed_fields  <code>abstractmethod</code>","text":"<pre><code>computed_fields() -&gt; collections.abc.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, typing.Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractor_base.py</code> <pre><code>@classproperty\n@abstractmethod\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:  # noqa: N805\n    \"\"\"\n    A mapping of metadata field names to callables that compute their values.\n\n    The callable should accept a pydicom Dataset and return a value.\n\n    Returns\n    -------\n    dict[str, Callable[[pydicom.Dataset], ComputedValue]]\n        Mapping of field names to computation functions.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor.extract","title":"extract  <code>classmethod</code>","text":"<pre><code>extract(\n    dicom: imgtools.dicom.DicomInput,\n    extra_tags: list[str] | None = None,\n) -&gt; (\n    imgtools.dicom.dicom_metadata.extractor_base.ExtractedFields\n)\n</code></pre> <p>Extract metadata tags and computed fields from a DICOM dataset.</p> <p>Parameters:</p> Name Type Description Default <code>imgtools.dicom.DicomInput</code> <p>A path, byte stream, or pydicom FileDataset.</p> required <code>list[str] | None</code> <p>Additional DICOM tags to extract, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]</code> <p>A dictionary mapping metadata field names to values. Values may be strings, numbers, dictionaries, or lists of these types. Missing tags or errors during computation will result in an empty string.</p> Notes <p>Be aware that using extra_tags may lead to unexpected results if the extra tags are not compatible with the modality or if they are not present in the DICOM file. The extractor will not validate the extra tags against the modality, so it's the user's responsibility to ensure that the extra tags are relevant and valid for the given DICOM file.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractor_base.py</code> <pre><code>@classmethod\ndef extract(\n    cls, dicom: DicomInput, extra_tags: list[str] | None = None\n) -&gt; ExtractedFields:\n    \"\"\"\n    Extract metadata tags and computed fields from a DICOM dataset.\n\n    Parameters\n    ----------\n    dicom : DicomInput\n        A path, byte stream, or pydicom FileDataset.\n    extra_tags : list[str] | None, optional\n        Additional DICOM tags to extract, by default None\n\n    Returns\n    -------\n    dict[str, ComputedValue]\n        A dictionary mapping metadata field names to values.\n        Values may be strings, numbers, dictionaries, or lists of these types.\n        Missing tags or errors during computation will result in an empty string.\n\n    Notes\n    -----\n    Be aware that using extra_tags may lead to unexpected results if the\n    extra tags are not compatible with the modality or if they are not\n    present in the DICOM file. The extractor will not validate the extra tags\n    against the modality, so it's the user's responsibility to ensure that\n    the extra tags are relevant and valid for the given DICOM file.\n    \"\"\"\n    ds = load_dicom(dicom)\n    output: ExtractedFields = {}\n\n    # Extract base and modality-specific tags\n    tags_to_extract = cls.base_tags.union(cls.modality_tags)\n    if extra_tags:\n        tags_to_extract = tags_to_extract.union(extra_tags)\n\n    for tag in tags_to_extract:\n        output[tag] = str(ds.get(tag, \"\"))\n\n    # Compute advanced fields\n    for key, fn in cls.computed_fields.items():\n        try:\n            # Store computed value directly without conversion to string\n            output[key] = fn(ds)\n        except Exception as e:\n            warnmsg = (\n                f\"Failed to compute field '{key}' for modality '{cls.modality()}'. \"\n                \"This may be due to missing or malformed data in the DICOM file.\"\n            )\n            warnmsg += f\" Error: {e}\"\n            logger.warning(warnmsg, file=str(dicom))\n            output[key] = \"\"\n\n    # sort all keys\n    return {k: output[k] for k in sorted(output.keys())}\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor.extract(dicom)","title":"<code>dicom</code>","text":""},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor.extract(extra_tags)","title":"<code>extra_tags</code>","text":""},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor.metadata_keys","title":"metadata_keys  <code>classmethod</code>","text":"<pre><code>metadata_keys() -&gt; list[str]\n</code></pre> <p>Return a predictable, sorted list of metadata field names.</p> <p>This includes both direct DICOM tag names and any computed metadata keys.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>All metadata keys produced by this extractor.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractor_base.py</code> <pre><code>@classmethod\ndef metadata_keys(cls) -&gt; list[str]:\n    \"\"\"\n    Return a predictable, sorted list of metadata field names.\n\n    This includes both direct DICOM tag names and any computed metadata keys.\n\n    Returns\n    -------\n    list[str]\n        All metadata keys produced by this extractor.\n    \"\"\"\n    # if no modality_tags or computed_fields are defined, return base_tags\n    if not cls.modality_tags and not cls.computed_fields:\n        return sorted(cls.base_tags)\n\n    all_tags = cls.base_tags.union(cls.modality_tags)\n    all_keys = all_tags.union(cls.computed_fields.keys())\n    return sorted(all_keys)\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor.modality","title":"modality  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>modality() -&gt; str\n</code></pre> <p>The DICOM modality handled by this extractor (e.g., \"CT\", \"MR\").</p> <p>Returns:</p> Type Description <code>str</code> <p>Modality name.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractor_base.py</code> <pre><code>@classmethod\n@abstractmethod\ndef modality(cls) -&gt; str:\n    \"\"\"\n    The DICOM modality handled by this extractor (e.g., \"CT\", \"MR\").\n\n    Returns\n    -------\n    str\n        Modality name.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor.modality_tags","title":"modality_tags  <code>abstractmethod</code>","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractor_base.py</code> <pre><code>@classproperty\n@abstractmethod\ndef modality_tags(cls) -&gt; set[str]:  # noqa: N805\n    \"\"\"\n    A set of DICOM tags specific to the modality handled by this extractor.\n\n    Returns\n    -------\n    set[str]\n        Set of DICOM tag names.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.FallbackMetadataExtractor","title":"FallbackMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> <p>Generic fallback extractor for unsupported or uncommon DICOM modalities.</p> <p>This extractor uses only the base tags defined in the superclass and defines no modality-specific tags or computed fields. It allows graceful handling of modalities not yet explicitly supported.</p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.FallbackMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> <code>Returns an empty set since no modality-specific tags are defined.</code> <p>Returns:</p> Type Description <code>set[str]</code> <p>Empty set.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    \"\"\"\n    Returns an empty set since no modality-specific tags are defined.\n\n    Returns\n    -------\n    set[str]\n        Empty set.\n    \"\"\"\n    return set()\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.FallbackMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> <code>Returns an empty mapping since no computed fields are defined.</code> <p>Returns:</p> Type Description <code>typing.Mapping[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedField]</code> <p>Empty mapping.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    \"\"\"\n    Returns an empty mapping since no computed fields are defined.\n\n    Returns\n    -------\n    Mapping[str, ComputedField]\n        Empty mapping.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.CTMetadataExtractor","title":"CTMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> <p>Metadata extractor for CT modality DICOM datasets.</p> <p>This subclass defines modality-specific tags and computed fields relevant to CT (Computed Tomography) imaging. It extends the base metadata extractor with CT-specific acquisition and reconstruction parameters.</p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.CTMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> <code>CT-specific DICOM tag names.</code> <p>Returns:</p> Type Description <code>set[str]</code> <p>CT acquisition and reconstruction-related DICOM tags.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    \"\"\"\n    CT-specific DICOM tag names.\n\n    Returns\n    -------\n    set[str]\n        CT acquisition and reconstruction-related DICOM tags.\n    \"\"\"\n    return {\n        # Contrast &amp; Enhancement\n        \"ContrastFlowDuration\",\n        \"ContrastFlowRate\",\n        \"ContrastBolusAgent\",\n        \"ContrastBolusVolume\",\n        \"ContrastBolusStartTime\",\n        \"ContrastBolusStopTime\",\n        \"ContrastBolusIngredient\",\n        \"ContrastBolusIngredientConcentration\",\n        # X-ray Exposure &amp; Dose\n        \"KVP\",\n        \"XRayTubeCurrent\",\n        \"ExposureTime\",\n        \"Exposure\",\n        \"ExposureModulationType\",\n        \"CTDIvol\",\n        # Image Reconstruction &amp; Processing\n        \"ReconstructionAlgorithm\",\n        \"ReconstructionDiameter\",\n        \"ReconstructionMethod\",\n        \"ReconstructionTargetCenterPatient\",\n        \"ReconstructionFieldOfView\",\n        \"ConvolutionKernel\",\n        # Scan &amp; Acquisition Parameters\n        \"SpiralPitchFactor\",\n        \"SingleCollimationWidth\",\n        \"TotalCollimationWidth\",\n        \"TableSpeed\",\n        \"TableMotion\",\n        \"GantryDetectorTilt\",\n        \"DetectorType\",\n        \"DetectorConfiguration\",\n        \"DataCollectionCenterPatient\",\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.CTMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> <code>CT-specific computed fields.</code> <p>Returns:</p> Type Description <code>typing.Mapping[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedField]</code> <p>Mapping of field names to functions that compute values from DICOM datasets.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    \"\"\"\n    CT-specific computed fields.\n\n    Returns\n    -------\n    Mapping[str, ComputedField]\n        Mapping of field names to functions that compute values from DICOM datasets.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.MRMetadataExtractor","title":"MRMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.MRMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    return {\n        # Magnetic Field &amp; RF Properties\n        \"MagneticFieldStrength\",\n        \"ImagingFrequency\",\n        \"TransmitCoilName\",\n        # Sequence &amp; Acquisition Parameters\n        \"SequenceName\",\n        \"ScanningSequence\",\n        \"SequenceVariant\",\n        \"AcquisitionContrast\",\n        \"AcquisitionType\",\n        \"EchoTime\",\n        \"RepetitionTime\",\n        \"InversionTime\",\n        \"EchoTrainLength\",\n        \"NumberOfAverages\",\n        \"FlipAngle\",\n        \"PercentSampling\",\n        \"PercentPhaseFieldOfView\",\n        \"PixelBandwidth\",\n        \"SpacingBetweenSlices\",\n        # Diffusion Imaging\n        \"DiffusionGradientDirectionSequence\",\n        \"DiffusionBMatrixSequence\",\n        # Parallel Imaging &amp; Acceleration\n        \"ParallelAcquisitionTechnique\",\n        \"ParallelReductionFactorInPlane\",\n        \"ParallelReductionFactorOutOfPlane\",\n        # Functional MRI (fMRI)\n        \"NumberOfTemporalPositions\",\n        \"TemporalResolution\",\n        \"FrameReferenceTime\",\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.MRMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> <code>MR-specific computed fields.</code> <p>Returns:</p> Type Description <code>typing.Mapping[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedField]</code> <p>Mapping of field names to functions that compute values from DICOM datasets.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    \"\"\"\n    MR-specific computed fields.\n\n    Returns\n    -------\n    Mapping[str, ComputedField]\n        Mapping of field names to functions that compute values from DICOM datasets.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.PTMetadataExtractor","title":"PTMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.PTMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    return {\n        # Radiotracer &amp; Injection Information\n        \"Radiopharmaceutical\",\n        \"RadiopharmaceuticalStartTime\",\n        \"RadionuclideTotalDose\",\n        \"RadionuclideHalfLife\",\n        \"RadionuclidePositronFraction\",\n        \"RadiopharmaceuticalVolume\",\n        \"RadiopharmaceuticalSpecificActivity\",\n        \"RadiopharmaceuticalStartDateTime\",\n        \"RadiopharmaceuticalStopDateTime\",\n        \"RadiopharmaceuticalRoute\",\n        \"RadiopharmaceuticalCodeSequence\",\n        # PET Image Quantification\n        \"DecayCorrection\",\n        \"DecayFactor\",\n        \"AttenuationCorrectionMethod\",\n        \"ScatterCorrectionMethod\",\n        \"DecayCorrected\",\n        \"DeadTimeCorrectionFlag\",\n        \"ReconstructionMethod\",\n        # SUV (Standardized Uptake Value) Calculation\n        \"SUVType\",\n        # Acquisition Timing &amp; Dynamics\n        \"FrameReferenceTime\",\n        \"FrameTime\",\n        \"ActualFrameDuration\",\n        \"AcquisitionStartCondition\",\n        \"AcquisitionTerminationCondition\",\n        \"TimeSliceVector\",\n        # PET Detector &amp; Calibration\n        \"DetectorType\",\n        \"CoincidenceWindowWidth\",\n        \"EnergyWindowLowerLimit\",\n        \"EnergyWindowUpperLimit\",\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.PTMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> <code>PET-specific computed fields.</code> <p>Returns:</p> Type Description <code>typing.Mapping[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedField]</code> <p>Mapping of field names to functions that compute values from DICOM datasets.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    \"\"\"\n    PET-specific computed fields.\n\n    Returns\n    -------\n    Mapping[str, ComputedField]\n        Mapping of field names to functions that compute values from DICOM datasets.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.SEGMetadataExtractor","title":"SEGMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> See Also <p>https://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_C.8.20.2.html</p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.SEGMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    return {\n        # DICOM-SEG tags\n        # BINARY, FRACTIONAL, or LABELMAP\n        # https://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_C.8.20.2.3.html\n        \"SegmentationType\",\n        \"SegmentationFractionalType\",\n        \"MaximumFractionalValue\",\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.SEGMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> <code>SEG-specific computed fields.</code> <code>Each computed field is a function that takes a pydicom.Dataset as input</code> <code>and returns a computed value. The functions are defined to extract</code> <code>relevant information from the DICOM dataset.</code> <p>Returns:</p> Type Description <code>typing.Mapping[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedField]</code> <p>Mapping of field names to functions that compute values from DICOM datasets.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    \"\"\"\n    SEG-specific computed fields.\n\n    Each computed field is a function that takes a pydicom.Dataset as input\n    and returns a computed value. The functions are defined to extract\n    relevant information from the DICOM dataset.\n\n    Returns\n    -------\n    Mapping[str, ComputedField]\n        Mapping of field names to functions that compute values from DICOM datasets.\n    \"\"\"\n    from imgtools.dicom.dicom_metadata.modality_utils.seg_utils import (\n        get_seg_direction,\n        get_seg_spacing,\n        seg_reference_uids,\n    )\n\n    def get_seg_ref_series(seg: Dataset) -&gt; str:\n        \"\"\"Get the reference series UID for the segmentation.\"\"\"\n        return seg_reference_uids(seg)[0]\n\n    def get_seg_ref_sop_uids(seg: Dataset) -&gt; list[str]:\n        \"\"\"Get the reference SOP instance UIDs for the segmentation.\"\"\"\n        return seg_reference_uids(seg)[1]\n\n    def get_seg_segmentlabels(seg: Dataset) -&gt; list[str]:\n        \"\"\"Get the segment labels from the segmentation.\"\"\"\n        return [\n            desc.get(\"SegmentLabel\", \"\")\n            for desc in seg.get(\"SegmentSequence\", [])\n        ]\n\n    def get_seg_descriptions(seg: Dataset) -&gt; list[str]:\n        \"\"\"Get the segment descriptions from the segmentation.\"\"\"\n        return [\n            desc.get(\"SegmentDescription\", \"\")\n            for desc in seg.get(\"SegmentSequence\", [])\n        ]\n\n    return {\n        # prefix with \"Seg\" to avoid collision sitk computed attrbutes\n        \"SegSpacing\": lambda ds: get_seg_spacing(ds) or \"\",\n        \"SegDirection\": lambda ds: get_seg_direction(ds) or \"\",\n        \"ROINames\": get_seg_segmentlabels,\n        \"ROIDescriptions\": get_seg_descriptions,\n        \"ReferencedSeriesUID\": get_seg_ref_series,\n        \"ReferencedSOPUIDs\": get_seg_ref_sop_uids,\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTSTRUCTMetadataExtractor","title":"RTSTRUCTMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> <p>Metadata extractor for RTSTRUCT modality DICOM datasets.</p> <p>This class uses computed fields to extract ROI metadata and reference UIDs.</p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTSTRUCTMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> <code>RTSTRUCT-specific direct tags (generally minimal).</code> <p>Returns:</p> Type Description <code>set[str]</code> <p>A set of directly accessible RTSTRUCT tag names.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    \"\"\"\n    RTSTRUCT-specific direct tags (generally minimal).\n\n    Returns\n    -------\n    set[str]\n        A set of directly accessible RTSTRUCT tag names.\n    \"\"\"\n    return {\n        \"StructureSetLabel\",\n        \"StructureSetName\",\n        \"StructureSetDate\",\n        \"StructureSetTime\",\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTSTRUCTMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> <code>RTSTRUCT-specific computed fields.</code> <p>Returns:</p> Type Description <code>typing.Mapping[str, imgtools.dicom.dicom_metadata.extractor_base.ComputedField]</code> <p>Field names mapped to functions that extract computed values.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    \"\"\"\n    RTSTRUCT-specific computed fields.\n\n    Returns\n    -------\n    Mapping[str, ComputedField]\n        Field names mapped to functions that extract computed values.\n    \"\"\"\n\n    from imgtools.dicom.dicom_metadata.modality_utils.rtstruct_utils import (\n        extract_roi_names,\n        rtstruct_reference_uids,\n    )\n\n    return {\n        \"ReferencedSeriesUID\": lambda ds: rtstruct_reference_uids(ds)[0],\n        \"ReferencedSOPUIDs\": lambda ds: rtstruct_reference_uids(ds)[1],\n        \"ROINames\": extract_roi_names,\n        \"NumROIs\": lambda ds: len(extract_roi_names(ds)),\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTDOSEMetadataExtractor","title":"RTDOSEMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> <p>Metadata extractor for RTDOSE modality DICOM datasets.</p> <p>Extracts direct and computed reference UIDs from dose DICOM files.</p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTDOSEMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    return {\n        \"DoseType\",\n        \"DoseUnits\",\n        \"DoseSummationType\",\n        \"DoseGridScaling\",\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTDOSEMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    from imgtools.dicom.dicom_metadata.modality_utils.rtdose_utils import (\n        rtdose_reference_uids,\n    )\n\n    def get_sop_uids(ds: Dataset) -&gt; list[str]:\n        ref_pl, ref_struct, ref_series = rtdose_reference_uids(ds)\n        return [ref_struct or ref_pl]\n\n    return {\n        \"ReferencedSeriesUID\": lambda ds: rtdose_reference_uids(ds)[2],\n        \"ReferencedSeriesSOPUIDs\": get_sop_uids,\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTPLANMetadataExtractor","title":"RTPLANMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> <p>Metadata extractor for RTPLAN modality DICOM datasets.</p> <p>Extracts basic DICOM tags and reference to an RTSTRUCT UID.</p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTPLANMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    return {\n        \"SeriesInstanceUID\",\n        \"StudyInstanceUID\",\n        \"RTPlanLabel\",\n        \"RTPlanName\",\n        \"RTPlanDate\",\n        \"RTPlanTime\",\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.RTPLANMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    from imgtools.dicom.dicom_metadata.modality_utils.rtplan_utils import (\n        rtplan_reference_uids,\n    )\n\n    return {\"ReferencedSOPUIDs\": lambda ds: [rtplan_reference_uids(ds)]}\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.SRMetadataExtractor","title":"SRMetadataExtractor","text":"<p>               Bases: <code>imgtools.dicom.dicom_metadata.extractor_base.ModalityMetadataExtractor</code></p> <p>Metadata extractor for SR (Structured Report) modality DICOM datasets.</p> <p>Extracts referenced SeriesInstanceUIDs and SOPInstanceUIDs from structured reports.</p> <p>Methods:</p> Name Description <code>modality_tags</code> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <code>computed_fields</code> <p>A mapping of metadata field names to callables that compute their values.</p>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.SRMetadataExtractor.modality_tags","title":"modality_tags","text":"<pre><code>modality_tags() -&gt; set[str]\n</code></pre> <p>A set of DICOM tags specific to the modality handled by this extractor.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of DICOM tag names.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef modality_tags(cls) -&gt; set[str]:\n    return {\n        \"SeriesInstanceUID\",\n        \"StudyInstanceUID\",\n        \"Modality\",\n        \"Manufacturer\",\n        \"ContentDate\",\n        \"ContentTime\",\n        \"SeriesDescription\",\n    }\n</code></pre>"},{"location":"reference/dicom_metadata/#imgtools.dicom.dicom_metadata.extractors.SRMetadataExtractor.computed_fields","title":"computed_fields","text":"<pre><code>computed_fields() -&gt; typing.Mapping[\n    str,\n    imgtools.dicom.dicom_metadata.extractor_base.ComputedField,\n]\n</code></pre> <p>A mapping of metadata field names to callables that compute their values.</p> <p>The callable should accept a pydicom Dataset and return a value.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[pydicom.Dataset], imgtools.dicom.dicom_metadata.extractor_base.ComputedValue]]</code> <p>Mapping of field names to computation functions.</p> Source code in <code>src/imgtools/dicom/dicom_metadata/extractors.py</code> <pre><code>@classproperty\ndef computed_fields(cls) -&gt; Mapping[str, ComputedField]:\n    from imgtools.dicom.dicom_metadata.modality_utils.sr_utils import (\n        sr_reference_uids,\n    )\n\n    def get_series_uids(ds: Dataset) -&gt; list[str]:\n        series, _ = sr_reference_uids(ds)\n        return list(series)\n\n    def get_sop_uids(ds: Dataset) -&gt; list[str]:\n        _, sops = sr_reference_uids(ds)\n        return list(sops)\n\n    return {\n        \"ReferencedSeriesUIDs\": get_series_uids,\n        \"ReferencedSOPUIDs\": get_sop_uids,\n    }\n</code></pre>"},{"location":"reference/interlacer/","title":"Interlacer","text":""},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer","title":"Interlacer  <code>dataclass</code>","text":"<pre><code>Interlacer(\n    crawl_index: str | pathlib.Path | pandas.DataFrame,\n)\n</code></pre> <p>Builds and queries a forest of SeriesNode objects from DICOM series data.</p> <p>Parameters:</p> Name Type Description Default <code>str | pathlib.Path | pandas.DataFrame</code> <p>Path to the CSV file or DataFrame containing the series data</p> required <p>Attributes:</p> Name Type Description <code>crawl_df</code> <code>pandas.DataFrame</code> <p>DataFrame containing the data loaded from the CSV file or passed in <code>crawl_index</code></p> <code>series_nodes</code> <code>dict[str, imgtools.dicom.interlacer.SeriesNode]</code> <p>Maps SeriesInstanceUID to SeriesNode objects</p> <code>root_nodes</code> <code>list[imgtools.dicom.interlacer.SeriesNode]</code> <p>List of root nodes in the forest</p> <p>Methods:</p> Name Description <code>print_tree</code> <p>Print a representation of the forest.</p> <code>query</code> <p>Query the forest for specific modalities.</p> <code>query_all</code> <p>Simply return ALL possible matches</p> <code>visualize_forest</code> <p>Visualize the forest as an interactive network graph.</p>"},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer(crawl_index)","title":"<code>crawl_index</code>","text":""},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer.print_tree","title":"print_tree","text":"<pre><code>print_tree(input_directory: pathlib.Path | None) -&gt; None\n</code></pre> <p>Print a representation of the forest.</p> Source code in <code>src/imgtools/dicom/interlacer.py</code> <pre><code>def print_tree(self, input_directory: Path | None) -&gt; None:\n    \"\"\"Print a representation of the forest.\"\"\"\n    print_interlacer_tree(self.root_nodes, input_directory)\n</code></pre>"},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer.query","title":"query","text":"<pre><code>query(\n    query_string: str, group_by_root: bool = True\n) -&gt; list[list[imgtools.dicom.interlacer.SeriesNode]]\n</code></pre> <p>Query the forest for specific modalities.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Comma-separated string of modalities to query (e.g., 'CT,MR')</p> required <code>bool</code> <p>If True, group the returned SeriesNodes by their root CT/MR/PT node (i.e., avoid duplicate root nodes across results).</p> <code>True</code> <p>Returns:</p> Type Description <code>list[list[dict[str, str]]]</code> <p>List of matched series groups where each series is represented by a dict containing 'Series' and 'Modality' keys</p> Notes <p>Supported modalities: - CT: Computed Tomography - PT: Positron Emission Tomography - MR: Magnetic Resonance Imaging - SEG: Segmentation - RTSTRUCT: Radiotherapy Structure - RTDOSE: Radiotherapy Dose</p> Source code in <code>src/imgtools/dicom/interlacer.py</code> <pre><code>def query(\n    self,\n    query_string: str,\n    group_by_root: bool = True,\n) -&gt; list[list[SeriesNode]]:\n    \"\"\"\n    Query the forest for specific modalities.\n\n    Parameters\n    ----------\n    query_string : str\n        Comma-separated string of modalities to query (e.g., 'CT,MR')\n\n    group_by_root : bool, default=True\n        If True, group the returned SeriesNodes by their root CT/MR/PT\n        node (i.e., avoid duplicate root nodes across results).\n\n    Returns\n    -------\n    list[list[dict[str, str]]]\n        List of matched series groups where each series is represented by a\n        dict containing 'Series' and 'Modality' keys\n\n    Notes\n    -----\n    Supported modalities:\n    - CT: Computed Tomography\n    - PT: Positron Emission Tomography\n    - MR: Magnetic Resonance Imaging\n    - SEG: Segmentation\n    - RTSTRUCT: Radiotherapy Structure\n    - RTDOSE: Radiotherapy Dose\n    \"\"\"\n    if query_string in [\"*\", \"all\"]:\n        query_results = self.query_all()\n    else:\n        queried_modalities = self._get_valid_query(query_string.split(\",\"))\n        query_results = self._query(queried_modalities)\n\n    if not group_by_root:\n        return query_results\n\n    grouped: dict[SeriesNode, set[SeriesNode]] = defaultdict(set)\n    # pretty much start with the root node, then add all branches\n    for path in query_results:\n        root = path[0]\n        grouped[root].update(path[1:])\n\n    # break each item into a list starting with key, then all the values\n    return [[key] + list(value) for key, value in grouped.items()]\n</code></pre>"},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer.query(query_string)","title":"<code>query_string</code>","text":""},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer.query(group_by_root)","title":"<code>group_by_root</code>","text":""},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer.query_all","title":"query_all","text":"<pre><code>query_all() -&gt; (\n    list[list[imgtools.dicom.interlacer.SeriesNode]]\n)\n</code></pre> <p>Simply return ALL possible matches Note this has a different approach than query, since we dont care about the order of the modalities, just that they exist in the Branch</p> Source code in <code>src/imgtools/dicom/interlacer.py</code> <pre><code>def query_all(self) -&gt; list[list[SeriesNode]]:\n    \"\"\"Simply return ALL possible matches\n    Note this has a different approach than query, since we dont care\n    about the order of the modalities, just that they exist in the\n    Branch\n    \"\"\"\n    results: list[list[SeriesNode]] = []\n\n    def dfs(node: SeriesNode, path: list[SeriesNode]) -&gt; None:\n        path.append(node)\n        if len(node.children) == 0:\n            # If this is a leaf node, check if the path is unique\n            # but first, if the path has any 'RTPLAN' nodes, remove them\n            # TODO:: create a global VALID_MODALITIES list instead of hardcoding\n            cleaned_path = [n for n in path if n.Modality != \"RTPLAN\"]\n            if cleaned_path not in results:\n                results.append(cleaned_path)\n\n        for child in node.children:\n            dfs(child, path.copy())\n\n    for root in self.root_nodes:\n        dfs(root, [])\n    return results\n</code></pre>"},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer.visualize_forest","title":"visualize_forest","text":"<pre><code>visualize_forest(\n    save_path: str | pathlib.Path,\n) -&gt; pathlib.Path\n</code></pre> <p>Visualize the forest as an interactive network graph.</p> <p>Creates an HTML visualization showing nodes for each SeriesNode and edges for parent-child relationships.</p> <p>Parameters:</p> Name Type Description Default <code>str | pathlib.Path</code> <p>Path to save the HTML visualization.</p> required <p>Returns:</p> Type Description <code>pathlib.Path</code> <p>Path to the saved HTML visualization</p> Source code in <code>src/imgtools/dicom/interlacer.py</code> <pre><code>def visualize_forest(self, save_path: str | Path) -&gt; Path:\n    \"\"\"\n    Visualize the forest as an interactive network graph.\n\n    Creates an HTML visualization showing nodes for each SeriesNode and\n    edges for parent-child relationships.\n\n    Parameters\n    ----------\n    save_path : str | Path\n        Path to save the HTML visualization.\n\n    Returns\n    -------\n    Path\n        Path to the saved HTML visualization\n\n    Raises\n    ------\n    OptionalImportError\n        If pyvis package is not installed\n    \"\"\"\n    if not _pyvis_available:\n        raise OptionalImportError(\"pyvis\")\n\n    save_path = Path(save_path)\n    save_path.parent.mkdir(parents=True, exist_ok=True)\n\n    net = pyvis.network.Network(\n        height=\"800px\", width=\"100%\", notebook=False, directed=True\n    )\n\n    modality_colors = {\n        \"CT\": \"#1f77b4\",  # Blue\n        \"MR\": \"#ff7f0e\",  # Orange\n        \"PT\": \"#2ca02c\",  # Green\n        \"SEG\": \"#d62728\",  # Red\n        \"RTSTRUCT\": \"#9467bd\",  # Purple\n        \"RTPLAN\": \"#8c564b\",  # Brown\n        \"RTDOSE\": \"#e377c2\",  # Pink\n    }\n\n    patient_trees = {}  # Store patient-to-root mappings\n\n    def add_node_and_edges(\n        node: SeriesNode, parent: SeriesNode | None = None\n    ) -&gt; None:\n        color = modality_colors.get(\n            node.Modality, \"#7f7f7f\"\n        )  # Default gray if unknown\n        title = f\"PatientID: {node.PatientID}\\nSeries: {node.SeriesInstanceUID}\"\n        net.add_node(\n            node.SeriesInstanceUID,\n            label=node.Modality,\n            title=title,\n            color=color,\n        )\n        if parent:\n            net.add_edge(node.SeriesInstanceUID, parent.SeriesInstanceUID)\n\n        for child in node.children:\n            add_node_and_edges(child, node)\n\n    # Add root nodes (each representing a patient)\n    for root in self.root_nodes:\n        add_node_and_edges(root)\n        patient_trees[root.PatientID] = (\n            root.SeriesInstanceUID\n        )  # Store the root Series as entry point for the patient\n\n    net.force_atlas_2based()\n\n    # Generate the sidebar HTML with clickable patient IDs\n    sidebar_html = \"\"\"\n    &lt;div id=\"sidebar\"&gt;\n        &lt;h2&gt;Patient List&lt;/h2&gt;\n        &lt;ul&gt;\n    \"\"\"\n    for patient_id, root_series in patient_trees.items():\n        sidebar_html += f'&lt;li&gt;&lt;a href=\"#\" onclick=\"focusNode(\\'{root_series}\\')\"&gt;{patient_id}&lt;/a&gt;&lt;/li&gt;'\n\n    sidebar_html += \"\"\"\n        &lt;/ul&gt;\n    &lt;/div&gt;\n\n    &lt;style&gt;\n        body {\n            margin: 0;\n            padding: 0;\n        }\n\n        #sidebar {\n            position: fixed;\n            left: 0;\n            top: 0;\n            width: 250px;\n            height: 100%;\n            background: #f4f4f4;\n            padding: 20px;\n            overflow-y: auto;\n            box-shadow: 2px 0 5px rgba(0,0,0,0.3);\n            z-index: 1000;\n        }\n\n        #sidebar h2 {\n            text-align: center;\n            font-family: Arial, sans-serif;\n        }\n\n        #sidebar ul {\n            list-style: none;\n            padding: 0;\n        }\n\n        #sidebar li {\n            margin: 10px 0;\n        }\n\n        #sidebar a {\n            text-decoration: none;\n            color: #007bff;\n            font-weight: bold;\n            font-family: Arial, sans-serif;\n        }\n\n        #sidebar a:hover {\n            text-decoration: underline;\n        }\n\n        #mynetwork {\n            margin-left: 270px; /* Room for sidebar */\n            height: 100vh;\n        }\n    &lt;/style&gt;\n\n    &lt;script type=\"text/javascript\"&gt;\n        function focusNode(nodeId) {\n            if (typeof network !== 'undefined') {\n                network.selectNodes([nodeId]);\n                network.focus(nodeId, {\n                    scale: 3.5,\n                    animation: {\n                        duration: 500,\n                        easingFunction: \"easeInOutQuad\"\n                    }\n                });\n            } else {\n                alert(\"Network graph not loaded yet.\");\n            }\n        }\n    &lt;/script&gt;\n    \"\"\"\n\n    # Generate the full HTML file\n    logger.info(\"Saving forest visualization...\", path=save_path)\n    net_html = net.generate_html()\n    full_html = net_html.replace(\n        \"&lt;body&gt;\", f\"&lt;body&gt;{sidebar_html}\"\n    )  # Insert sidebar into HTML\n\n    # Write the final HTML file\n    save_path.write_text(full_html, encoding=\"utf-8\")\n\n    return save_path\n</code></pre>"},{"location":"reference/interlacer/#imgtools.dicom.interlacer.Interlacer.visualize_forest(save_path)","title":"<code>save_path</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/","title":"Find DICOMs","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms","title":"imgtools.dicom.find_dicoms","text":"<pre><code>find_dicoms(\n    directory: pathlib.Path,\n    recursive: bool = True,\n    check_header: bool = False,\n    extension: str = \"dcm\",\n    case_sensitive: bool = False,\n    limit: int | None = None,\n    search_input: typing.List[str] | None = None,\n) -&gt; typing.List[pathlib.Path]\n</code></pre> <p>Locate DICOM files in a specified directory.</p> <p>This function scans a directory for files matching the specified extension and validates them as DICOM files based on the provided options. It supports recursive search and optional header validation to confirm file validity.</p> <p>Parameters:</p> Name Type Description Default <code>pathlib.Path</code> <p>The directory in which to search for DICOM files.</p> required <code>bool</code> <p>Whether to include subdirectories in the search</p> <code>True</code> <code>bool</code> <p>Whether to validate files by checking for a valid DICOM header.     - If <code>True</code>, perform DICOM header validation (slower but more accurate).     - If <code>False</code>, skip header validation and rely on extension.</p> <code>False</code> <code>str</code> <p>File extension to search for (e.g., \"dcm\"). If <code>None</code>, consider all files regardless of extension.</p> <code>\"dcm\"</code> <code>bool</code> <p>Whether to perform a case-sensitive search for the file extension. If <code>False</code>, the search is case-insensitive.</p> <code>False</code> <code>int</code> <p>Maximum number of DICOM files to return. If <code>None</code>, return all found files.</p> <code>None</code> <code>typing.List[str]</code> <p>List of terms to filter files by. Only files containing all terms in their paths will be included. If <code>None</code>, no filtering is applied.</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.List[pathlib.Path]</code> <p>A list of valid DICOM file paths found in the directory.</p> Notes <ul> <li>If <code>check_header</code> is enabled, the function checks each file for a valid     DICOM header, which may slow down the search process.</li> </ul> <p>Examples:</p> <p>Setup</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from imgtools.dicom.dicom_find import find_dicoms\n</code></pre> <p>Find DICOM files recursively without header validation:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=False,\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm'), PosixPath('/data/subdir/scan3.DCM')]\n</code></pre> <p>Suppose that <code>scan3.DCM</code> is not a valid DICOM file. Find DICOM files with header validation:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=True,\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n</code></pre> <p>Find DICOM files without recursion:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=False,\n...     check_header=False,\n... )\n[PosixPath('/data/scan1.dcm')]\n</code></pre> <p>Find DICOM files with a specific extension:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=False,\n...     extension=\"dcm\",\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n</code></pre> <p>Find DICOM files with a search input (substring match):</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=False,\n...     search_input=[\"1\", \"scan2\"],\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n</code></pre> <p>Find DICOM files with a limit:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=False,\n...     limit=1,\n... )\n[PosixPath('/data/scan1.dcm')]\n</code></pre> <p>Find DICOM files with all options:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=True,\n...     extension=\"dcm\",\n...     limit=2,\n...     search_input=[\"scan\"],\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n</code></pre> Source code in <code>src/imgtools/dicom/dicom_find.py</code> <pre><code>def find_dicoms(\n    directory: Path,\n    recursive: bool = True,\n    check_header: bool = False,\n    extension: str = \"dcm\",\n    case_sensitive: bool = False,\n    limit: int | None = None,\n    search_input: List[str] | None = None,\n) -&gt; List[Path]:\n    \"\"\"Locate DICOM files in a specified directory.\n\n    This function scans a directory for files matching the specified extension\n    and validates them as DICOM files based on the provided options. It supports\n    recursive search and optional header validation to confirm file validity.\n\n    Parameters\n    ----------\n    directory : Path\n        The directory in which to search for DICOM files.\n    recursive : bool\n        Whether to include subdirectories in the search\n    check_header : bool\n        Whether to validate files by checking for a valid DICOM header.\n            - If `True`, perform DICOM header validation (slower but more accurate).\n            - If `False`, skip header validation and rely on extension.\n    extension : str, default=\"dcm\"\n        File extension to search for (e.g., \"dcm\"). If `None`, consider all files\n        regardless of extension.\n    case_sensitive : bool, default=False\n        Whether to perform a case-sensitive search for the file extension.\n        If `False`, the search is case-insensitive.\n    limit : int, optional\n        Maximum number of DICOM files to return. If `None`, return all found files.\n    search_input : List[str], optional\n        List of terms to filter files by. Only files containing all terms\n        in their paths will be included. If `None`, no filtering is applied.\n\n    Returns\n    -------\n    List[Path]\n        A list of valid DICOM file paths found in the directory.\n\n    Notes\n    -----\n    - If `check_header` is enabled, the function checks each file for a valid\n        DICOM header, which may slow down the search process.\n\n    Examples\n    --------\n    Setup\n\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from imgtools.dicom.dicom_find import find_dicoms\n\n    Find DICOM files recursively without header validation:\n\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=False,\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm'), \\\nPosixPath('/data/subdir/scan3.DCM')]\n\n    Suppose that `scan3.DCM` is not a valid DICOM file. Find DICOM files with \\\nheader validation:\n\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=True,\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n\n    Find DICOM files without recursion:\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=False,\n    ...     check_header=False,\n    ... )\n    [PosixPath('/data/scan1.dcm')]\n\n    Find DICOM files with a specific extension:\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=False,\n    ...     extension=\"dcm\",\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n\n    Find DICOM files with a search input (substring match):\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=False,\n    ...     search_input=[\"1\", \"scan2\"],\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n\n    Find DICOM files with a limit:\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=False,\n    ...     limit=1,\n    ... )\n    [PosixPath('/data/scan1.dcm')]\n\n    Find DICOM files with all options:\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=True,\n    ...     extension=\"dcm\",\n    ...     limit=2,\n    ...     search_input=[\"scan\"],\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n    \"\"\"\n\n    files = filter_valid_dicoms(\n        directory,\n        check_header,\n        case_sensitive,\n        search_input,\n        extension or \"\",\n        recursive,\n    )\n\n    return list(islice(files, limit)) if limit else list(files)\n</code></pre>"},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(directory)","title":"<code>directory</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(recursive)","title":"<code>recursive</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(check_header)","title":"<code>check_header</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(extension)","title":"<code>extension</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(case_sensitive)","title":"<code>case_sensitive</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(limit)","title":"<code>limit</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(search_input)","title":"<code>search_input</code>","text":""},{"location":"reference/dicom-utils/load-dicom/","title":"Load DICOM","text":""},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom","title":"imgtools.dicom.load_dicom","text":"<pre><code>load_dicom(\n    dicom_input: imgtools.dicom.dicom_reader.DicomInput,\n    force: bool = True,\n    stop_before_pixels: bool = True,\n    **kwargs: typing.Any\n) -&gt; pydicom.dataset.FileDataset\n</code></pre> <p>Load a DICOM file and return the parsed FileDataset object.</p> <p>This function supports various input types including file paths, byte streams, and file-like objects. It uses the <code>pydicom.dcmread</code> function to read the DICOM file.</p> Notes <ul> <li>If <code>dicom_input</code> is already a <code>FileDataset</code>, it is returned as is.</li> <li>If <code>dicom_input</code> is a file path or file-like object, it is read using <code>pydicom.dcmread</code>.</li> <li>If <code>dicom_input</code> is a byte stream, it is wrapped in a <code>BytesIO</code> object and then read.</li> <li>An <code>InvalidDicomError</code> is raised if the input type is unsupported.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>pydicom.dataset.FileDataset | str | pathlib.Path | bytes | typing.BinaryIO</code> <p>Input DICOM file as a <code>pydicom.FileDataset</code>, file path, byte stream, or file-like object.</p> required <code>bool</code> <p>Whether to allow reading DICOM files missing the File Meta Information header, by default True.</p> <code>True</code> <code>bool</code> <p>Whether to stop reading the DICOM file before loading pixel data, by default True.</p> <code>True</code> <code>typing.Any</code> <p>Additional keyword arguments to pass to <code>pydicom.dcmread</code>. i.e <code>specific_tags</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pydicom.dataset.FileDataset</code> <p>Parsed DICOM dataset.</p> <p>Raises:</p> Type Description <code>imgtools.exceptions.InvalidDicomError</code> <p>If the input is of an unsupported type or cannot be read as a DICOM file.</p> Source code in <code>src/imgtools/dicom/dicom_reader.py</code> <pre><code>def load_dicom(\n    dicom_input: DicomInput,\n    force: bool = True,\n    stop_before_pixels: bool = True,\n    **kwargs: Any,  # noqa: ANN401\n) -&gt; FileDataset:\n    \"\"\"Load a DICOM file and return the parsed FileDataset object.\n\n    This function supports various input types including file paths, byte streams,\n    and file-like objects. It uses the `pydicom.dcmread` function to read the DICOM file.\n\n    Notes\n    -----\n    - If `dicom_input` is already a `FileDataset`, it is returned as is.\n    - If `dicom_input` is a file path or file-like object, it is read using `pydicom.dcmread`.\n    - If `dicom_input` is a byte stream, it is wrapped in a `BytesIO` object and then read.\n    - An `InvalidDicomError` is raised if the input type is unsupported.\n\n    Parameters\n    ----------\n    dicom_input : FileDataset | str | Path | bytes | BinaryIO\n        Input DICOM file as a `pydicom.FileDataset`, file path, byte stream, or file-like object.\n    force : bool, optional\n        Whether to allow reading DICOM files missing the *File Meta Information*\n        header, by default True.\n    stop_before_pixels : bool, optional\n        Whether to stop reading the DICOM file before loading pixel data, by default True.\n    **kwargs\n        Additional keyword arguments to pass to `pydicom.dcmread`.\n        i.e `specific_tags`.\n    Returns\n    -------\n    FileDataset\n        Parsed DICOM dataset.\n\n    Raises\n    ------\n    InvalidDicomError\n        If the input is of an unsupported type or cannot be read as a DICOM file.\n    \"\"\"\n    match dicom_input:\n        case FileDataset():\n            return dicom_input\n        case str() | Path() | BinaryIO():\n            dicom_source = path_from_pathlike(dicom_input)\n            return dcmread(\n                dicom_source,\n                force=force,\n                stop_before_pixels=stop_before_pixels,\n                **kwargs,\n            )\n        case bytes():\n            return dcmread(\n                BytesIO(dicom_input),\n                force=force,\n                stop_before_pixels=stop_before_pixels,\n                **kwargs,\n            )\n        case _:\n            msg = (\n                f\"Invalid input type for 'dicom_input': {type(dicom_input)}. \"\n                \"Must be a FileDataset, str, Path, bytes, or BinaryIO object.\"\n            )\n            raise InvalidDicomError(msg)\n</code></pre>"},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom(dicom_input)","title":"<code>dicom_input</code>","text":""},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom(force)","title":"<code>force</code>","text":""},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom(stop_before_pixels)","title":"<code>stop_before_pixels</code>","text":""},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"reference/dicom-utils/lookup_tag/","title":"Lookup Tag","text":""},{"location":"reference/dicom-utils/lookup_tag/#imgtools.dicom.lookup_tag","title":"imgtools.dicom.lookup_tag  <code>cached</code>","text":"<pre><code>lookup_tag(\n    keyword: str, hex_format: bool = False\n) -&gt; typing.Optional[str]\n</code></pre> <p>Lookup the tag for a given DICOM keyword.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The DICOM keyword to look up.</p> required <code>bool</code> <p>If True, return the tag in hexadecimal format (default is False).</p> <code>False</code> <p>Returns:</p> Type Description <code>str or None</code> <p>The DICOM tag as a string, or None if the keyword is invalid.</p> <p>Examples:</p> <p>Lookup a DICOM tag in decimal format:</p> <pre><code>&gt;&gt;&gt; lookup_tag(\"PatientID\")\n'1048608'\n</code></pre> <p>Lookup a DICOM tag in hexadecimal format:</p> <pre><code>&gt;&gt;&gt; lookup_tag(\n...     \"PatientID\",\n...     hex_format=True,\n... )\n'0x100020'\n</code></pre> Source code in <code>src/imgtools/dicom/utils.py</code> <pre><code>@functools.lru_cache(maxsize=1024)\ndef lookup_tag(keyword: str, hex_format: bool = False) -&gt; Optional[str]:\n    \"\"\"\n    Lookup the tag for a given DICOM keyword.\n\n    Parameters\n    ----------\n    keyword : str\n        The DICOM keyword to look up.\n    hex_format : bool, optional\n        If True, return the tag in hexadecimal format (default is False).\n\n    Returns\n    -------\n    str or None\n        The DICOM tag as a string, or None if the keyword is invalid.\n\n    Examples\n    --------\n\n    Lookup a DICOM tag in decimal format:\n\n    &gt;&gt;&gt; lookup_tag(\"PatientID\")\n    '1048608'\n\n    Lookup a DICOM tag in hexadecimal format:\n\n    &gt;&gt;&gt; lookup_tag(\n    ...     \"PatientID\",\n    ...     hex_format=True,\n    ... )\n    '0x100020'\n    \"\"\"\n    if (tag := tag_for_keyword(keyword)) is None:\n        return None\n    return f\"0x{tag:X}\" if hex_format else str(tag)\n</code></pre>"},{"location":"reference/dicom-utils/lookup_tag/#imgtools.dicom.lookup_tag(keyword)","title":"<code>keyword</code>","text":""},{"location":"reference/dicom-utils/lookup_tag/#imgtools.dicom.lookup_tag(hex_format)","title":"<code>hex_format</code>","text":""},{"location":"reference/dicom-utils/similar_tags/","title":"Similar Tags","text":""},{"location":"reference/dicom-utils/similar_tags/#imgtools.dicom.similar_tags","title":"imgtools.dicom.similar_tags  <code>cached</code>","text":"<pre><code>similar_tags(\n    keyword: str, n: int = 3, threshold: float = 0.6\n) -&gt; typing.List[str]\n</code></pre> <p>Find similar DICOM tags for a given keyword.</p> <p>Useful for User Interface to suggest similar tags based on a misspelled keyword.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The keyword to search for similar tags.</p> required <code>int</code> <p>Maximum number of similar tags to return (default is 3).</p> <code>3</code> <code>float</code> <p>Minimum similarity ratio (default is 0.6).</p> <code>0.6</code> <p>Returns:</p> Type Description <code>typing.List[str]</code> <p>A list of up to <code>n</code> similar DICOM tags.</p> <p>Examples:</p> <p>Find similar tags for a misspelled keyword:</p> <pre><code>&gt;&gt;&gt; similar_tags(\"PatinetID\")\n['PatientID', 'PatientName', 'PatientBirthDate']\n</code></pre> <p>Adjust the number of results and threshold:</p> <pre><code>&gt;&gt;&gt; similar_tags(\n...     \"PatinetID\",\n...     n=5,\n...     threshold=0.7,\n... )\n['PatientID', 'PatientName']\n</code></pre> Source code in <code>src/imgtools/dicom/utils.py</code> <pre><code>@functools.lru_cache(maxsize=1024)\ndef similar_tags(\n    keyword: str, n: int = 3, threshold: float = 0.6\n) -&gt; List[str]:\n    \"\"\"Find similar DICOM tags for a given keyword.\n\n    Useful for User Interface to suggest similar tags based on a misspelled keyword.\n\n    Parameters\n    ----------\n    keyword : str\n        The keyword to search for similar tags.\n    n : int, optional\n        Maximum number of similar tags to return (default is 3).\n    threshold : float, optional\n        Minimum similarity ratio (default is 0.6).\n\n    Returns\n    -------\n    List[str]\n        A list of up to `n` similar DICOM tags.\n\n    Examples\n    --------\n    Find similar tags for a misspelled keyword:\n\n    &gt;&gt;&gt; similar_tags(\"PatinetID\")\n    ['PatientID', 'PatientName', 'PatientBirthDate']\n\n    Adjust the number of results and threshold:\n\n    &gt;&gt;&gt; similar_tags(\n    ...     \"PatinetID\",\n    ...     n=5,\n    ...     threshold=0.7,\n    ... )\n    ['PatientID', 'PatientName']\n    \"\"\"\n    return difflib.get_close_matches(keyword, ALL_DICOM_TAGS, n, threshold)\n</code></pre>"},{"location":"reference/dicom-utils/similar_tags/#imgtools.dicom.similar_tags(keyword)","title":"<code>keyword</code>","text":""},{"location":"reference/dicom-utils/similar_tags/#imgtools.dicom.similar_tags(n)","title":"<code>n</code>","text":""},{"location":"reference/dicom-utils/similar_tags/#imgtools.dicom.similar_tags(threshold)","title":"<code>threshold</code>","text":""},{"location":"reference/dicom-utils/tag_exists/","title":"Tag Exists","text":""},{"location":"reference/dicom-utils/tag_exists/#imgtools.dicom.tag_exists","title":"imgtools.dicom.tag_exists  <code>cached</code>","text":"<pre><code>tag_exists(keyword: str) -&gt; bool\n</code></pre> <p>Boolean check if a DICOM tag exists for a given keyword.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The DICOM keyword to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the tag exists, False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tag_exists(\"PatientID\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; tag_exists(\"InvalidKeyword\")\nFalse\n</code></pre> Source code in <code>src/imgtools/dicom/utils.py</code> <pre><code>@functools.lru_cache(maxsize=1024)\ndef tag_exists(keyword: str) -&gt; bool:\n    \"\"\"Boolean check if a DICOM tag exists for a given keyword.\n\n    Parameters\n    ----------\n    keyword : str\n        The DICOM keyword to check.\n\n    Returns\n    -------\n    bool\n        True if the tag exists, False otherwise.\n\n    Examples\n    --------\n\n    &gt;&gt;&gt; tag_exists(\"PatientID\")\n    True\n\n    &gt;&gt;&gt; tag_exists(\"InvalidKeyword\")\n    False\n    \"\"\"\n    return dictionary_has_tag(keyword)\n</code></pre>"},{"location":"reference/dicom-utils/tag_exists/#imgtools.dicom.tag_exists(keyword)","title":"<code>keyword</code>","text":""},{"location":"reference/dicomsort/dicomsorter/","title":"DICOMSorter","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort","title":"sort","text":"<p>Sorting DICOM Files by Specific Tags and Patterns.</p> <p>This module provides functionality to organize DICOM files into structured directories based on customizable target patterns.</p> <p>The target patterns allow metadata-driven file organization using placeholders for DICOM tags, enabling flexible and systematic storage.</p> Extended Summary <p>Target patterns define directory structures using placeholders, such as <code>%&lt;DICOMKey&gt;</code> and <code>{DICOMKey}</code>, which are resolved to their corresponding metadata values in the DICOM file.</p> <p>This approach ensures that files are organized based on their metadata, while retaining their original basenames. Files with identical metadata fields are placed in separate directories to preserve unique identifiers.</p> <p>Examples of target patterns:</p> <pre><code>- `%PatientID/%StudyID/{SeriesID}/`\n- `path/to_destination/%PatientID/images/%Modality/%SeriesInstanceUID/`\n</code></pre> <p>Important: Only the directory structure is modified during the sorting process. The basename of each file remains unchanged.</p> Notes <p>The module ensures that:</p> <ol> <li>Target patterns are resolved accurately based on the metadata in DICOM files.</li> <li>Files are placed in directories that reflect their resolved metadata fields.</li> <li>Original basenames are preserved to prevent unintended overwrites!</li> </ol> <p>Examples:</p> <p>Source file:</p> <pre><code>/source_dir/HN-CHUS-082/1-1.dcm\n</code></pre> <p>Target directory pattern:</p> <pre><code>./data/dicoms/%PatientID/Study-%StudyInstanceUID/Series-%SeriesInstanceUID/%Modality/\n</code></pre> <p>would result in the following structure for each file:</p> <pre><code>data/\n\u2514\u2500\u2500 dicoms/\n    \u2514\u2500\u2500 {PatientID}/\n        \u2514\u2500\u2500 Study-{StudyInstanceUID}/\n            \u2514\u2500\u2500 Series-{SeriesInstanceUID}/\n                \u2514\u2500\u2500 {Modality}/\n                    \u2514\u2500\u2500 1-1.dcm\n</code></pre> <p>And so the resolved path for the file would be:</p> <pre><code>./data/dicoms/HN-CHUS-082/Study-06980/Series-67882/RTSTRUCT/1-1.dcm\n</code></pre> <p>Here, the file is relocated into the resolved directory structure:</p> <pre><code>./data/dicoms/HN-CHUS-082/Study-06980/Series-67882/RTSTRUCT/\n</code></pre> <p>while the basename <code>1-1.dcm</code> remains unchanged.</p>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter","title":"DICOMSorter","text":"<pre><code>DICOMSorter(\n    source_directory: pathlib.Path,\n    target_pattern: str,\n    pattern_parser: typing.Pattern = imgtools.dicom.sort.dicomsorter.DEFAULT_PATTERN_PARSER,\n)\n</code></pre> <p>               Bases: <code>imgtools.dicom.sort.SorterBase</code></p> <p>A specialized implementation of the <code>SorterBase</code> for sorting DICOM files by metadata.</p> <p>This class resolves paths for DICOM files based on specified target patterns, using metadata extracted from the files. The filename of each source file is preserved during this process.</p> <p>Attributes:</p> Name Type Description <code>source_directory</code> <code>pathlib.Path</code> <p>The directory containing the files to be sorted.</p> <code>logger</code> <code>Logger</code> <p>The instance logger bound with the source directory context.</p> <code>dicom_files</code> <code>list of Path</code> <p>The list of DICOM files found in the <code>source_directory</code>.</p> <code>format</code> <code>str</code> <p>The parsed format string with placeholders for DICOM tags.</p> <code>keys</code> <code>typing.Set[str]</code> <p>DICOM tags extracted from the target pattern.</p> <code>invalid_keys</code> <code>typing.Set[str]</code> <p>DICOM tags from the pattern that are invalid.</p> <code>force_dcmread</code> <code>bool</code> <p>If True, force the use of <code>pydicom.dcmread</code> for reading DICOM files.</p> <p>Methods:</p> Name Description <code>execute</code> <p>Execute the file action on DICOM files.</p> <code>print_tree</code> <p>Display the pattern structure as a tree visualization.</p> <code>validate_keys</code> <p>Validate extracted keys. Subclasses should implement this method</p> Source code in <code>src/imgtools/dicom/sort/dicomsorter.py</code> <pre><code>def __init__(\n    self,\n    source_directory: Path,\n    target_pattern: str,\n    pattern_parser: Pattern = DEFAULT_PATTERN_PARSER,\n) -&gt; None:\n    super().__init__(\n        source_directory=source_directory,\n        target_pattern=target_pattern,\n        pattern_parser=pattern_parser,\n    )\n    self.logger.debug(\n        \"All DICOM Keys are Valid in target pattern\", keys=self.keys\n    )\n</code></pre>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.format","title":"format  <code>property</code>","text":"<pre><code>format: str\n</code></pre> <p>Get the formatted pattern string.</p>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.invalid_keys","title":"invalid_keys  <code>property</code>","text":"<pre><code>invalid_keys: typing.Set[str]\n</code></pre> <p>Get the set of invalid keys.</p> <p>Essentially, this will check <code>pydicom.dictionary_has_tag</code> for each key in the pattern and return the set of keys that are invalid.</p> <p>Returns:</p> Type Description <code>typing.Set[str]</code> <p>The set of invalid keys.</p>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.keys","title":"keys  <code>property</code>","text":"<pre><code>keys: typing.Set[str]\n</code></pre> <p>Get the set of keys extracted from the pattern.</p>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.pattern_preview","title":"pattern_preview  <code>property</code>","text":"<pre><code>pattern_preview: str\n</code></pre> <p>Returns a human readable preview of the pattern.</p> <p>Useful for visualizing the pattern structure and can be highlighted using Rich Console.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; target_pattern = \"%key1/%key2/%key3\"\n&gt;&gt;&gt; pattern_preview = \"{key1}/{key2}/{key3}\"\n</code></pre>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute","title":"execute","text":"<pre><code>execute(\n    action: (\n        imgtools.dicom.sort.FileAction | str\n    ) = imgtools.dicom.sort.FileAction.MOVE,\n    overwrite: bool = False,\n    dry_run: bool = False,\n    num_workers: int = 1,\n    truncate_uids: int = 5,\n) -&gt; None\n</code></pre> <p>Execute the file action on DICOM files.</p> <p>Users are encouraged to use FileAction.HARDLINK for efficient storage and performance for large dataset, as well as protection against lost data.</p> <p>Using hard links can save disk space and improve performance by creating multiple directory entries (links) for a single file instead of duplicating the file content. This is particularly useful when working with large datasets, such as DICOM files, where storage efficiency is crucial.</p> <p>Parameters:</p> Name Type Description Default <code>imgtools.dicom.sort.FileAction</code> <p>The action to apply to the DICOM files (e.g., move, copy).</p> <code>FileAction.MOVE</code> <code>bool</code> <p>If True, overwrite existing files at the destination.</p> <code>False</code> <code>bool</code> <p>If True, perform a dry run without making any changes.</p> <code>False</code> <code>int</code> <p>The number of worker threads to use for processing files.</p> <code>1</code> <code>int</code> <p>The number of characters to truncate from the UID.</p> <code>5</code> Source code in <code>src/imgtools/dicom/sort/dicomsorter.py</code> <pre><code>def execute(\n    self,\n    action: FileAction | str = FileAction.MOVE,\n    overwrite: bool = False,\n    dry_run: bool = False,\n    num_workers: int = 1,\n    truncate_uids: int = 5,\n) -&gt; None:\n    \"\"\"Execute the file action on DICOM files.\n\n    Users are encouraged to use FileAction.HARDLINK for\n    efficient storage and performance for large dataset, as well as\n    protection against lost data.\n\n    Using hard links can save disk space and improve performance by\n    creating multiple directory entries (links) for a single file\n    instead of duplicating the file content. This is particularly\n    useful when working with large datasets, such as DICOM files,\n    where storage efficiency is crucial.\n\n    Parameters\n    ----------\n    action : FileAction, default: FileAction.MOVE\n        The action to apply to the DICOM files (e.g., move, copy).\n    overwrite : bool, default: False\n        If True, overwrite existing files at the destination.\n    dry_run : bool, default: False\n        If True, perform a dry run without making any changes.\n    num_workers : int, default: 1\n        The number of worker threads to use for processing files.\n    truncate_uids : int, default: 5\n        The number of characters to truncate from the UID.\n\n    Raises\n    ------\n    ValueError\n            If the provided action is not a valid FileAction.\n    \"\"\"\n    if not isinstance(action, FileAction):\n        action = FileAction.validate(action)\n\n    self.logger.debug(\n        f\"Mapping {len(self.dicom_files)} files to new paths\"\n    )\n\n    # Create a progress bar that can be used to track everything\n    with self._progress_bar() as progress_bar:\n        ################################################################################\n        # Resolve new paths\n        ################################################################################\n        file_map: Dict[Path, Path] = self._resolve_new_paths(\n            progress_bar=progress_bar,\n            num_workers=num_workers,\n            truncate_uids=truncate_uids,\n        )\n    self.logger.info(\"Finished resolving paths\")\n\n    ################################################################################\n    # Check if any of the resolved paths are duplicates\n    ################################################################################\n    file_map = self._check_duplicates(file_map)\n    self.logger.info(\"Finished checking for duplicates\")\n\n    ################################################################################\n    # Handle files\n    ################################################################################\n    if dry_run:\n        self._dry_run(file_map)\n        return\n\n    with self._progress_bar() as progress_bar:\n        task_files = progress_bar.add_task(\n            \"Handling files\", total=len(file_map)\n        )\n        new_paths: List[Path | None] = []\n        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n            future_to_file = {\n                executor.submit(\n                    handle_file,\n                    source_path,\n                    resolved_path,\n                    action,\n                    overwrite,\n                ): source_path\n                for source_path, resolved_path in file_map.items()\n            }\n            for future in as_completed(future_to_file):\n                try:\n                    result = future.result()\n                    new_paths.append(result)\n                    progress_bar.update(task_files, advance=1)\n                except Exception as e:\n                    self.logger.exception(\n                        \"Failed to handle file\",\n                        exc_info=e,\n                        file=future_to_file[future],\n                    )\n</code></pre>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(action)","title":"<code>action</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(overwrite)","title":"<code>overwrite</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(dry_run)","title":"<code>dry_run</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(num_workers)","title":"<code>num_workers</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(truncate_uids)","title":"<code>truncate_uids</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.print_tree","title":"print_tree","text":"<pre><code>print_tree(base_dir: pathlib.Path | None = None) -&gt; None\n</code></pre> <p>Display the pattern structure as a tree visualization.</p> Notes <p>This only prints the target pattern, parsed and formatted. Performing a dry-run execute will display more information.</p> Source code in <code>src/imgtools/dicom/sort/sorter_base.py</code> <pre><code>def print_tree(self, base_dir: Path | None = None) -&gt; None:\n    \"\"\"\n    Display the pattern structure as a tree visualization.\n\n    Notes\n    -----\n    This only prints the target pattern, parsed and formatted.\n    Performing a dry-run execute will display more information.\n\n    Raises\n    ------\n    SorterBaseError\n        If the tree visualization fails to generate.\n    \"\"\"\n    try:\n        base_dir = base_dir or Path().cwd().resolve()\n        tree = self._setup_tree(base_dir)\n        self._generate_tree_structure(self.pattern_preview, tree)\n        self._console.print(tree)\n    except Exception as e:\n        errmsg = \"Failed to generate tree visualization.\"\n        raise SorterBaseError(errmsg) from e\n</code></pre>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.validate_keys","title":"validate_keys","text":"<pre><code>validate_keys() -&gt; None\n</code></pre> <p>Validate extracted keys. Subclasses should implement this method to perform specific validations based on their context.</p> <p>Validate the DICOM keys in the target pattern.</p> <p>If any invalid keys are found, it suggests similar valid keys and raises an error.</p> Source code in <code>src/imgtools/dicom/sort/dicomsorter.py</code> <pre><code>def validate_keys(self) -&gt; None:\n    \"\"\"Validate the DICOM keys in the target pattern.\n\n    If any invalid keys are found, it\n    suggests similar valid keys and raises an error.\n    \"\"\"\n    if not self.invalid_keys:\n        return\n\n    for key in sorted(self.invalid_keys):\n        # TODO: keep this logic, but make the suggestion more user-friendly/readable\n        similar = similar_tags(key)\n        suggestion = (\n            f\"\\n\\tDid you mean: [bold green]{', '.join(similar)}[/bold green]?\"\n            if similar\n            else \" And [bold red]no similar keys[/bold red] found.\"\n        )\n        _error = (\n            f\"Invalid DICOM key: [bold red]{key}[/bold red].{suggestion}\"\n        )\n        self._console.print(f\"{_error}\")\n    self._console.print(f\"Parsed Path: `{self.pattern_preview}`\")\n    errmsg = \"Invalid DICOM Keys found.\"\n    raise InvalidDICOMKeyError(errmsg)\n</code></pre>"},{"location":"reference/dicomsort/patternparser/","title":"PatternParser","text":""},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser","title":"parser","text":"<p>Parser module for extracting and validating placeholders from target patterns.</p> Summary <p>This module provides functionality to parse and validate sorting patterns with placeholders. Users can define custom regex patterns to extract keys from their sorting patterns.</p> Extended Summary <p>The <code>PatternParser</code> class allows users to define patterns with placeholders that can be replaced with actual values. The placeholders can be defined using custom regex patterns, making the parser flexible for various use cases.</p> <p>Examples:</p> <p>Setup:</p> <pre><code>&gt;&gt;&gt; import re\n&gt;&gt;&gt; from imgtools.dicom.sort.parser import (\n...     PatternParser,\n... )\n</code></pre> <p>Example 1: Suppose you want to parse a target pattern like <code>{Key1}-{Key2}</code> and replace the placeholders with values from a dictionary:</p> <pre><code>&gt;&gt;&gt; key_values = {\n...     \"Key1\": \"John\",\n...     \"Key2\": \"Doe\",\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; pattern = \"{Key1}-{Key2}\"\n&gt;&gt;&gt; pattern_matcher = re.compile(r\"\\{(\\w+)\\}\")\n&gt;&gt;&gt; parser = PatternParser(\n...     pattern,\n...     pattern_matcher,\n... )\n&gt;&gt;&gt; (\n...     formatted_pattern,\n...     keys,\n... ) = parser.parse()\n&gt;&gt;&gt; print(formatted_pattern)\n'%(Key1)s-%(Key2)s'\n&gt;&gt;&gt; print(keys)\n['Key1', 'Key2']\n</code></pre> <p>Now you can use the formatted pattern to replace the placeholders:</p> <pre><code>&gt;&gt;&gt; resolved_string = formatted_pattern % key_values\n&gt;&gt;&gt; print(resolved_string)\n'John-Doe'\n</code></pre> <p>Example 2: Suppose you want to parse a target pattern like <code>%&lt;Key1&gt; and {Key2}</code> and replace the placeholders with values from a dictionary:</p> <pre><code>&gt;&gt;&gt; key_values = {\n...     \"Key1\": \"Alice\",\n...     \"Key2\": \"Bob\",\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; pattern = \"%&lt;Key1&gt; and {Key2}\"\n&gt;&gt;&gt; pattern_matcher = re.compile(\n...     r\"%&lt;(\\w+)&gt;|\\{(\\w+)\\}\"\n... )\n&gt;&gt;&gt; parser = PatternParser(\n...     pattern,\n...     pattern_matcher,\n... )\n&gt;&gt;&gt; (\n...     formatted_pattern,\n...     keys,\n... ) = parser.parse()\n&gt;&gt;&gt; print(formatted_pattern)\n'%(Key1)s and %(Key2)s'\n&gt;&gt;&gt; print(keys)\n['Key1', 'Key2']\n</code></pre> <p>Now you can use the formatted pattern to replace the placeholders:</p> <pre><code>&gt;&gt;&gt; resolved_string = formatted_pattern % key_values\n&gt;&gt;&gt; print(resolved_string)\n'Alice and Bob'\n</code></pre> <p>Example 3: Suppose you want to parse a target pattern like <code>/path/to/{Key1}/and/{Key2}</code> and replace the placeholders with values from a dictionary:</p> <pre><code>&gt;&gt;&gt; key_values = {\n...     \"Key1\": \"folder1\",\n...     \"Key2\": \"folder2\",\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; pattern = \"/path/to/{Key1}/and/{Key2}\"\n&gt;&gt;&gt; pattern_matcher = re.compile(r\"\\{(\\w+)\\}\")\n&gt;&gt;&gt; parser = PatternParser(\n...     pattern,\n...     pattern_matcher,\n... )\n&gt;&gt;&gt; (\n...     formatted_pattern,\n...     keys,\n... ) = parser.parse()\n&gt;&gt;&gt; print(formatted_pattern)\n'/path/to/%(Key1)s/and/%(Key2)s'\n&gt;&gt;&gt; print(keys)\n['Key1', 'Key2']\n</code></pre> <p>Now you can use the formatted pattern to replace the placeholders:</p> <pre><code>&gt;&gt;&gt; resolved_string = formatted_pattern % key_values\n&gt;&gt;&gt; print(resolved_string)\n'/path/to/folder1/and/folder2'\n</code></pre>"},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser","title":"PatternParser","text":"<pre><code>PatternParser(\n    pattern: str, pattern_matcher: typing.Pattern\n)\n</code></pre> <p>A helper class to parse, validate, and sanitize sorting patterns.</p> <p>This class handles: - Pattern parsing and validation - Key extraction from patterns</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The pattern string to parse.</p> required <code>typing.Pattern</code> <p>Custom regex pattern for parsing</p> required <p>Attributes:</p> Name Type Description <code>keys</code> <code>list of str</code> <p>Extracted keys from the pattern.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import re\n&gt;&gt;&gt; from imgtools.dicom.sort.parser import (\n...     PatternParser,\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; key_values = {\n...     \"Key1\": \"Value1\",\n...     \"Key2\": \"Value2\",\n... }\n&gt;&gt;&gt; pattern = \"{Key1}-{Key2}\"\n&gt;&gt;&gt; pattern_matcher = re.compile(r\"\\{(\\w+)\\}\")\n&gt;&gt;&gt; parser = PatternParser(\n...     pattern,\n...     pattern_matcher,\n... )\n&gt;&gt;&gt; (\n...     formatted_pattern,\n...     keys,\n... ) = parser.parse()\n&gt;&gt;&gt; print(formatted_pattern)\n'%(Key1)s-%(Key2)s'\n&gt;&gt;&gt; print(keys)\n['Key1', 'Key2']\n&gt;&gt;&gt; resolved_string = formatted_pattern % key_values\n&gt;&gt;&gt; print(resolved_string)\n'Value1-Value2'\n</code></pre> <p>Methods:</p> Name Description <code>parse</code> <p>Parse and validate the pattern.</p> Source code in <code>src/imgtools/pattern_parser/parser.py</code> <pre><code>def __init__(self, pattern: str, pattern_matcher: Pattern) -&gt; None:\n    assert isinstance(pattern, str) and pattern, (\n        \"Pattern must be a non-empty string.\"\n    )\n    self._pattern = pattern\n    self._keys: List[str] = []\n    assert isinstance(pattern_matcher, Pattern), (\n        \"Pattern parser must be a regex pattern.\"\n    )\n    self._parser: Pattern = pattern_matcher\n</code></pre>"},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser(pattern)","title":"<code>pattern</code>","text":""},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser(pattern_matcher)","title":"<code>pattern_matcher</code>","text":""},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser.keys","title":"keys  <code>property</code>","text":"<pre><code>keys: typing.List[str]\n</code></pre> <p>Get the list of extracted keys.</p>"},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser.parse","title":"parse","text":"<pre><code>parse() -&gt; typing.Tuple[str, typing.List[str]]\n</code></pre> <p>Parse and validate the pattern.</p> <p>Returns:</p> Type Description <code>typing.Tuple[str, typing.List[str]]</code> <p>The formatted pattern string and a list of extracted keys.</p> Source code in <code>src/imgtools/pattern_parser/parser.py</code> <pre><code>def parse(self) -&gt; Tuple[str, List[str]]:\n    \"\"\"\n    Parse and validate the pattern.\n\n    Returns\n    -------\n    Tuple[str, List[str]]\n        The formatted pattern string and a list of extracted keys.\n\n    Raises\n    ------\n    InvalidPatternError\n        If the pattern contains no valid placeholders or is invalid.\n    \"\"\"\n\n    sanitized_pattern = self._pattern.strip()\n    if not self._parser.search(sanitized_pattern):\n        errmsg = f\"Pattern must contain placeholders matching '{self._parser.pattern}'.\"\n        raise InvalidPatternError(errmsg)\n\n    formatted_pattern = self._parser.sub(\n        self._replace_key, sanitized_pattern\n    )\n    return formatted_pattern, self._keys\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>The following documentation is a work-in-progress. If you encounter any issues or discrepencies, please let us know by opening an issue.</p>"},{"location":"usage/Writers/BaseWriter/","title":"Abstract Base Writer","text":"<p>The <code>AbstractBaseWriter</code> class is the foundation for all writers in this library.</p> <p>It provides a standard interface, reusable methods, and tools that writers can extend to handle file writing tasks efficiently and consistently.</p> <p>If you're building a writer to manage file outputs with custom paths, filenames, or formats, this is where you start!</p> <p>For details on implementing the <code>AbstractBaseWriter</code> in your custom writer, see the Implementing Writers guide.</p>"},{"location":"usage/Writers/BaseWriter/#introduction","title":"Introduction","text":""},{"location":"usage/Writers/BaseWriter/#what-is-the-abstractbasewriter","title":"What is the <code>AbstractBaseWriter</code>?","text":"<p>The <code>AbstractBaseWriter</code> is:</p> <ul> <li>A reusable template: Manage file-writing tasks consistently across different writer implementations.  </li> <li>Customizable: Extend it to handle your file formats and workflows.  </li> <li>Safe and robust: Features context management, filename sanitization, and optional CSV indexing.  </li> </ul>"},{"location":"usage/Writers/BaseWriter/#when-should-you-extend-abstractbasewriter-for-your-custom-writer","title":"When should you extend <code>AbstractBaseWriter</code> for your custom writer?","text":"<p>If you write many files with dynamic paths and filenames, or need to manage file existence scenarios, you might consider extending <code>AbstractBaseWriter</code> (or even one of its subclasses) to simplify your implementation.</p> <p><code>AbstractBaseWriter</code> is useful when you need:</p> <ul> <li>Dynamic paths and filenames (e.g., <code>{subject_id}/{study_date}.nii.gz</code>).  </li> <li>Configurable handling of existing files (<code>OVERWRITE</code>, <code>SKIP</code>, etc.).  </li> <li>Logging of saved files via an optional CSV index.  </li> <li>Thread-safe and multiprocessing-compatible file writing.  </li> <li>A consistent interface across different types of writers.  </li> </ul>"},{"location":"usage/Writers/BaseWriter/#core-concepts","title":"Core Concepts","text":""},{"location":"usage/Writers/BaseWriter/#root-directory-and-filename-format-parameters","title":"Root Directory and Filename Format Parameters","text":"<p>Root Directory:</p> <ul> <li>Base folder for all saved files, automatically created if missing (via <code>create_dirs</code> parameter)</li> </ul> <p>Filename Format:</p> <ul> <li>A string template defining your file and folder names.  </li> <li>Uses placeholders like <code>{key}</code> to insert context values dynamically.  </li> </ul> <p>Example:</p> <pre><code>writer = ExampleWriter(\n    root_directory=\"./data\",\n    filename_format=\"{person_name}/{date}_{message_type}.txt\",\n)\n\n# Save a file with context variables\ndata = \"Hello, World!\"\nwriter.save(\n  data, \n  person_name=\"JohnDoe\",\n  date=\"2025-01-01\",\n  message_type=\"greeting\"\n)\n\n# Saved file path: \n# ./data/JohnDoe/2025-01-01_greeting.txt\n</code></pre>"},{"location":"usage/Writers/BaseWriter/#file-existence-modes","title":"File Existence Modes","text":"<p>Why It Matters:</p> <ul> <li>When your writer saves a file, it needs to decide what to do if a file with the same name already exists.</li> <li>This is especially important in batch operations or when writing to shared directories.</li> <li>The <code>AbstractBaseWriter</code> provides several options to handle this scenario through the use of   an <code>enum</code> called <code>ExistingFileMode</code>.</li> </ul> <p>It is important to handle these options carefully in your writer's <code>save()</code> method to avoid data loss or conflicts.</p>"},{"location":"usage/Writers/BaseWriter/#imgtools.io.writers.ExistingFileMode","title":"ExistingFileMode","text":"<p>               Bases: <code>str</code>, <code>enum.Enum</code></p> <p>Enum to specify handling behavior for existing files.</p> <p>Attributes:</p> Name Type Description <code>OVERWRITE</code> <code>str</code> <p>Overwrite the existing file. Logs as debug and continues with the operation.</p> <code>FAIL</code> <code>str</code> <p>Fail the operation if the file exists. Logs as error and raises a FileExistsError.</p> <code>SKIP</code> <code>str</code> <p>Skip the operation if the file exists. Meant to be used for previewing the path before any expensive computation. <code>preview_path()</code> will return None if the file exists. <code>resolve_path()</code> will still return the path even if the file exists. The writer's <code>save</code> method should handle the file existence if set to SKIP.</p>"},{"location":"usage/Writers/BaseWriter/#advanced-concepts","title":"Advanced Concepts","text":""},{"location":"usage/Writers/BaseWriter/#lifecycle-management","title":"Lifecycle Management","text":"<p>Context Manager Support:</p> <ul> <li>Writers can be used with <code>with</code> statements to ensure proper setup and cleanup.  </li> </ul> <p>What Happens on Exit?:</p> <ul> <li>Removes lock files used for the index file.  </li> <li>Deletes empty directories created during the writing process (if no files were written).  </li> </ul> <p>Example:</p> <pre><code>with TextWriter(root_directory=\"/data\", filename_format=\"{id}.txt\") as writer:\n  data = \"Hello, World!\"\n  writer.save(data, id=\"1234\")\n</code></pre>"},{"location":"usage/Writers/BaseWriter/#previewing-file-paths-and-caching-context","title":"Previewing File Paths and Caching Context","text":"<p>In the simplest usage of a writer, users can pass in the context information as keyword arguments to each <code>save()</code> call.</p> <p>However, this can become cumbersome when the same context variables are used across multiple save operations.</p> <p>Example:</p> <p>In the above example, the <code>date</code> and <code>message_type</code> context variables are the same for all students. Instead of passing them in every time, you can store these variables in the writer itself and update them as needed.</p> <p>Let's use the following example to illustrate this:</p> <p>Say we want to save greetings for students in a particular highschool class:</p> <pre><code>writer = TextWriter(\n    root_directory=\"./data\",\n    filename_format=\"{grade}/{class_subject}/{person_name}/{date}_{message_type}.txt\",\n)\n</code></pre> Basic UsageSetting Context Variables manuallySetting Context Variables during Initialization <p>We see here that the context variables for <code>grade</code>, <code>class_subject</code>, <code>date</code>, and <code>message_type</code> are the same for all students.</p> <p>This can become even worse with more context variables, allowing for mistakes, and making the code harder to read.</p> <pre><code>student, message = \"Alice\", \"Hello, Alice!\"\nwriter.save(\n    message,\n    person_name=student,\n    grade=\"12\",\n    class_subject=\"math\",\n    date=\"2025-01-01\",\n    message_type=\"greeting\"\n)\n\nstudent, message = \"Bob\", \"Good morning, Bob!\"\nwriter.save(\n    message,\n    person_name=student,\n    grade=\"12\",\n    class_subject=\"math\",\n    date=\"2025-01-01\",\n    message_type=\"greeting\"\n)\n</code></pre> <p>Instead of passing in the context variables every time, you can store these variables in the writer and update them as needed using the <code>set_context()</code> method.</p> <p>Then only pass in the unique context variables for each <code>.save()</code> operation.</p> <pre><code>writer.set_context(\n  grade=\"12\",\n  class_subject=\"math\",\n  date=\"2025-01-01\",\n  message_type=\"greeting\"\n)\n\nstudent, message = \"Alice\", \"Hello, Alice!\"\nwriter.save(message, person_name=student)\n\nstudent, message = \"Bob\", \"Good morning, Bob!\"\nwriter.save(message, person_name=student)\n</code></pre> <p>If majority of the context variables are the same across all save  operations, you can set context when initializing the writer.</p> <p>Note that here, we must pass as a dictionary to the <code>context</code> parameter  instead of individual keyword arguments.</p> <pre><code>writer = TextWriter(\n    root_directory=\"./data\",\n    filename_format=\"{class_subject}/{person_name}/{date}_{message_type}.txt\",\n    context={\"grade\": \"12\", \"class_subject\": \"math\", \"date\": \"2025-01-01\", \"message_type\": \"greeting\"}\n)\n\nstudent, message = \"Alice\", \"Hello, Alice!\"\nwriter.save(message, person_name=student)\n\nstudent, message = \"Bob\", \"Good morning, Bob!\"\nwriter.save(message, person_name=student)\n</code></pre>"},{"location":"usage/Writers/BaseWriter/#previewing-file-paths","title":"Previewing File Paths","text":"<p>Oftentimes, you may want to check if a file exists before performing an expensive computation. If you set the existence mode to <code>ExistingFileMode.SKIP</code>, the <code>preview_path()</code> method will return <code>None</code> if the file already exists, allowing you to skip the computation.</p> <p>This method also caches the additional context variables for future use.</p> <p>Here's an example of how you might handle this:</p> <pre><code># assuming writer is already initialized with `existing_file_mode=ExistingFileMode.SKIP`\n\n# set some context variables\nwriter.set_context(class_subject=\"math\", date=\"2025-01-01\", message_type=\"greeting\")\n\nif (path := writer.preview_path(person_name=\"Alice\")) is None:\n    print(\"File already exists, skipping computation.\")\nelse:\n    print(f\"Proceed with computation for {path}\")\n    ... \n    # perform expensive computation \n    ...\n    writer.save(content=\"Hello, world!\")\n</code></pre>"},{"location":"usage/Writers/BaseWriter/#index-file-management","title":"Index File Management","text":"<p>What is the Index File?:</p> <ul> <li>A CSV file used to log details about saved files, like their paths and context variables.  </li> <li>Helps track what files have been written, especially useful in batch operations.</li> <li>Additionally can save all the context variables used for each file, convienient for   saving additional metadata, while improving traceability.</li> </ul> <p>How It Works:</p> <ul> <li>The AbstractBaseWriter now uses the powerful <code>IndexWriter</code> class to handle all index operations</li> <li>By default, the index file is named <code>{root_directory.name}_index.csv</code></li> <li>You can customize the filename or provide an absolute path for more control</li> <li>When implementing a writer class, call <code>add_to_index(path)</code> in your <code>save()</code> method to record saved files</li> </ul> <p>Key Features:</p> <ul> <li>Customizable Filename: Use <code>index_filename</code> to set a custom name or absolute path.</li> <li>Absolute/Relative Paths: Control file paths in the index with <code>absolute_paths_in_index</code> (defaults to relative).</li> <li>Schema Evolution: Control schema evolution with the <code>merge_columns</code> parameter when calling <code>add_to_index()</code>.</li> <li>Safe Concurrent Access: Uses inter-process locking for thread-safe operations in multi-process environments.</li> <li>Robust Error Handling: Specific exceptions for index-related errors to help troubleshoot issues.</li> </ul> <p>Using the add_to_index Method:</p> <pre><code># In your writer's save method:\ndef save(self, content, **kwargs):\n    output_path = self.resolve_path(**kwargs)\n\n    # Write your content to the file...\n\n    # Record this file in the index, with optional parameters:\n    self.add_to_index(\n        path=output_path,\n        include_all_context=True,   # Include all context variables, not just those used in the filename\n        filepath_column=\"path\",     # Name of the column to store file paths\n        replace_existing=False,     # Whether to replace existing entries for the same file\n        merge_columns=True          # Whether to allow schema evolution\n    )\n\n    return output_path\n</code></pre> <p>Schema Evolution with merge_columns:</p> <p>The <code>merge_columns</code> parameter (defaults to <code>True</code>) controls how the IndexWriter handles changes to your data schema:</p> <ul> <li>When <code>True</code>: If your context has new fields that didn't exist in previous CSV entries, they'll be added as new columns. This is great for:</li> <li>Iterative development when you're adding new metadata fields</li> <li>Different processes writing files with slightly different context variables</li> <li> <p>Ensuring backward compatibility with existing index files</p> </li> <li> <p>When <code>False</code>: Strict schema enforcement is applied. The IndexWriter will raise an error if the columns don't match exactly what's already in the index file. This is useful when:</p> </li> <li>You want to enforce a consistent schema across all entries</li> <li>You're concerned about typos or unintended fields creeping into your index</li> <li>Data consistency is critical for downstream processing</li> </ul>"},{"location":"usage/Writers/BaseWriter/#sanitizing-filenames","title":"Sanitizing Filenames","text":"<p>Why Sanitize Filenames?:</p> <ul> <li>To ensure that filenames are safe and compatible across different operating systems.  </li> </ul> <p>How It Works:</p> <ul> <li>Replaces illegal characters (e.g., <code>&lt;</code>, <code>&gt;</code>, <code>:</code>, <code>\"</code>, <code>/</code>, <code>\\</code>, <code>|</code>, <code>?</code>, <code>*</code>) with underscores.  </li> <li>Trims leading or trailing spaces and periods to avoid issues.</li> </ul> <p>When Is It Applied?:</p> <ul> <li>Automatically applied when generating filenames, unless disabled by setting <code>sanitize_filenames=False</code>.</li> </ul>"},{"location":"usage/Writers/BaseWriter/#multiprocessing-compatibility","title":"Multiprocessing Compatibility","text":"<p>Why It Matters:</p> <ul> <li>In batch operations or high-performance use cases, multiple processes may write files simultaneously.  </li> </ul> <p>Key Features:</p> <ul> <li>Supports multiprocessing with inter-process locking to ensure thread-safe file writes.  </li> <li>Avoids conflicts or data corruption when multiple instances of a writer are running.</li> </ul>"},{"location":"usage/Writers/ImplementingWriters/","title":"Extending the <code>AbstractBaseWriter</code> class","text":"<p>The <code>AbstractBaseWriter</code> is designed to be extended, allowing you to create custom writers tailored to your specific needs. This guide will walk you through the steps to extend the class and implement your custom functionality.</p>"},{"location":"usage/Writers/ImplementingWriters/#setting-up-your-writer","title":"Setting Up Your Writer","text":"<p>To create a custom writer, you need to extend the <code>AbstractBaseWriter</code> and implement the <code>save</code> method. This method is the core of your writer, handling how and where data is saved.</p> <p>For a walkthrough of all key methods and features, see the Key Methods section below.</p>"},{"location":"usage/Writers/ImplementingWriters/#steps-to-set-up","title":"Steps to Set Up","text":"<ol> <li> <p>Inherit from <code>AbstractBaseWriter</code>:    Create a new class and extend <code>AbstractBaseWriter</code> with the appropriate type.    If you are saving text data, use <code>AbstractBaseWriter[str]</code>, for example.    If you are saving image data, use <code>AbstractBaseWriter[sitk.Image]</code>.</p> </li> <li> <p>Define the <code>save</code> Method:   Use <code>resolve_path()</code> or <code>preview_path()</code> to generate file paths.   Implement the logic for saving data.  </p> </li> <li> <p>Customize Behavior (Optional):   Override any existing methods for specific behavior.   Add additional methods or properties to enhance functionality.  </p> </li> </ol>"},{"location":"usage/Writers/ImplementingWriters/#simple-example","title":"Simple Example","text":"<pre><code>from pathlib import Path\nfrom imgtools.io import AbstractBaseWriter\n\nclass MyCustomWriter(AbstractBaseWriter[str]):\n    def save(self, content: str, **kwargs) -&gt; Path:\n        # Resolve the output file path\n        output_path = self.resolve_path(**kwargs)\n\n        # Write content to the file\n        with output_path.open(mode=\"w\", encoding=\"utf-8\") as f:\n            f.write(content)\n\n        # Log and track the save operation using the new IndexWriter\n        self.add_to_index(output_path)\n\n        return output_path\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#implementing-the-save-method","title":"Implementing the <code>save</code> Method","text":"<p>The <code>save</code> method is the heart of your custom writer. It determines how data is written to files and interacts with the core features of <code>AbstractBaseWriter</code>.</p>"},{"location":"usage/Writers/ImplementingWriters/#key-responsibilities-of-save","title":"Key Responsibilities of <code>save</code>","text":"<ol> <li> <p>Path Resolution:</p> <ul> <li>Use <code>resolve_path()</code> to dynamically generate file paths based on the provided     context and filename format.</li> <li>You can optionally use <code>preview_path()</code> as well.</li> <li>Ensure paths are validated to prevent overwriting or duplication.</li> </ul> </li> <li> <p>Data Writing:  </p> <ul> <li>Define how the content will be written to the resolved path.  </li> <li>Use file-handling best practices to ensure reliability.</li> </ul> </li> <li> <p>Logging and Tracking:  </p> <ul> <li>Log each save operation for debugging or auditing purposes.  </li> <li>Use <code>add_to_index()</code> to maintain a record of saved files and their associated     context variables.</li> </ul> </li> <li> <p>Return Value:  </p> <ul> <li>Return the <code>Path</code> object representing the saved file.  </li> <li>This allows users to access the file path for further processing or verification.</li> </ul> </li> </ol>"},{"location":"usage/Writers/ImplementingWriters/#example-implementation","title":"Example Implementation","text":"<p>Here's a minimal implementation of the <code>save</code> method for a custom writer.</p> <pre><code>from pathlib import Path\nfrom mypackage.abstract_base_writer import AbstractBaseWriter\n\nclass MyCustomWriter(AbstractBaseWriter[str]):\n    def save(self, content: str, **kwargs) -&gt; Path:\n        # Step 1: Resolve the output file path\n        # you can try-catch this in case set to \"FAIL\" mode\n        # or just let the error propagate\n        output_path = self.resolve_path(**kwargs) # resolve_path will always return the path\n\n        # OPTIONAL handling for \"SKIP\" modes\n        if output_path.exists():\n            # this will only be true if the file existence mode\n            # is set to SKIP\n            # - OVERWRITE will have already deleted the file\n            # - upto developer to choose to handle this if set to SKIP\n            pass\n\n        # Step 2: Write the content to the resolved path\n        with output_path.open(mode=\"w\", encoding=\"utf-8\") as f:\n            f.write(content)\n\n        # Step 3: Log and track the save operation\n        self.add_to_index(\n            path=output_path,\n            include_all_context=True,\n            filepath_column=\"filepath\", \n            replace_existing=False,\n            merge_columns=True,\n        )\n\n        # Step 4: ALWAYS Return the saved file path\n        return output_path\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#key-methods","title":"Key Methods","text":"<p>The <code>AbstractBaseWriter</code> provides several utility methods that simplify file writing and context management. These methods are designed to be flexible and reusable, allowing you to focus on your custom implementation.</p>"},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.resolve_path","title":"resolve_path","text":"<pre><code>resolve_path(**kwargs: object) -&gt; pathlib.Path\n</code></pre> <p>Generate a file path based on the filename format, subject ID, and additional parameters.</p> <p>Meant to be used by developers when creating a new writer class and used internally by the <code>save</code> method.</p> <p>What It Does:</p> <ul> <li>Dynamically generates a file path based on the provided context and filename format.</li> </ul> <p>When to Use It:</p> <ul> <li>This method is meant to be used in the <code>save</code> method to determine the file\u2019s target location, but can also be used by external code to generate paths.</li> <li>It ensures you\u2019re working with a valid path and can handle file existence scenarios.</li> <li>Only raises <code>FileExistsError</code> if the file already exists and the mode is set to <code>FAIL</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>typing.Any</code> <p>Parameters for resolving the filename and validating existence.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>resolved_path</code> <code>pathlib.Path</code> <p>The resolved path for the file.</p> Source code in <code>src/imgtools/io/writers/abstract_base_writer.py</code> <pre><code>def resolve_path(self, **kwargs: object) -&gt; Path:\n    \"\"\"\n    Generate a file path based on the filename format, subject ID, and\n    additional parameters.\n\n    Meant to be used by developers when creating a new writer class\n    and used internally by the `save` method.\n\n    **What It Does**:\n\n    - Dynamically generates a file path based on the provided context and\n    filename format.\n\n    **When to Use It**:\n\n    - This method is meant to be used in the `save` method to determine the\n    file\u2019s target location, but can also be used by external code to\n    generate paths.\n    - It ensures you\u2019re working with a valid path and can handle file\n    existence scenarios.\n    - Only raises `FileExistsError` if the file already exists and the mode\n    is set to `FAIL`.\n\n    Parameters\n    ----------\n    **kwargs : Any\n        Parameters for resolving the filename and validating existence.\n\n    Returns\n    -------\n    resolved_path: Path\n        The resolved path for the file.\n\n    Raises\n    ------\n    FileExistsError\n        If the file already exists and the mode is set to FAIL.\n    \"\"\"\n    out_path = self._generate_path(**kwargs)\n    if not out_path.exists():\n        if self.create_dirs:\n            self._ensure_directory_exists(out_path.parent)\n        # should we raise this error here?\n        # elif not out_path.parent.exists():\n        #     msg = f\"Directory {out_path.parent} does not exist.\"\n        #     raise DirectoryNotFoundError(msg)\n        return out_path\n    match self.existing_file_mode:\n        case ExistingFileMode.SKIP:\n            return out_path\n        case ExistingFileMode.FAIL:\n            msg = f\"File {out_path} already exists.\"\n            raise FileExistsError(msg)\n        case ExistingFileMode.OVERWRITE:\n            logger.debug(f\"Deleting existing {out_path} and overwriting.\")\n            out_path.unlink()\n            return out_path\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.resolve_path(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.preview_path","title":"preview_path","text":"<pre><code>preview_path(\n    **kwargs: object,\n) -&gt; typing.Optional[pathlib.Path]\n</code></pre> <p>Pre-checking file existence and setting up the writer context.</p> <p>Meant to be used by users to skip expensive computations if a file already exists and you dont want to overwrite it. Only difference between this and resolve_path is that this method does not return the path if the file exists and the mode is set to <code>SKIP</code>.</p> <p>This is because the <code>.save()</code> method should be able to return the path even if the file exists.</p> <p>What It Does:</p> <ul> <li>Pre-checks the file path based on context without writing the file.</li> <li>Returns <code>None</code> if the file exists and the mode is set to <code>SKIP</code>.</li> <li>Raises a <code>FileExistsError</code> if the mode is set to <code>FAIL</code>.</li> <li>An added benefit of using <code>preview_path</code> is that it automatically caches the context variables for future use, and <code>save()</code> can be called without passing in the context variables again.</li> </ul> <p>Examples:</p> <p>Main idea here is to allow users to save computation if they choose to skip existing files.</p> <p>i.e. if file exists and mode is <code>SKIP</code>, we return <code>None</code>, so the user can skip the computation.</p> <pre><code>&gt;&gt;&gt; if nifti_writer.preview_path(subject=\"math\", name=\"test\") is None:\n&gt;&gt;&gt;     logger.info(\"File already exists. Skipping computation.\")\n&gt;&gt;&gt;     continue # could be `break` or `return` depending on the use case\n</code></pre> <p>if the mode is <code>FAIL</code>, we raise an error if the file exists, so user doesnt have to perform expensive computation only to fail when saving.</p> Useful Feature <p>The context is saved in the instance, so running <code>.save()</code> after this will use the same context, and user can optionally update the context with new values passed to <code>.save()</code>.</p> <p><pre><code>&gt;&gt;&gt; if path := writer.preview_path(subject=\"math\", name=\"test\"):\n&gt;&gt;&gt;     ... # do some expensive computation to generate the data\n&gt;&gt;&gt;     writer.save(data)\n</code></pre> <code>.save()</code> automatically uses the context for <code>subject</code> and <code>name</code> we passed to <code>preview_path</code></p> <p>Parameters:</p> Name Type Description Default <code>typing.Any</code> <p>Parameters for resolving the filename and validating existence.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pathlib.Path | None</code> <p>If the file exists and the mode is <code>SKIP</code>, returns <code>None</code>. if the file exists and the mode is FAIL, raises a <code>FileExistsError</code>. If the file exists and the mode is OVERWRITE, logs a debug message and returns the path.</p> Source code in <code>src/imgtools/io/writers/abstract_base_writer.py</code> <pre><code>def preview_path(self, **kwargs: object) -&gt; Optional[Path]:\n    \"\"\"\n    Pre-checking file existence and setting up the writer context.\n\n    Meant to be used by users to skip expensive computations if a file\n    already exists and you dont want to overwrite it.\n    Only difference between this and resolve_path is that this method\n    does not return the path if the file exists and the mode is set to\n    `SKIP`.\n\n    This is because the `.save()` method should be able to return\n    the path even if the file exists.\n\n    **What It Does**:\n\n    - Pre-checks the file path based on context without writing the file.\n    - Returns `None` if the file exists and the mode is set to `SKIP`.\n    - Raises a `FileExistsError` if the mode is set to `FAIL`.\n    - An added benefit of using `preview_path` is that it automatically\n    caches the context variables for future use, and `save()` can be called\n    without passing in the context variables again.\n\n    Examples\n    --------\n\n    Main idea here is to allow users to save computation if they choose to\n    skip existing files.\n\n    i.e. if file exists and mode is **`SKIP`**, we return\n    `None`, so the user can skip the computation.\n    &gt;&gt;&gt; if nifti_writer.preview_path(subject=\"math\", name=\"test\") is None:\n    &gt;&gt;&gt;     logger.info(\"File already exists. Skipping computation.\")\n    &gt;&gt;&gt;     continue # could be `break` or `return` depending on the use case\n\n    if the mode is **`FAIL`**, we raise an error if the file exists, so user\n    doesnt have to perform expensive computation only to fail when saving.\n\n    **Useful Feature**\n    ----------------------\n    The context is saved in the instance, so running\n    `.save()` after this will use the same context, and user can optionally\n    update the context with new values passed to `.save()`.\n\n    ```python\n    &gt;&gt;&gt; if path := writer.preview_path(subject=\"math\", name=\"test\"):\n    &gt;&gt;&gt;     ... # do some expensive computation to generate the data\n    &gt;&gt;&gt;     writer.save(data)\n    ```\n    `.save()` automatically uses the context for `subject` and `name` we\n    passed to `preview_path`\n\n    Parameters\n    ----------\n    **kwargs : Any\n        Parameters for resolving the filename and validating existence.\n\n    Returns\n    ------\n    Path | None\n        If the file exists and the mode is `SKIP`, returns `None`. if the file\n        exists and the mode is FAIL, raises a `FileExistsError`. If the file\n        exists and the mode is OVERWRITE, logs a debug message and returns\n        the path.\n\n    Raises\n    ------\n    FileExistsError\n        If the file exists and the mode is FAIL.\n    \"\"\"\n    out_path = self._generate_path(**kwargs)\n\n    if not out_path.exists():\n        return out_path\n    elif out_path.is_dir():\n        msg = f\"Path {out_path} is already a directory that exists.\"\n        msg += \" Use a different filename format or context to avoid this.\"\n        raise IsADirectoryError(msg)\n\n    match self.existing_file_mode:\n        case ExistingFileMode.SKIP:\n            return None\n        case ExistingFileMode.FAIL:\n            msg = f\"File {out_path} already exists.\"\n            raise FileExistsError(msg)\n        case ExistingFileMode.OVERWRITE:\n            logger.debug(\n                f\"File {out_path} exists. Deleting and overwriting.\"\n            )\n            out_path.unlink()\n\n    return out_path\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.preview_path(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.clear_context","title":"clear_context","text":"<pre><code>clear_context() -&gt; None\n</code></pre> <p>Clear the context for the writer.</p> <p>Useful for resetting the context after using <code>preview_path</code> or <code>save</code> and want to make sure that the context is empty for new operations.</p> Source code in <code>src/imgtools/io/writers/abstract_base_writer.py</code> <pre><code>def clear_context(self) -&gt; None:\n    \"\"\"\n    Clear the context for the writer.\n\n    Useful for resetting the context after using `preview_path` or `save`\n    and want to make sure that the context is empty for new operations.\n    \"\"\"\n    self.context.clear()\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#add_to_index","title":"add_to_index","text":"<p>What It Does:</p> <ul> <li>Records file information in a centralized CSV index file using the powerful IndexWriter</li> <li>Safely handles concurrent writes with inter-process locking</li> <li>Supports schema evolution to handle changing metadata fields</li> </ul> <p>When to Use It:</p> <ul> <li>Call this method from your <code>save()</code> implementation to track files</li> <li>Great for batch operations where you need to maintain records of processed files</li> </ul> <p>Usage Example:</p> <pre><code>def save(self, content, **kwargs):\n    path = self.resolve_path(**kwargs)\n    # ... write content to file ...\n\n    # Add entry to index with all context variables\n    self.add_to_index(\n        path=path,\n        include_all_context=True,  # Include ALL context vars (not just those in filename)\n        filepath_column=\"path\",    # Column name for file paths\n        replace_existing=False     # Whether to replace existing entries\n    )\n\n    return path\n</code></pre> <p>Important Parameters:</p> <ul> <li><code>include_all_context</code>: Controls whether to save all context variables or only those used in the filename</li> <li><code>filepath_column</code>: Customizes the column name for file paths</li> <li><code>replace_existing</code>: Whether to replace or append entries for the same file</li> </ul> <p>Error Handling:</p> <p>The method uses robust error handling with specific exceptions like <code>WriterIndexError</code> that wrap any underlying IndexWriter errors, making troubleshooting easier.</p> <p>What It Does:</p> <ul> <li>A helper method for resolving file paths based on the current context and   filename format.  </li> <li>Automatically sanitizes filenames if <code>sanitize_filenames=True</code>.</li> </ul> <p>When to Use It:</p> <ul> <li>Typically called internally by <code>resolve_path()</code> and <code>preview_path()</code>, which handle   additional validation and error handling.</li> <li>Can be called by your class methods to generate paths without the additional   context checks.</li> </ul> <p>Example:</p> <pre><code>custom_path = writer._generate_path(subject=\"math\", name=\"example\")\nprint(f\"Generated path: {custom_path}\")\n</code></pre> <p>By using these key methods effectively, you can customize your writer to handle a wide range of file-writing scenarios while maintaining clean and consistent logic.</p>"},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter._generate_path","title":"_generate_path","text":"<pre><code>_generate_path(**kwargs: object) -&gt; pathlib.Path\n</code></pre> <p>Helper for resolving paths with the given context.</p> Source code in <code>src/imgtools/io/writers/abstract_base_writer.py</code> <pre><code>def _generate_path(self, **kwargs: object) -&gt; Path:\n    \"\"\"\n    Helper for resolving paths with the given context.\n    \"\"\"\n    save_context = {\n        **self.context,\n        **kwargs,\n        \"saved_time\": datetime.now(timezone.utc).strftime(\n            \"%Y-%m-%d:%H-%M-%S\"\n        ),\n    }\n    self.set_context(**save_context)\n    try:\n        filename = self.pattern_resolver.resolve(save_context)\n    except MissingPlaceholderValueError as e:\n        # Replace the class name in the error message dynamically\n        raise MissingPlaceholderValueError(\n            e.missing_keys,\n            class_name=self.__class__.__name__,\n            key=e.key,\n        ) from e\n    if self.sanitize_filenames:\n        filename = self._sanitize_filename(filename)\n    out_path = self.root_directory / filename\n    # logger.debug(\n    #     f\"Resolved path: {out_path} and {out_path.exists()=}\",\n    #     handling=self.existing_file_mode,\n    # )\n    return out_path\n</code></pre>"},{"location":"usage/crawl_interlacer/crawler/","title":"Crawler","text":"<p>The <code>Crawler</code> in Med-ImageTools has the core responsibility of walking through a directory and collecting all the dicom files (<code>.dcm</code>/<code>.DCM</code>), regardless of the directory structure. </p> <p>It was designed to extract as much information as possible from the files, to build an internal database of the data users have.</p>"},{"location":"usage/crawl_interlacer/crawler/#metadata-extraction","title":"Metadata extraction","text":"<p>As of the 2.0 release, the crawler implements a modality-specific set of extractions which facilitate raw extraction of a DICOM tag (i.e <code>SeriesInstanceUID</code>) as well as a 'ComputedValue' which requires computation on one or more tags (i.e <code>ROINames</code> in <code>RTSTRUCT</code> files are computed from the <code>ROIContourSequence</code> tag).</p> <p>This is done using the ModalityMedataExtractor base class, which defines the <code>base_tags</code> that are common to all modalities, and the <code>computed_tags</code> which sub-classes can implement to extract modality-specific information on top of their own <code>modality_tags</code>.</p> <p>See the following:</p> <ul> <li>CTMetadataExtractor</li> <li>MRMetadataExtractor</li> <li>PTMetadataExtractor</li> <li>SEGMetadataExtractor</li> <li>RTSTRUCTMetadataExtractor</li> <li>RTDOSEMetadataExtractor</li> <li>RTPLANMetadataExtractor</li> <li>SRMetadataExtractor</li> </ul> <p>For each of the above modalities, there is a <code>modality_tags</code> property that returns a set of tags that can be directly extracted from the DICOM file. There also may be a <code>computed_tags</code> property that returns a mapping of  keys defined by Med-ImageTools (i.e <code>SegSpacing</code> in the <code>SEG</code> extractor) to a callable function that will compute the value from the DICOM file.</p>"},{"location":"usage/crawl_interlacer/crawler/#assumptions-made-when-crawling","title":"Assumptions made when crawling","text":"<p>As of 2.0, the crawler makes the following assumptions:</p> <ol> <li> <p>All DICOM files within the specified input directory are valid DICOM files.     That is, they all contain a valid DICOM header and can be read by pydicom.</p> </li> <li> <p>All DICOM files belonging to the same series are in the same directory.     This assumption is made, to simplify pointing to a series of files, by      just pointing to the directory containing the files.</p> <p>Note</p> <p>Though we require that all files in a series are in the same directory, we do not require that all files in a directory belong to the same series. That is, a directory may contain files from multiple series, and the crawler will still be able to extract the series information from each file.</p> </li> </ol>"},{"location":"usage/crawl_interlacer/crawler/#reference-building","title":"Reference building","text":"<p>One of the main features of Med-ImageTools is building the internal database of all the complex relationships between DICOM series. The first step in this process is to extract the necessary information from each DICOM file, which is modality-specific, and given the evolution of the DICOM standard, may change over time.</p> <p>For example, while modern <code>RTSTRUCT</code> files contain a <code>RTReferencedSeriesSequence</code> tag that references the <code>SeriesInstanceUID</code> of the series that the structure was derived from, this is not always present in older files. As such, we have to rely on the <code>ReferencedSOPInstanceUID</code> tag, which is a unique identifier for all the files in the Referenced Series.</p> <p>During the crawling process, we also build a database that maps each found DICOM file to its corresponding series <code>SOPInstanceUID -&gt; SeriesInstanceUID</code>.</p> <p>If the <code>RTSTRUCT</code> file does not contain the <code>RTReferencedSeriesSequence</code>, we use all the <code>ReferencedSOPInstanceUID</code> tags in the file to find the corresponding seires using the mapping.</p> <p>After a successful crawl, the <code>Crawler</code> will have two database interfaces:</p> <ol> <li> <p><code>crawl_db</code>: This is the database that contains all the information     extracted from the DICOM files.     It is a dictionary mapping the <code>SeriesInstanceUID</code> to all the metadatal     extracted from the files in the series using the     <code>ModalityMetadataExtractor</code>     extractors.</p> </li> <li> <p><code>index</code>: This is a slimmed database that contains the core metadata     to build a representation of the data relationships.</p> <p>It contains the following information:</p> <ol> <li><code>PatientID</code></li> <li><code>StudyInstanceUID</code></li> <li><code>SeriesInstanceUID</code></li> <li><code>SubSeries</code> (possible unique Acquisition)</li> <li><code>Modality</code></li> <li><code>ReferencedModality</code></li> <li><code>ReferencedSeriesUID</code></li> <li><code>instances</code> (number of instances in the series)</li> <li><code>folder</code> (path to the folder containing the series)</li> </ol> </li> </ol> <p>These files are stored in a <code>.imgtools</code> directory next to the input directory.</p> <p>That is if the input directory is <code>/path/to/DICOM_FILES</code>, the index output files will be stored in <code>/path/to/.imgtools/DICOM_FILES</code>.</p>"},{"location":"usage/crawl_interlacer/interlacer/","title":"Interlacer Module","text":"<p>The Interlacer module builds and searches a tree-like structure made from DICOM series using metadata links. </p> <p>This tool enables efficient grouping, querying, and vizualization of medical imaging series, making it easier to understand the complex relationships between various imaging modalities (CT, MR, PT) and derived objects (RTSTRUCT, RTDOSE, SEG)</p> <p>Note</p> <p>This module is available in <code>med-imagetools 2.0</code> and later versions. It replaces the now deprecated <code>DataGraph</code> module from <code>med-imagetools 1.0</code>.</p>"},{"location":"usage/crawl_interlacer/interlacer/#overview","title":"Overview","text":"<p>This module turns DICOM series into a set of trees (a forest), using metadata to connect related series. This helps users follow the relationships between series \u2014 for example, linking a <code>CT</code> scan to its <code>RTSTRUCT</code> and <code>RTDOSE</code> \u2014 and makes it easier to run queries or group series by type.</p>"},{"location":"usage/crawl_interlacer/interlacer/#main-classes","title":"Main Classes","text":""},{"location":"usage/crawl_interlacer/interlacer/#seriesnode","title":"<code>SeriesNode</code>","text":"<p>Represents an individual DICOM series and its hierarchical relationships:</p> <ul> <li>Attributes:</li> <li><code>SeriesInstanceUID</code></li> <li><code>Modality</code></li> <li><code>PatientID</code></li> <li><code>StudyInstanceUID</code></li> <li><code>folder</code>: Path to the folder containing the DICOM files</li> <li><code>ReferencedSeriesUID</code>: Series that this one references, if any</li> <li><code>children</code>: List of child nodes representing referenced series<ul> <li>i.e a <code>CT</code> series might have 1 or more links to <code>RTSTRUCT</code> and/or  <code>PT</code> series</li> </ul> </li> </ul>"},{"location":"usage/crawl_interlacer/interlacer/#interlacer","title":"<code>Interlacer</code>","text":"<p>Key features:</p> <ul> <li>Query validation: Ensures that modality queries follow DICOM standard requirements</li> <li>Interactive visualization: Creates HTML-based network graphs of relationships</li> <li>Rich text console display: Pretty-prints the hierarchy with color-coding</li> <li>Dependency validation: Enforces rules like \"RTSTRUCT requires CT, MR, or PT\"</li> </ul>"},{"location":"usage/crawl_interlacer/interlacer/#grouping-series","title":"Grouping Series","text":"<p>The Interlacer currently groups series using Referenced Series UID, which links series based on their metadata references (i.e the <code>ReferencedSeriesInstanceUID</code> tag in <code>RTSTRUCT</code>s). This creates a hierarchical structure showing the relationships between different series.</p> <p>Future Development</p> <p>In a future release, the Interlacer will support additional grouping methods:</p> <ul> <li>Study Instance UID \u2013 Group everything in the same study</li> <li>Patient ID \u2013 Group all series from the same patient</li> </ul> <p>This enhancement is being tracked in GitHub issue #318.</p>"},{"location":"usage/crawl_interlacer/interlacer/#usage-example","title":"Usage Example","text":"<pre><code>from pathlib import Path\nfrom imgtools.dicom.crawl import Crawler\nfrom imgtools.dicom.interlacer import Interlacer\n\n# Define path to DICOM directory\ndicom_dir = Path(\"data/\")\n\n# Create crawler and scan the directory\ncrawler = Crawler(\n    dicom_dir=dicom_dir,\n    n_jobs=5,\n    force=False,\n)\ncrawler.crawl()\n\n# Create the Interlacer from crawler results\ninterlacer = Interlacer(crawler.index)\n\n# Visualize the forest structure\ninterlacer.print_tree(dicom_dir)  # Console visualization\n\n# Query for specific modality combinations\n# Find CT series with associated RTSTRUCT objects\nct_rtstruct_results = interlacer.query(\"CT,RTSTRUCT\")\n\n# Get all possible series combinations\nall_results = interlacer.query(\"*\")  # or interlacer.query(\"all\")\n</code></pre>"},{"location":"usage/crawl_interlacer/interlacer/#query-rules-and-dependencies","title":"Query Rules and Dependencies","text":"<p>The Interlacer enforces the following modality dependency rules:</p> <ol> <li><code>RTSTRUCT</code> and <code>RTDOSE</code> require a <code>CT</code>, <code>MR</code>, or <code>PT</code> series</li> <li><code>SEG</code> requires a <code>CT</code> or <code>MR</code> series</li> </ol> <p>Examples of valid and invalid queries:</p> <ul> <li>\u2705 <code>\"CT,RTDOSE\"</code> - Valid: CT with associated RTDOSE</li> <li>\u2705 <code>\"CT,PT,RTSTRUCT\"</code> - Valid: CT and PT with associated RTSTRUCT</li> <li>\u274c <code>\"PT,SEG\"</code> - Invalid: SEG requires CT or MR, not PT</li> <li>\u274c <code>\"RTSTRUCT,RTDOSE\"</code> - Invalid: Both require a source imaging series</li> </ul>"},{"location":"usage/crawl_interlacer/interlacer/#example-output","title":"Example Output","text":"<p>The raw graph of all series in the DICOM directory:</p> <p></p> <p>The interlaced connections between series:</p> <p></p>"}]}