{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Med-Imagetools: Transparent and Reproducible Medical Image Processing Pipelines in Python","text":""},{"location":"#med-imagetools-core-features","title":"Med-ImageTools core features","text":"<ul> <li>AutoPipeline CLI</li> <li><code>nnunet</code> nnU-Net compatibility mode</li> <li>Built-in train/test split for both normal/nnU-Net modes</li> <li><code>random_state</code> for reproducible seeds</li> <li>Region of interest (ROI) yaml dictionary intake for RTSTRUCT processing</li> <li>Markdown report output post-processing</li> <li><code>continue_processing</code> flag to continue autopipeline</li> <li><code>dry_run</code> flag to only crawl the dataset</li> </ul> <p>Med-Imagetools, a python package offers the perfect tool to transform messy medical dataset folders to deep learning ready format in few lines of code. It not only processes DICOMs consisting of different modalities (like CT, PET, RTDOSE and RTSTRUCTS), it also transforms them into deep learning ready subject based format taking the dependencies of these modalities into consideration.  </p>"},{"location":"#introduction","title":"Introduction","text":"<p>A medical dataset, typically contains multiple different types of scans for a single patient in a single study. As seen in the figure below, the different scans containing DICOM of different modalities are interdependent on each other. For making effective machine learning models, one ought to take different modalities into account.</p> <p></p> <p>Fig.1 - Different network topology for different studies of different patients</p> <p>Med-Imagetools is a unique tool, which focuses on subject based Machine learning. It crawls the dataset and makes a network by connecting different modalities present in the dataset. Based on the user defined modalities, med-imagetools, queries the graph and process the queried raw DICOMS. The processed DICOMS are saved as nrrds, which med-imagetools converts to torchio subject dataset and eventually torch dataloader for ML pipeline.</p> <p></p> <p>Fig.2 - Med-Imagetools AutoPipeline diagram</p>"},{"location":"#installing-med-imagetools","title":"Installing med-imagetools","text":"<pre><code>pip install med-imagetools\n</code></pre>"},{"location":"#create-new-conda-virtual-environment","title":"Create new conda virtual environment","text":"<pre><code>conda create -n mit\nconda activate mit\npip install med-imagetools\n</code></pre>"},{"location":"#create-a-pixi-environment","title":"Create a <code>pixi</code> environment","text":"<pre><code>pixi init mit\npixi add --pypi med-imagetools\n</code></pre>"},{"location":"#optional-install-in-development-mode","title":"(optional) Install in development mode","text":"<pre><code>conda create -n mit\nconda activate mit\npip install -e git+https://github.com/bhklab/med-imagetools.git\n</code></pre> <p>This will install the package in editable mode, so that the installed package will update when the code is changed.</p>"},{"location":"database_report/","title":"Database Report","text":""},{"location":"database_report/#number-of-patients-100","title":"Number of Patients: 100","text":""},{"location":"database_report/#number-of-studies-315","title":"Number of Studies: 315","text":""},{"location":"database_report/#number-of-series-3123","title":"Number of Series: 3123","text":""},{"location":"database_report/#modality-summary","title":"Modality Summary","text":"Modality Count MR 152 SEG 68 CT 138 OT 1 PT 10 RTSTRUCT 16 RTDOSE 16 RTPLAN 13 DX 8 SR 10 MG 5 NM 1 CR 11"},{"location":"database_report/#data-summary","title":"Data Summary","text":"Patient ID Number of Studies Number of Series Unique Modalities TCGA-06-0184 12 183 {'SEG', 'MR'} TCGA-06-0185 16 176 {'SEG', 'MR'} TCGA-BB-A5HY 11 121 {'CT', 'OT', 'MR'} TCGA-06-0188 9 110 {'SEG', 'MR'} TCGA-CV-7090 15 93 {'PT', 'CT', 'MR'} TCGA-06-0138 6 90 {'SEG', 'MR'} TCGA-06-1084 6 77 {'SEG', 'MR'} TCGA-06-0139 5 76 {'SEG', 'MR'} TCGA-CV-7243 15 72 {'RTDOSE', 'CT', 'RTSTRUCT'} TCGA-CV-A6K0 13 71 {'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-A6JY 14 68 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-DD-A4NG 8 58 {'PT', 'CT', 'MR'} TCGA-06-0238 3 54 {'SEG', 'MR'} TCGA-06-1802 3 51 {'SEG', 'MR'} TCGA-D1-A16D 9 43 {'PT', 'CT', 'MR'} TCGA-06-0164 3 36 {'SEG', 'MR'} TCGA-06-0137 2 34 {'SEG', 'MR'} TCGA-14-1794 4 34 {'CT', 'SEG', 'MR'} TCGA-06-0130 2 33 {'SEG', 'MR'} TCGA-CS-6186 2 33 {'CT', 'SEG', 'MR'} TCGA-CV-A6JO 8 32 {'RTPLAN', 'CT', 'RTDOSE', 'PT', 'RTSTRUCT'} TCGA-06-0154 1 32 {'SEG', 'MR'} TCGA-02-0075 1 31 {'SEG', 'MR'} TCGA-06-0190 2 31 {'SEG', 'MR'} TCGA-02-0087 1 30 {'SEG', 'MR'} TCGA-CV-A6K1 7 28 {'RTDOSE', 'CT', 'RTSTRUCT', 'RTPLAN'} TCGA-G2-A3IE 6 28 {'CT', 'DX', 'MR'} TCGA-AO-A0JB 3 26 {'SR', 'MG', 'MR'} TCGA-02-0064 1 25 {'SEG', 'MR'} TCGA-02-0059 1 25 {'SEG', 'MR'} TCGA-02-0034 1 25 {'SEG', 'MR'} TCGA-06-0122 1 25 {'SEG', 'MR'} TCGA-06-0644 1 25 {'SEG', 'MR'} TCGA-06-0646 1 25 {'SEG', 'MR'} TCGA-06-5413 1 25 {'SEG', 'MR'} TCGA-06-0192 2 25 {'SEG', 'MR'} TCGA-06-0179 1 25 {'SEG', 'MR'} TCGA-08-0359 1 25 {'SEG', 'MR'} TCGA-06-5417 1 25 {'SEG', 'MR'} TCGA-02-0069 1 24 {'SEG', 'MR'} TCGA-06-0119 1 24 {'SEG', 'MR'} TCGA-CV-A6K2 5 24 {'RTPLAN', 'CT', 'RTSTRUCT', 'RTDOSE'} TCGA-08-0389 1 24 {'SEG', 'MR'} TCGA-06-0149 1 24 {'SEG', 'MR'} TCGA-CR-7368 4 24 {'PT', 'CT', 'MR'} TCGA-06-0158 2 24 {'SEG', 'MR'} TCGA-02-0086 1 24 {'SEG', 'MR'} TCGA-08-0355 1 24 {'SEG', 'MR'} TCGA-06-2570 1 23 {'SEG', 'MR'} TCGA-02-0027 1 22 {'SEG', 'MR'} TCGA-B9-A44B 2 22 {'PT', 'CT', 'MR'} TCGA-06-6389 1 22 {'SEG', 'MR'} TCGA-50-5072 4 22 {'PT', 'CT', 'NM'} TCGA-08-0385 2 22 {'SEG', 'MR'} TCGA-06-0142 1 22 {'SEG', 'MR'} TCGA-02-0068 1 22 {'SEG', 'MR'} TCGA-06-0240 1 22 {'SEG', 'MR'} TCGA-08-0360 1 21 {'SEG', 'MR'} TCGA-06-0182 1 21 {'SEG', 'MR'} TCGA-G2-A2EK 11 21 {'CR', 'CT', 'DX'} TCGA-06-0187 1 21 {'SEG', 'MR'} TCGA-08-0392 1 21 {'SEG', 'MR'} TCGA-06-5408 1 21 {'SEG', 'MR'} TCGA-08-0390 1 20 {'SEG', 'MR'} TCGA-02-0070 1 20 {'SEG', 'MR'} TCGA-02-0054 1 19 {'SEG', 'MR'} TCGA-08-0356 1 19 {'SEG', 'MR'} TCGA-G2-A2EL 5 19 {'CR', 'CT', 'DX'} TCGA-AO-A0JF 5 19 {'SR', 'MG', 'MR'} TCGA-06-0177 1 19 {'SEG', 'MR'} TCGA-02-0011 1 18 {'SEG', 'MR'} TCGA-02-0033 1 18 {'SEG', 'MR'} TCGA-02-0047 1 18 {'SEG', 'MR'} TCGA-02-0037 1 18 {'SEG', 'MR'} TCGA-06-0162 1 18 {'SEG', 'MR'} TCGA-02-0106 1 18 {'SEG', 'MR'} TCGA-06-0145 1 18 {'SEG', 'MR'} TCGA-06-0176 1 17 {'SEG', 'MR'} TCGA-G2-AA3D 5 17 {'CR', 'CT', 'DX'} TCGA-G2-A2EO 7 17 {'CR', 'CT', 'DX'} TCGA-AO-A0JI 2 17 {'SR', 'MG', 'MR'} TCGA-02-0116 1 17 {'SEG', 'MR'} TCGA-02-0009 1 16 {'SEG', 'MR'} TCGA-02-0006 1 16 {'SEG', 'MR'} TCGA-02-0046 1 16 {'SEG', 'MR'} TCGA-G7-A8LD 3 16 {'PT', 'CT', 'MR'} TCGA-02-0102 1 16 {'SEG', 'MR'} TCGA-02-0085 1 16 {'SEG', 'MR'} TCGA-CR-6478 2 14 {'PT', 'CT', 'MR'} TCGA-CV-5973 2 13 {'RTPLAN', 'CT', 'RTSTRUCT', 'RTDOSE'} TCGA-CV-5977 2 13 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-7235 2 10 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-5976 2 10 {'RTDOSE', 'CT', 'RTSTRUCT', 'RTPLAN'} TCGA-CV-6433 2 9 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-08-0509 1 8 {'SEG', 'MR'} TCGA-CV-5966 2 8 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-5978 2 8 {'RTPLAN', 'CT', 'RTDOSE', 'RTSTRUCT'} TCGA-CV-5970 2 7 {'RTPLAN', 'CT', 'RTSTRUCT', 'RTDOSE'} TCGA-CV-7236 2 7 {'RTDOSE', 'CT', 'RTSTRUCT'} TCGA-CV-7245 2 7 {'RTPLAN', 'CT', 'RTSTRUCT', 'RTDOSE'}"},{"location":"cli/imgtools/","title":"<code>imgtools</code> CLI","text":""},{"location":"cli/imgtools/#imgtools","title":"imgtools","text":"<p>A collection of tools for working with medical imaging data.</p> <p>Usage:</p> <pre><code>imgtools [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--quiet</code>, <code>-q</code> boolean Suppress all logging except errors, overrides verbosity options. <code>False</code> <code>--verbose</code>, <code>-v</code> integer range (<code>0</code> and above) Increase verbosity of logging, overrides environment variable. (0-3: ERROR, WARNING, INFO, DEBUG). <code>0</code> <code>--version</code> boolean Show the version and exit. <code>False</code> <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/imgtools/#imgtools-dicomfind","title":"imgtools dicomfind","text":"<p>A tool to find DICOM files.</p> <p>PATH is the directory to search for DICOM files.</p> <p>SEARCH_INPUT is an optional list of substring(s) to search for in the DICOM files. If multiple substrings are provided, all substrings must match to return a result.</p> <p>i.e dicomfind /path/to/directory/ \"substring1\" \"substring2\" \"substring3\"</p> <p>Usage:</p> <pre><code>imgtools dicomfind [OPTIONS] PATH [SEARCH_INPUT]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>-e</code>, <code>--extension</code> text File extension to look for. <code>dcm</code> <code>-c</code>, <code>--count</code> boolean Whether to just print the count of files found. This is useful for scripts. <code>False</code> <code>-l</code>, <code>--limit</code> integer The limit of results to return. None <code>-ch</code>, <code>--check-header</code> boolean Whether to check DICOM header for \"DICM\" signature. <code>False</code> <code>-s</code>, <code>--sorted</code> boolean Sort the results alphabetically. <code>False</code> <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/imgtools/#imgtools-dicomsort","title":"imgtools dicomsort","text":"<p>Sorts DICOM files into directories based on their tags.</p> <p>Usage:</p> <pre><code>imgtools dicomsort [OPTIONS] SOURCE_DIRECTORY TARGET_DIRECTORY\n</code></pre> <p>Options:</p> Name Type Description Default <code>--action</code>, <code>-a</code> choice (<code>move</code> | <code>copy</code> | <code>symlink</code> | <code>hardlink</code>) Action to perform on the files. _required <code>-n</code>, <code>--dry-run</code> boolean Do not move or copy files, just print what would be done. Always recommended to use this first to confirm the operation! <code>False</code> <code>-j</code>, <code>--num-workers</code> integer Number of worker processes to use for sorting. <code>1</code> <code>--truncate-uids</code>, <code>-t</code> integer Truncate the UIDs in the DICOM files to the specified length. Set to 0 to disable truncation. <code>5</code> <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/imgtools/#imgtools-index","title":"imgtools index","text":"<p>Crawl DICOM directory and create a database index.</p> <ul> <li> <p>looks for all DICOM files in the specified directory, extracts metadata,      and builds a comprehensive index of the dataset.</p> </li> <li> <p>The index includes information about the series, modalities, and other     relevant details, making it easier to manage and analyze the DICOM files.</p> </li> <li> <p>The output is saved in a structured format, including JSON and CSV files,     which can be used for further processing or analysis.</p> </li> <li> <p>By default, it saves the results in a \".imgtools\" folder right next to      your DICOM directory, but you can pick your own place to store them.</p> </li> </ul> <p>Usage:</p> <pre><code>imgtools index [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--dicom-dir</code> path Path to the DICOM directory. _required <code>--output-dir</code> path Path to the output directory. If not specified, a directory named '.imgtools' will be created in the parent directory of the DICOM directory. None <code>--dataset-name</code> text Name of the dataset. If not specified, the name of the DICOM directory will be used. None <code>--n-jobs</code> integer Number of jobs to use for parallel processing. <code>2</code> <code>--force</code> boolean Force overwrite existing files. <code>False</code> <code>-h</code>, <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/imgtools/#imgtools-shell-completion","title":"imgtools shell-completion","text":"<p>Emit shell completion script (hidden command).</p> <p>This command generates a shell completion script for the specified shell. Supported shells: bash, zsh, fish.</p> <p>Usage:</p> <pre><code>imgtools shell-completion [OPTIONS] {bash|zsh|fish}\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/shell-completion/","title":"Shell Completion","text":"<p>Shell completion is a feature that allows you to press the <code>Tab</code> key while typing a command to automatically complete command names, options, and arguments. This can significantly improve your productivity when working with the <code>imgtools</code> CLI.</p>"},{"location":"cli/shell-completion/#generating-completion-scripts","title":"Generating Completion Scripts","text":"<p>The <code>imgtools</code> CLI provides a built-in command to generate shell completion scripts for various shells:</p> <pre><code>imgtools shell-completion [SHELL]\n</code></pre> <p>Where <code>[SHELL]</code> is one of: <code>bash</code>, <code>zsh</code>, or <code>fish</code>.</p>"},{"location":"cli/shell-completion/#installation-instructions","title":"Installation Instructions","text":"BashZshFish <p>To enable completion for the current bash session:</p> <pre><code>source &lt;(imgtools shell-completion bash)\n</code></pre> <p>For permanent setup, add the completion script to a file in your bash completion directory:</p> <pre><code># Create the completions directory if it doesn't exist\nmkdir -p ~/.bash_completion.d\n\n# Save the completion script to a file\nimgtools shell-completion bash &gt; ~/.bash_completion.d/imgtools\n\n# Add the following to your ~/.bashrc file\necho 'source ~/.bash_completion.d/imgtools' &gt;&gt; ~/.bashrc\n\n# Reload your shell configuration\nsource ~/.bashrc\n</code></pre> <p>To enable completion for the current zsh session:</p> <pre><code>source &lt;(imgtools shell-completion zsh)\n</code></pre> <p>For permanent setup:</p> <pre><code># Create the completions directory if it doesn't exist\nmkdir -p ~/.zsh/completion\n\n# Save the completion script to a file\nimgtools shell-completion zsh &gt; ~/.zsh/completion/_imgtools\n\n# Add to your ~/.zshrc file\necho 'fpath=(~/.zsh/completion $fpath)' &gt;&gt; ~/.zshrc\necho 'autoload -U compinit &amp;&amp; compinit' &gt;&gt; ~/.zshrc\n\n# Reload your shell configuration\nsource ~/.zshrc\n</code></pre> <p>To enable completion for the current fish session:</p> <pre><code>imgtools shell-completion fish | source\n</code></pre> <p>For permanent setup:</p> <pre><code># Create the completions directory if it doesn't exist\nmkdir -p ~/.config/fish/completions\n\n# Save the completion script\nimgtools shell-completion fish &gt; ~/.config/fish/completions/imgtools.fish\n\n# Fish will automatically load the completions on next shell start\n</code></pre>"},{"location":"cli/shell-completion/#verifying-completion-works","title":"Verifying Completion Works","text":"<p>After setting up completion, you can verify it works by typing:</p> <pre><code>imgtools &lt;TAB&gt;\n</code></pre> <p>This should display available subcommands. You can also try:</p> <pre><code>imgtools dicomsort --&lt;TAB&gt;\n</code></pre> <p>This should show the <code>--</code>options available for the <code>dicomsort</code> command  (i.e <code>--action</code>, <code>--output</code>, etc.)</p>"},{"location":"cli/shell-completion/#troubleshooting","title":"Troubleshooting","text":"<p>If completions don't work after following these steps:</p> <ol> <li>Make sure you've reloaded your shell configuration or started a new terminal session</li> <li>Verify that the completion script was properly generated and saved</li> <li>Check if your shell supports tab completion (it should by default)</li> </ol>"},{"location":"reference/dicom-utils/find-dicoms/","title":"Find DICOMs","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms","title":"imgtools.dicom.find_dicoms","text":"<pre><code>find_dicoms(\n    directory: pathlib.Path,\n    recursive: bool = True,\n    check_header: bool = False,\n    extension: str = \"dcm\",\n    case_sensitive: bool = False,\n    limit: int | None = None,\n    search_input: typing.List[str] | None = None,\n) -&gt; typing.List[pathlib.Path]\n</code></pre> <p>Locate DICOM files in a specified directory.</p> <p>This function scans a directory for files matching the specified extension and validates them as DICOM files based on the provided options. It supports recursive search and optional header validation to confirm file validity.</p> <p>Parameters:</p> Name Type Description Default <code>pathlib.Path</code> <p>The directory in which to search for DICOM files.</p> required <code>bool</code> <p>Whether to include subdirectories in the search</p> <code>True</code> <code>bool</code> <p>Whether to validate files by checking for a valid DICOM header.     - If <code>True</code>, perform DICOM header validation (slower but more accurate).     - If <code>False</code>, skip header validation and rely on extension.</p> <code>False</code> <code>str</code> <p>File extension to search for (e.g., \"dcm\"). If <code>None</code>, consider all files regardless of extension.</p> <code>\"dcm\"</code> <code>bool</code> <p>Whether to perform a case-sensitive search for the file extension. If <code>False</code>, the search is case-insensitive.</p> <code>False</code> <code>int</code> <p>Maximum number of DICOM files to return. If <code>None</code>, return all found files.</p> <code>None</code> <code>typing.List[str]</code> <p>List of terms to filter files by. Only files containing all terms in their paths will be included. If <code>None</code>, no filtering is applied.</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.List[pathlib.Path]</code> <p>A list of valid DICOM file paths found in the directory.</p> Notes <ul> <li>If <code>check_header</code> is enabled, the function checks each file for a valid     DICOM header, which may slow down the search process.</li> </ul> <p>Examples:</p> <p>Setup</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from imgtools.dicom.dicom_find import find_dicoms\n</code></pre> <p>Find DICOM files recursively without header validation:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=False,\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm'), PosixPath('/data/subdir/scan3.DCM')]\n</code></pre> <p>Suppose that <code>scan3.DCM</code> is not a valid DICOM file. Find DICOM files with header validation:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=True,\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n</code></pre> <p>Find DICOM files without recursion:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=False,\n...     check_header=False,\n... )\n[PosixPath('/data/scan1.dcm')]\n</code></pre> <p>Find DICOM files with a specific extension:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=False,\n...     extension=\"dcm\",\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n</code></pre> <p>Find DICOM files with a search input (substring match):</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=False,\n...     search_input=[\"1\", \"scan2\"],\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n</code></pre> <p>Find DICOM files with a limit:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=False,\n...     limit=1,\n... )\n[PosixPath('/data/scan1.dcm')]\n</code></pre> <p>Find DICOM files with all options:</p> <pre><code>&gt;&gt;&gt; find_dicoms(\n...     Path(\"/data\"),\n...     recursive=True,\n...     check_header=True,\n...     extension=\"dcm\",\n...     limit=2,\n...     search_input=[\"scan\"],\n... )\n[PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n</code></pre> Source code in <code>src/imgtools/dicom/dicom_find.py</code> <pre><code>def find_dicoms(\n    directory: Path,\n    recursive: bool = True,\n    check_header: bool = False,\n    extension: str = \"dcm\",\n    case_sensitive: bool = False,\n    limit: int | None = None,\n    search_input: List[str] | None = None,\n) -&gt; List[Path]:\n    \"\"\"Locate DICOM files in a specified directory.\n\n    This function scans a directory for files matching the specified extension\n    and validates them as DICOM files based on the provided options. It supports\n    recursive search and optional header validation to confirm file validity.\n\n    Parameters\n    ----------\n    directory : Path\n        The directory in which to search for DICOM files.\n    recursive : bool\n        Whether to include subdirectories in the search\n    check_header : bool\n        Whether to validate files by checking for a valid DICOM header.\n            - If `True`, perform DICOM header validation (slower but more accurate).\n            - If `False`, skip header validation and rely on extension.\n    extension : str, default=\"dcm\"\n        File extension to search for (e.g., \"dcm\"). If `None`, consider all files\n        regardless of extension.\n    case_sensitive : bool, default=False\n        Whether to perform a case-sensitive search for the file extension.\n        If `False`, the search is case-insensitive.\n    limit : int, optional\n        Maximum number of DICOM files to return. If `None`, return all found files.\n    search_input : List[str], optional\n        List of terms to filter files by. Only files containing all terms\n        in their paths will be included. If `None`, no filtering is applied.\n\n    Returns\n    -------\n    List[Path]\n        A list of valid DICOM file paths found in the directory.\n\n    Notes\n    -----\n    - If `check_header` is enabled, the function checks each file for a valid\n        DICOM header, which may slow down the search process.\n\n    Examples\n    --------\n    Setup\n\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from imgtools.dicom.dicom_find import find_dicoms\n\n    Find DICOM files recursively without header validation:\n\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=False,\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm'), \\\nPosixPath('/data/subdir/scan3.DCM')]\n\n    Suppose that `scan3.DCM` is not a valid DICOM file. Find DICOM files with \\\nheader validation:\n\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=True,\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n\n    Find DICOM files without recursion:\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=False,\n    ...     check_header=False,\n    ... )\n    [PosixPath('/data/scan1.dcm')]\n\n    Find DICOM files with a specific extension:\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=False,\n    ...     extension=\"dcm\",\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n\n    Find DICOM files with a search input (substring match):\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=False,\n    ...     search_input=[\"1\", \"scan2\"],\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n\n    Find DICOM files with a limit:\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=False,\n    ...     limit=1,\n    ... )\n    [PosixPath('/data/scan1.dcm')]\n\n    Find DICOM files with all options:\n    &gt;&gt;&gt; find_dicoms(\n    ...     Path(\"/data\"),\n    ...     recursive=True,\n    ...     check_header=True,\n    ...     extension=\"dcm\",\n    ...     limit=2,\n    ...     search_input=[\"scan\"],\n    ... )\n    [PosixPath('/data/scan1.dcm'), PosixPath('/data/subdir/scan2.dcm')]\n    \"\"\"\n\n    files = filter_valid_dicoms(\n        directory,\n        check_header,\n        case_sensitive,\n        search_input,\n        extension or \"\",\n        recursive,\n    )\n\n    return list(islice(files, limit)) if limit else list(files)\n</code></pre>"},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(directory)","title":"<code>directory</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(recursive)","title":"<code>recursive</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(check_header)","title":"<code>check_header</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(extension)","title":"<code>extension</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(case_sensitive)","title":"<code>case_sensitive</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(limit)","title":"<code>limit</code>","text":""},{"location":"reference/dicom-utils/find-dicoms/#imgtools.dicom.find_dicoms(search_input)","title":"<code>search_input</code>","text":""},{"location":"reference/dicom-utils/load-dicom/","title":"Load DICOM","text":""},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom","title":"imgtools.dicom.load_dicom","text":"<pre><code>load_dicom(\n    dicom_input: imgtools.dicom.dicom_reader.DicomInput,\n    force: bool = True,\n    stop_before_pixels: bool = True,\n    **kwargs: typing.Any\n) -&gt; pydicom.dataset.FileDataset\n</code></pre> <p>Load a DICOM file and return the parsed FileDataset object.</p> <p>This function supports various input types including file paths, byte streams, and file-like objects. It uses the <code>pydicom.dcmread</code> function to read the DICOM file.</p> Notes <ul> <li>If <code>dicom_input</code> is already a <code>FileDataset</code>, it is returned as is.</li> <li>If <code>dicom_input</code> is a file path or file-like object, it is read using <code>pydicom.dcmread</code>.</li> <li>If <code>dicom_input</code> is a byte stream, it is wrapped in a <code>BytesIO</code> object and then read.</li> <li>An <code>InvalidDicomError</code> is raised if the input type is unsupported.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>pydicom.dataset.FileDataset | str | pathlib.Path | bytes | typing.BinaryIO</code> <p>Input DICOM file as a <code>pydicom.FileDataset</code>, file path, byte stream, or file-like object.</p> required <code>bool</code> <p>Whether to allow reading DICOM files missing the File Meta Information header, by default True.</p> <code>True</code> <code>bool</code> <p>Whether to stop reading the DICOM file before loading pixel data, by default True.</p> <code>True</code> <code>typing.Any</code> <p>Additional keyword arguments to pass to <code>pydicom.dcmread</code>. i.e <code>specific_tags</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pydicom.dataset.FileDataset</code> <p>Parsed DICOM dataset.</p> <p>Raises:</p> Type Description <code>imgtools.exceptions.InvalidDicomError</code> <p>If the input is of an unsupported type or cannot be read as a DICOM file.</p> Source code in <code>src/imgtools/dicom/dicom_reader.py</code> <pre><code>def load_dicom(\n    dicom_input: DicomInput,\n    force: bool = True,\n    stop_before_pixels: bool = True,\n    **kwargs: Any,  # noqa: ANN401\n) -&gt; FileDataset:\n    \"\"\"Load a DICOM file and return the parsed FileDataset object.\n\n    This function supports various input types including file paths, byte streams,\n    and file-like objects. It uses the `pydicom.dcmread` function to read the DICOM file.\n\n    Notes\n    -----\n    - If `dicom_input` is already a `FileDataset`, it is returned as is.\n    - If `dicom_input` is a file path or file-like object, it is read using `pydicom.dcmread`.\n    - If `dicom_input` is a byte stream, it is wrapped in a `BytesIO` object and then read.\n    - An `InvalidDicomError` is raised if the input type is unsupported.\n\n    Parameters\n    ----------\n    dicom_input : FileDataset | str | Path | bytes | BinaryIO\n        Input DICOM file as a `pydicom.FileDataset`, file path, byte stream, or file-like object.\n    force : bool, optional\n        Whether to allow reading DICOM files missing the *File Meta Information*\n        header, by default True.\n    stop_before_pixels : bool, optional\n        Whether to stop reading the DICOM file before loading pixel data, by default True.\n    **kwargs\n        Additional keyword arguments to pass to `pydicom.dcmread`.\n        i.e `specific_tags`.\n    Returns\n    -------\n    FileDataset\n        Parsed DICOM dataset.\n\n    Raises\n    ------\n    InvalidDicomError\n        If the input is of an unsupported type or cannot be read as a DICOM file.\n    \"\"\"\n    match dicom_input:\n        case FileDataset():\n            return dicom_input\n        case str() | Path() | BinaryIO():\n            dicom_source = path_from_pathlike(dicom_input)\n            return dcmread(\n                dicom_source,\n                force=force,\n                stop_before_pixels=stop_before_pixels,\n                **kwargs,\n            )\n        case bytes():\n            return dcmread(\n                BytesIO(dicom_input),\n                force=force,\n                stop_before_pixels=stop_before_pixels,\n                **kwargs,\n            )\n        case _:\n            msg = (\n                f\"Invalid input type for 'dicom_input': {type(dicom_input)}. \"\n                \"Must be a FileDataset, str, Path, bytes, or BinaryIO object.\"\n            )\n            raise InvalidDicomError(msg)\n</code></pre>"},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom(dicom_input)","title":"<code>dicom_input</code>","text":""},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom(force)","title":"<code>force</code>","text":""},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom(stop_before_pixels)","title":"<code>stop_before_pixels</code>","text":""},{"location":"reference/dicom-utils/load-dicom/#imgtools.dicom.load_dicom(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"reference/dicom-utils/lookup_tag/","title":"Lookup Tag","text":""},{"location":"reference/dicom-utils/lookup_tag/#imgtools.dicom.lookup_tag","title":"imgtools.dicom.lookup_tag  <code>cached</code>","text":"<pre><code>lookup_tag(\n    keyword: str, hex_format: bool = False\n) -&gt; typing.Optional[str]\n</code></pre> <p>Lookup the tag for a given DICOM keyword.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The DICOM keyword to look up.</p> required <code>bool</code> <p>If True, return the tag in hexadecimal format (default is False).</p> <code>False</code> <p>Returns:</p> Type Description <code>str or None</code> <p>The DICOM tag as a string, or None if the keyword is invalid.</p> <p>Examples:</p> <p>Lookup a DICOM tag in decimal format:</p> <pre><code>&gt;&gt;&gt; lookup_tag(\"PatientID\")\n'1048608'\n</code></pre> <p>Lookup a DICOM tag in hexadecimal format:</p> <pre><code>&gt;&gt;&gt; lookup_tag(\n...     \"PatientID\",\n...     hex_format=True,\n... )\n'0x100020'\n</code></pre> Source code in <code>src/imgtools/dicom/utils.py</code> <pre><code>@functools.lru_cache(maxsize=1024)\ndef lookup_tag(keyword: str, hex_format: bool = False) -&gt; Optional[str]:\n    \"\"\"\n    Lookup the tag for a given DICOM keyword.\n\n    Parameters\n    ----------\n    keyword : str\n        The DICOM keyword to look up.\n    hex_format : bool, optional\n        If True, return the tag in hexadecimal format (default is False).\n\n    Returns\n    -------\n    str or None\n        The DICOM tag as a string, or None if the keyword is invalid.\n\n    Examples\n    --------\n\n    Lookup a DICOM tag in decimal format:\n\n    &gt;&gt;&gt; lookup_tag(\"PatientID\")\n    '1048608'\n\n    Lookup a DICOM tag in hexadecimal format:\n\n    &gt;&gt;&gt; lookup_tag(\n    ...     \"PatientID\",\n    ...     hex_format=True,\n    ... )\n    '0x100020'\n    \"\"\"\n    if (tag := tag_for_keyword(keyword)) is None:\n        return None\n    return f\"0x{tag:X}\" if hex_format else str(tag)\n</code></pre>"},{"location":"reference/dicom-utils/lookup_tag/#imgtools.dicom.lookup_tag(keyword)","title":"<code>keyword</code>","text":""},{"location":"reference/dicom-utils/lookup_tag/#imgtools.dicom.lookup_tag(hex_format)","title":"<code>hex_format</code>","text":""},{"location":"reference/dicom-utils/similar_tags/","title":"Similar Tags","text":""},{"location":"reference/dicom-utils/similar_tags/#imgtools.dicom.similar_tags","title":"imgtools.dicom.similar_tags  <code>cached</code>","text":"<pre><code>similar_tags(\n    keyword: str, n: int = 3, threshold: float = 0.6\n) -&gt; typing.List[str]\n</code></pre> <p>Find similar DICOM tags for a given keyword.</p> <p>Useful for User Interface to suggest similar tags based on a misspelled keyword.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The keyword to search for similar tags.</p> required <code>int</code> <p>Maximum number of similar tags to return (default is 3).</p> <code>3</code> <code>float</code> <p>Minimum similarity ratio (default is 0.6).</p> <code>0.6</code> <p>Returns:</p> Type Description <code>typing.List[str]</code> <p>A list of up to <code>n</code> similar DICOM tags.</p> <p>Examples:</p> <p>Find similar tags for a misspelled keyword:</p> <pre><code>&gt;&gt;&gt; similar_tags(\"PatinetID\")\n['PatientID', 'PatientName', 'PatientBirthDate']\n</code></pre> <p>Adjust the number of results and threshold:</p> <pre><code>&gt;&gt;&gt; similar_tags(\n...     \"PatinetID\",\n...     n=5,\n...     threshold=0.7,\n... )\n['PatientID', 'PatientName']\n</code></pre> Source code in <code>src/imgtools/dicom/utils.py</code> <pre><code>@functools.lru_cache(maxsize=1024)\ndef similar_tags(\n    keyword: str, n: int = 3, threshold: float = 0.6\n) -&gt; List[str]:\n    \"\"\"Find similar DICOM tags for a given keyword.\n\n    Useful for User Interface to suggest similar tags based on a misspelled keyword.\n\n    Parameters\n    ----------\n    keyword : str\n        The keyword to search for similar tags.\n    n : int, optional\n        Maximum number of similar tags to return (default is 3).\n    threshold : float, optional\n        Minimum similarity ratio (default is 0.6).\n\n    Returns\n    -------\n    List[str]\n        A list of up to `n` similar DICOM tags.\n\n    Examples\n    --------\n    Find similar tags for a misspelled keyword:\n\n    &gt;&gt;&gt; similar_tags(\"PatinetID\")\n    ['PatientID', 'PatientName', 'PatientBirthDate']\n\n    Adjust the number of results and threshold:\n\n    &gt;&gt;&gt; similar_tags(\n    ...     \"PatinetID\",\n    ...     n=5,\n    ...     threshold=0.7,\n    ... )\n    ['PatientID', 'PatientName']\n    \"\"\"\n    return difflib.get_close_matches(keyword, ALL_DICOM_TAGS, n, threshold)\n</code></pre>"},{"location":"reference/dicom-utils/similar_tags/#imgtools.dicom.similar_tags(keyword)","title":"<code>keyword</code>","text":""},{"location":"reference/dicom-utils/similar_tags/#imgtools.dicom.similar_tags(n)","title":"<code>n</code>","text":""},{"location":"reference/dicom-utils/similar_tags/#imgtools.dicom.similar_tags(threshold)","title":"<code>threshold</code>","text":""},{"location":"reference/dicom-utils/tag_exists/","title":"Tag Exists","text":""},{"location":"reference/dicom-utils/tag_exists/#imgtools.dicom.tag_exists","title":"imgtools.dicom.tag_exists  <code>cached</code>","text":"<pre><code>tag_exists(keyword: str) -&gt; bool\n</code></pre> <p>Boolean check if a DICOM tag exists for a given keyword.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The DICOM keyword to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the tag exists, False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tag_exists(\"PatientID\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; tag_exists(\"InvalidKeyword\")\nFalse\n</code></pre> Source code in <code>src/imgtools/dicom/utils.py</code> <pre><code>@functools.lru_cache(maxsize=1024)\ndef tag_exists(keyword: str) -&gt; bool:\n    \"\"\"Boolean check if a DICOM tag exists for a given keyword.\n\n    Parameters\n    ----------\n    keyword : str\n        The DICOM keyword to check.\n\n    Returns\n    -------\n    bool\n        True if the tag exists, False otherwise.\n\n    Examples\n    --------\n\n    &gt;&gt;&gt; tag_exists(\"PatientID\")\n    True\n\n    &gt;&gt;&gt; tag_exists(\"InvalidKeyword\")\n    False\n    \"\"\"\n    return dictionary_has_tag(keyword)\n</code></pre>"},{"location":"reference/dicom-utils/tag_exists/#imgtools.dicom.tag_exists(keyword)","title":"<code>keyword</code>","text":""},{"location":"reference/dicomsort/dicomsorter/","title":"DICOMSorter","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort","title":"sort","text":"<p>Sorting DICOM Files by Specific Tags and Patterns.</p> <p>This module provides functionality to organize DICOM files into structured directories based on customizable target patterns.</p> <p>The target patterns allow metadata-driven file organization using placeholders for DICOM tags, enabling flexible and systematic storage.</p> Extended Summary <p>Target patterns define directory structures using placeholders, such as <code>%&lt;DICOMKey&gt;</code> and <code>{DICOMKey}</code>, which are resolved to their corresponding metadata values in the DICOM file.</p> <p>This approach ensures that files are organized based on their metadata, while retaining their original basenames. Files with identical metadata fields are placed in separate directories to preserve unique identifiers.</p> <p>Examples of target patterns:</p> <pre><code>- `%PatientID/%StudyID/{SeriesID}/`\n- `path/to_destination/%PatientID/images/%Modality/%SeriesInstanceUID/`\n</code></pre> <p>Important: Only the directory structure is modified during the sorting process. The basename of each file remains unchanged.</p> Notes <p>The module ensures that:</p> <ol> <li>Target patterns are resolved accurately based on the metadata in DICOM files.</li> <li>Files are placed in directories that reflect their resolved metadata fields.</li> <li>Original basenames are preserved to prevent unintended overwrites!</li> </ol> <p>Examples:</p> <p>Source file:</p> <pre><code>/source_dir/HN-CHUS-082/1-1.dcm\n</code></pre> <p>Target directory pattern:</p> <pre><code>./data/dicoms/%PatientID/Study-%StudyInstanceUID/Series-%SeriesInstanceUID/%Modality/\n</code></pre> <p>would result in the following structure for each file:</p> <pre><code>data/\n\u2514\u2500\u2500 dicoms/\n    \u2514\u2500\u2500 {PatientID}/\n        \u2514\u2500\u2500 Study-{StudyInstanceUID}/\n            \u2514\u2500\u2500 Series-{SeriesInstanceUID}/\n                \u2514\u2500\u2500 {Modality}/\n                    \u2514\u2500\u2500 1-1.dcm\n</code></pre> <p>And so the resolved path for the file would be:</p> <pre><code>./data/dicoms/HN-CHUS-082/Study-06980/Series-67882/RTSTRUCT/1-1.dcm\n</code></pre> <p>Here, the file is relocated into the resolved directory structure:</p> <pre><code>./data/dicoms/HN-CHUS-082/Study-06980/Series-67882/RTSTRUCT/\n</code></pre> <p>while the basename <code>1-1.dcm</code> remains unchanged.</p>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter","title":"DICOMSorter","text":"<pre><code>DICOMSorter(\n    source_directory: pathlib.Path,\n    target_pattern: str,\n    pattern_parser: typing.Pattern = imgtools.dicom.sort.dicomsorter.DEFAULT_PATTERN_PARSER,\n)\n</code></pre> <p>A specialized implementation of the <code>SorterBase</code> for sorting DICOM files by metadata.</p> <p>This class resolves paths for DICOM files based on specified target patterns, using metadata extracted from the files. The filename of each source file is preserved during this process.</p> <p>Attributes:</p> Name Type Description <code>source_directory</code> <code>pathlib.Path</code> <p>The directory containing the files to be sorted.</p> <code>logger</code> <code>Logger</code> <p>The instance logger bound with the source directory context.</p> <code>dicom_files</code> <code>list of Path</code> <p>The list of DICOM files found in the <code>source_directory</code>.</p> <code>format</code> <code>str</code> <p>The parsed format string with placeholders for DICOM tags.</p> <code>keys</code> <code>typing.Set[str]</code> <p>DICOM tags extracted from the target pattern.</p> <code>invalid_keys</code> <code>typing.Set[str]</code> <p>DICOM tags from the pattern that are invalid.</p> <code>force_dcmread</code> <code>bool</code> <p>If True, force the use of <code>pydicom.dcmread</code> for reading DICOM files.</p> <p>Methods:</p> Name Description <code>execute</code> <p>Execute the file action on DICOM files.</p> <code>print_tree</code> <p>Display the pattern structure as a tree visualization.</p> <code>validate_keys</code> <p>Validate extracted keys. Subclasses should implement this method</p> Source code in <code>src/imgtools/dicom/sort/dicomsorter.py</code> <pre><code>def __init__(\n    self,\n    source_directory: Path,\n    target_pattern: str,\n    pattern_parser: Pattern = DEFAULT_PATTERN_PARSER,\n) -&gt; None:\n    super().__init__(\n        source_directory=source_directory,\n        target_pattern=target_pattern,\n        pattern_parser=pattern_parser,\n    )\n    self.logger.debug(\n        \"All DICOM Keys are Valid in target pattern\", keys=self.keys\n    )\n</code></pre>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.format","title":"format  <code>property</code>","text":"<pre><code>format: str\n</code></pre> <p>Get the formatted pattern string.</p>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.invalid_keys","title":"invalid_keys  <code>property</code>","text":"<pre><code>invalid_keys: typing.Set[str]\n</code></pre> <p>Get the set of invalid keys.</p> <p>Essentially, this will check <code>pydicom.dictionary_has_tag</code> for each key in the pattern and return the set of keys that are invalid.</p> <p>Returns:</p> Type Description <code>typing.Set[str]</code> <p>The set of invalid keys.</p>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.keys","title":"keys  <code>property</code>","text":"<pre><code>keys: typing.Set[str]\n</code></pre> <p>Get the set of keys extracted from the pattern.</p>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.pattern_preview","title":"pattern_preview  <code>property</code>","text":"<pre><code>pattern_preview: str\n</code></pre> <p>Returns a human readable preview of the pattern.</p> <p>Useful for visualizing the pattern structure and can be highlighted using Rich Console.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; target_pattern = \"%key1/%key2/%key3\"\n&gt;&gt;&gt; pattern_preview = \"{key1}/{key2}/{key3}\"\n</code></pre>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute","title":"execute","text":"<pre><code>execute(\n    action: (\n        imgtools.dicom.sort.FileAction | str\n    ) = imgtools.dicom.sort.FileAction.MOVE,\n    overwrite: bool = False,\n    dry_run: bool = False,\n    num_workers: int = 1,\n    truncate_uids: int = 5,\n) -&gt; None\n</code></pre> <p>Execute the file action on DICOM files.</p> <p>Users are encouraged to use FileAction.HARDLINK for efficient storage and performance for large dataset, as well as protection against lost data.</p> <p>Using hard links can save disk space and improve performance by creating multiple directory entries (links) for a single file instead of duplicating the file content. This is particularly useful when working with large datasets, such as DICOM files, where storage efficiency is crucial.</p> <p>Parameters:</p> Name Type Description Default <code>imgtools.dicom.sort.FileAction</code> <p>The action to apply to the DICOM files (e.g., move, copy).</p> <code>FileAction.MOVE</code> <code>bool</code> <p>If True, overwrite existing files at the destination.</p> <code>False</code> <code>bool</code> <p>If True, perform a dry run without making any changes.</p> <code>False</code> <code>int</code> <p>The number of worker threads to use for processing files.</p> <code>1</code> <code>int</code> <p>The number of characters to truncate from the UID.</p> <code>5</code> Source code in <code>src/imgtools/dicom/sort/dicomsorter.py</code> <pre><code>def execute(\n    self,\n    action: FileAction | str = FileAction.MOVE,\n    overwrite: bool = False,\n    dry_run: bool = False,\n    num_workers: int = 1,\n    truncate_uids: int = 5,\n) -&gt; None:\n    \"\"\"Execute the file action on DICOM files.\n\n    Users are encouraged to use FileAction.HARDLINK for\n    efficient storage and performance for large dataset, as well as\n    protection against lost data.\n\n    Using hard links can save disk space and improve performance by\n    creating multiple directory entries (links) for a single file\n    instead of duplicating the file content. This is particularly\n    useful when working with large datasets, such as DICOM files,\n    where storage efficiency is crucial.\n\n    Parameters\n    ----------\n    action : FileAction, default: FileAction.MOVE\n        The action to apply to the DICOM files (e.g., move, copy).\n    overwrite : bool, default: False\n        If True, overwrite existing files at the destination.\n    dry_run : bool, default: False\n        If True, perform a dry run without making any changes.\n    num_workers : int, default: 1\n        The number of worker threads to use for processing files.\n    truncate_uids : int, default: 5\n        The number of characters to truncate from the UID.\n\n    Raises\n    ------\n    ValueError\n            If the provided action is not a valid FileAction.\n    \"\"\"\n    if not isinstance(action, FileAction):\n        action = FileAction.validate(action)\n\n    self.logger.debug(\n        f\"Mapping {len(self.dicom_files)} files to new paths\"\n    )\n\n    # Create a progress bar that can be used to track everything\n    with self._progress_bar() as progress_bar:\n        ################################################################################\n        # Resolve new paths\n        ################################################################################\n        file_map: Dict[Path, Path] = self._resolve_new_paths(\n            progress_bar=progress_bar,\n            num_workers=num_workers,\n            truncate_uids=truncate_uids,\n        )\n    self.logger.info(\"Finished resolving paths\")\n\n    ################################################################################\n    # Check if any of the resolved paths are duplicates\n    ################################################################################\n    file_map = self._check_duplicates(file_map)\n    self.logger.info(\"Finished checking for duplicates\")\n\n    ################################################################################\n    # Handle files\n    ################################################################################\n    if dry_run:\n        self._dry_run(file_map)\n        return\n\n    with self._progress_bar() as progress_bar:\n        task_files = progress_bar.add_task(\n            \"Handling files\", total=len(file_map)\n        )\n        new_paths: List[Path | None] = []\n        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n            future_to_file = {\n                executor.submit(\n                    handle_file,\n                    source_path,\n                    resolved_path,\n                    action,\n                    overwrite,\n                ): source_path\n                for source_path, resolved_path in file_map.items()\n            }\n            for future in as_completed(future_to_file):\n                try:\n                    result = future.result()\n                    new_paths.append(result)\n                    progress_bar.update(task_files, advance=1)\n                except Exception as e:\n                    self.logger.exception(\n                        \"Failed to handle file\",\n                        exc_info=e,\n                        file=future_to_file[future],\n                    )\n</code></pre>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(action)","title":"<code>action</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(overwrite)","title":"<code>overwrite</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(dry_run)","title":"<code>dry_run</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(num_workers)","title":"<code>num_workers</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.execute(truncate_uids)","title":"<code>truncate_uids</code>","text":""},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.print_tree","title":"print_tree","text":"<pre><code>print_tree(base_dir: pathlib.Path | None = None) -&gt; None\n</code></pre> <p>Display the pattern structure as a tree visualization.</p> Notes <p>This only prints the target pattern, parsed and formatted. Performing a dry-run execute will display more information.</p> Source code in <code>src/imgtools/dicom/sort/sorter_base.py</code> <pre><code>def print_tree(self, base_dir: Path | None = None) -&gt; None:\n    \"\"\"\n    Display the pattern structure as a tree visualization.\n\n    Notes\n    -----\n    This only prints the target pattern, parsed and formatted.\n    Performing a dry-run execute will display more information.\n\n    Raises\n    ------\n    SorterBaseError\n        If the tree visualization fails to generate.\n    \"\"\"\n    try:\n        base_dir = base_dir or Path().cwd().resolve()\n        tree = self._setup_tree(base_dir)\n        self._generate_tree_structure(self.pattern_preview, tree)\n        self._console.print(tree)\n    except Exception as e:\n        errmsg = \"Failed to generate tree visualization.\"\n        raise SorterBaseError(errmsg) from e\n</code></pre>"},{"location":"reference/dicomsort/dicomsorter/#imgtools.dicom.sort.DICOMSorter.validate_keys","title":"validate_keys","text":"<pre><code>validate_keys() -&gt; None\n</code></pre> <p>Validate extracted keys. Subclasses should implement this method to perform specific validations based on their context.</p> <p>Validate the DICOM keys in the target pattern.</p> <p>If any invalid keys are found, it suggests similar valid keys and raises an error.</p> Source code in <code>src/imgtools/dicom/sort/dicomsorter.py</code> <pre><code>def validate_keys(self) -&gt; None:\n    \"\"\"Validate the DICOM keys in the target pattern.\n\n    If any invalid keys are found, it\n    suggests similar valid keys and raises an error.\n    \"\"\"\n    if not self.invalid_keys:\n        return\n\n    for key in sorted(self.invalid_keys):\n        # TODO: keep this logic, but make the suggestion more user-friendly/readable\n        similar = similar_tags(key)\n        suggestion = (\n            f\"\\n\\tDid you mean: [bold green]{', '.join(similar)}[/bold green]?\"\n            if similar\n            else \" And [bold red]no similar keys[/bold red] found.\"\n        )\n        _error = (\n            f\"Invalid DICOM key: [bold red]{key}[/bold red].{suggestion}\"\n        )\n        self._console.print(f\"{_error}\")\n    self._console.print(f\"Parsed Path: `{self.pattern_preview}`\")\n    errmsg = \"Invalid DICOM Keys found.\"\n    raise InvalidDICOMKeyError(errmsg)\n</code></pre>"},{"location":"reference/dicomsort/patternparser/","title":"PatternParser","text":""},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser","title":"parser","text":"<p>Parser module for extracting and validating placeholders from target patterns.</p> Summary <p>This module provides functionality to parse and validate sorting patterns with placeholders. Users can define custom regex patterns to extract keys from their sorting patterns.</p> Extended Summary <p>The <code>PatternParser</code> class allows users to define patterns with placeholders that can be replaced with actual values. The placeholders can be defined using custom regex patterns, making the parser flexible for various use cases.</p> <p>Examples:</p> <p>Setup:</p> <pre><code>&gt;&gt;&gt; import re\n&gt;&gt;&gt; from imgtools.dicom.sort.parser import (\n...     PatternParser,\n... )\n</code></pre> <p>Example 1: Suppose you want to parse a target pattern like <code>{Key1}-{Key2}</code> and replace the placeholders with values from a dictionary:</p> <pre><code>&gt;&gt;&gt; key_values = {\n...     \"Key1\": \"John\",\n...     \"Key2\": \"Doe\",\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; pattern = \"{Key1}-{Key2}\"\n&gt;&gt;&gt; pattern_matcher = re.compile(r\"\\{(\\w+)\\}\")\n&gt;&gt;&gt; parser = PatternParser(\n...     pattern,\n...     pattern_matcher,\n... )\n&gt;&gt;&gt; (\n...     formatted_pattern,\n...     keys,\n... ) = parser.parse()\n&gt;&gt;&gt; print(formatted_pattern)\n'%(Key1)s-%(Key2)s'\n&gt;&gt;&gt; print(keys)\n['Key1', 'Key2']\n</code></pre> <p>Now you can use the formatted pattern to replace the placeholders:</p> <pre><code>&gt;&gt;&gt; resolved_string = formatted_pattern % key_values\n&gt;&gt;&gt; print(resolved_string)\n'John-Doe'\n</code></pre> <p>Example 2: Suppose you want to parse a target pattern like <code>%&lt;Key1&gt; and {Key2}</code> and replace the placeholders with values from a dictionary:</p> <pre><code>&gt;&gt;&gt; key_values = {\n...     \"Key1\": \"Alice\",\n...     \"Key2\": \"Bob\",\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; pattern = \"%&lt;Key1&gt; and {Key2}\"\n&gt;&gt;&gt; pattern_matcher = re.compile(\n...     r\"%&lt;(\\w+)&gt;|\\{(\\w+)\\}\"\n... )\n&gt;&gt;&gt; parser = PatternParser(\n...     pattern,\n...     pattern_matcher,\n... )\n&gt;&gt;&gt; (\n...     formatted_pattern,\n...     keys,\n... ) = parser.parse()\n&gt;&gt;&gt; print(formatted_pattern)\n'%(Key1)s and %(Key2)s'\n&gt;&gt;&gt; print(keys)\n['Key1', 'Key2']\n</code></pre> <p>Now you can use the formatted pattern to replace the placeholders:</p> <pre><code>&gt;&gt;&gt; resolved_string = formatted_pattern % key_values\n&gt;&gt;&gt; print(resolved_string)\n'Alice and Bob'\n</code></pre> <p>Example 3: Suppose you want to parse a target pattern like <code>/path/to/{Key1}/and/{Key2}</code> and replace the placeholders with values from a dictionary:</p> <pre><code>&gt;&gt;&gt; key_values = {\n...     \"Key1\": \"folder1\",\n...     \"Key2\": \"folder2\",\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; pattern = \"/path/to/{Key1}/and/{Key2}\"\n&gt;&gt;&gt; pattern_matcher = re.compile(r\"\\{(\\w+)\\}\")\n&gt;&gt;&gt; parser = PatternParser(\n...     pattern,\n...     pattern_matcher,\n... )\n&gt;&gt;&gt; (\n...     formatted_pattern,\n...     keys,\n... ) = parser.parse()\n&gt;&gt;&gt; print(formatted_pattern)\n'/path/to/%(Key1)s/and/%(Key2)s'\n&gt;&gt;&gt; print(keys)\n['Key1', 'Key2']\n</code></pre> <p>Now you can use the formatted pattern to replace the placeholders:</p> <pre><code>&gt;&gt;&gt; resolved_string = formatted_pattern % key_values\n&gt;&gt;&gt; print(resolved_string)\n'/path/to/folder1/and/folder2'\n</code></pre>"},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser","title":"PatternParser","text":"<pre><code>PatternParser(\n    pattern: str, pattern_matcher: typing.Pattern\n)\n</code></pre> <p>A helper class to parse, validate, and sanitize sorting patterns.</p> <p>This class handles: - Pattern parsing and validation - Key extraction from patterns</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The pattern string to parse.</p> required <code>typing.Pattern</code> <p>Custom regex pattern for parsing</p> required <p>Attributes:</p> Name Type Description <code>keys</code> <code>list of str</code> <p>Extracted keys from the pattern.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import re\n&gt;&gt;&gt; from imgtools.dicom.sort.parser import (\n...     PatternParser,\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; key_values = {\n...     \"Key1\": \"Value1\",\n...     \"Key2\": \"Value2\",\n... }\n&gt;&gt;&gt; pattern = \"{Key1}-{Key2}\"\n&gt;&gt;&gt; pattern_matcher = re.compile(r\"\\{(\\w+)\\}\")\n&gt;&gt;&gt; parser = PatternParser(\n...     pattern,\n...     pattern_matcher,\n... )\n&gt;&gt;&gt; (\n...     formatted_pattern,\n...     keys,\n... ) = parser.parse()\n&gt;&gt;&gt; print(formatted_pattern)\n'%(Key1)s-%(Key2)s'\n&gt;&gt;&gt; print(keys)\n['Key1', 'Key2']\n&gt;&gt;&gt; resolved_string = formatted_pattern % key_values\n&gt;&gt;&gt; print(resolved_string)\n'Value1-Value2'\n</code></pre> <p>Methods:</p> Name Description <code>parse</code> <p>Parse and validate the pattern.</p> Source code in <code>src/imgtools/pattern_parser/parser.py</code> <pre><code>def __init__(self, pattern: str, pattern_matcher: Pattern) -&gt; None:\n    assert isinstance(pattern, str) and pattern, (\n        \"Pattern must be a non-empty string.\"\n    )\n    self._pattern = pattern\n    self._keys: List[str] = []\n    assert isinstance(pattern_matcher, Pattern), (\n        \"Pattern parser must be a regex pattern.\"\n    )\n    self._parser: Pattern = pattern_matcher\n</code></pre>"},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser(pattern)","title":"<code>pattern</code>","text":""},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser(pattern_matcher)","title":"<code>pattern_matcher</code>","text":""},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser.keys","title":"keys  <code>property</code>","text":"<pre><code>keys: typing.List[str]\n</code></pre> <p>Get the list of extracted keys.</p>"},{"location":"reference/dicomsort/patternparser/#imgtools.pattern_parser.parser.PatternParser.parse","title":"parse","text":"<pre><code>parse() -&gt; typing.Tuple[str, typing.List[str]]\n</code></pre> <p>Parse and validate the pattern.</p> <p>Returns:</p> Type Description <code>typing.Tuple[str, typing.List[str]]</code> <p>The formatted pattern string and a list of extracted keys.</p> Source code in <code>src/imgtools/pattern_parser/parser.py</code> <pre><code>def parse(self) -&gt; Tuple[str, List[str]]:\n    \"\"\"\n    Parse and validate the pattern.\n\n    Returns\n    -------\n    Tuple[str, List[str]]\n        The formatted pattern string and a list of extracted keys.\n\n    Raises\n    ------\n    InvalidPatternError\n        If the pattern contains no valid placeholders or is invalid.\n    \"\"\"\n\n    sanitized_pattern = self._pattern.strip()\n    if not self._parser.search(sanitized_pattern):\n        errmsg = f\"Pattern must contain placeholders matching '{self._parser.pattern}'.\"\n        raise InvalidPatternError(errmsg)\n\n    formatted_pattern = self._parser.sub(\n        self._replace_key, sanitized_pattern\n    )\n    return formatted_pattern, self._keys\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>The following documentation is a work-in-progress. If you encounter any issues or discrepencies, please let us know by opening an issue.</p>"},{"location":"usage/CoreTypes/regionbox/","title":"RegionBox: A Simple Way to Work with 3D Image Regions","text":"In\u00a0[2]: Copied! <pre>from imgtools import Coordinate3D, RegionBox\nfrom rich import print\n\n# Define a box from (5,5,5) to (10,10,10)\nbox = RegionBox(Coordinate3D(5, 5, 5), Coordinate3D(10, 10, 10))\n\nprint(box)\n</pre> from imgtools import Coordinate3D, RegionBox from rich import print  # Define a box from (5,5,5) to (10,10,10) box = RegionBox(Coordinate3D(5, 5, 5), Coordinate3D(10, 10, 10))  print(box) <pre>RegionBox(\n        min=Coordinate3D(x=5, y=5, z=5),\n        max=Coordinate3D(x=10, y=10, z=10)\n        size=Size3D(w=5, h=5, d=5)\n)\n</pre> In\u00a0[3]: Copied! <pre># Expand the box symmetrically by 5 units in all directions\nexpanded_box = box.pad(5)\nprint(expanded_box)\n</pre> # Expand the box symmetrically by 5 units in all directions expanded_box = box.pad(5) print(expanded_box) <pre>RegionBox(\n        min=Coordinate3D(x=0, y=0, z=0),\n        max=Coordinate3D(x=15, y=15, z=15)\n        size=Size3D(w=15, h=15, d=15)\n)\n</pre> <p>By default, the box expands equally in all directions by <code>padding</code> voxels.</p> <p>If you only want to expand in one direction (the max side), use the <code>BoxPadMethod.END</code> option:</p> In\u00a0[9]: Copied! <pre>from imgtools import BoxPadMethod\n\nend_padded_box = box.pad(5, method=BoxPadMethod.END)\nprint(end_padded_box)\n</pre> from imgtools import BoxPadMethod  end_padded_box = box.pad(5, method=BoxPadMethod.END) print(end_padded_box) <pre>RegionBox(\n        min=Coordinate3D(x=5, y=5, z=5),\n        max=Coordinate3D(x=15, y=15, z=15)\n        size=Size3D(w=10, h=10, d=10)\n)\n</pre> In\u00a0[15]: Copied! <pre>from imgtools.datasets import example_data\n\nmask = example_data()['mask']\n\n# Create a box around the mask's bounding box\nbbox_region = RegionBox.from_mask_bbox(mask)\nprint(bbox_region)\n</pre> from imgtools.datasets import example_data  mask = example_data()['mask']  # Create a box around the mask's bounding box bbox_region = RegionBox.from_mask_bbox(mask) print(bbox_region) <pre>RegionBox(\n        min=Coordinate3D(x=45, y=21, z=67),\n        max=Coordinate3D(x=55, y=38, z=84)\n        size=Size3D(w=10, h=17, d=17)\n)\n</pre> <p>You can create a <code>RegionBox</code> from the centroid of the mask.</p> <p>This will create a <code>RegionBox</code> of size 0, where the min and max points are the same.</p> <p>However, you can expand the box to include more context around the mask.</p> In\u00a0[13]: Copied! <pre># Create a box around the mask's centroid\ncentroid_box = RegionBox.from_mask_centroid(mask)\nprint(centroid_box)\n\nexpanded_centroid_box = centroid_box.expand_to_min_size(10)\nprint(expanded_centroid_box)\n</pre> # Create a box around the mask's centroid centroid_box = RegionBox.from_mask_centroid(mask) print(centroid_box)  expanded_centroid_box = centroid_box.expand_to_min_size(10) print(expanded_centroid_box) <pre>RegionBox(\n        min=Coordinate3D(x=50, y=29, z=76),\n        max=Coordinate3D(x=50, y=29, z=76)\n        size=Size3D(w=0, h=0, d=0)\n)\n</pre> <pre>RegionBox(\n        min=Coordinate3D(x=45, y=24, z=71),\n        max=Coordinate3D(x=55, y=34, z=81)\n        size=Size3D(w=10, h=10, d=10)\n)\n</pre> In\u00a0[16]: Copied! <pre>import SimpleITK as sitk\n\n# Load an example image (100x100x100 voxel CT scan)\nimage = example_data()['duck']\n\ncropped_image = bbox_region.crop_image(image)\nprint(cropped_image.GetSize())\n</pre> import SimpleITK as sitk  # Load an example image (100x100x100 voxel CT scan) image = example_data()['duck']  cropped_image = bbox_region.crop_image(image) print(cropped_image.GetSize()) <pre>(10, 17, 17)\n</pre> <p>You can also crop both the image and the mask at the same time.</p> In\u00a0[18]: Copied! <pre>cropped_image, cropped_mask = bbox_region.crop_image_and_mask(image, mask)\n\nprint(cropped_image.GetSize())\nprint(cropped_mask.GetSize())\n</pre> cropped_image, cropped_mask = bbox_region.crop_image_and_mask(image, mask)  print(cropped_image.GetSize()) print(cropped_mask.GetSize()) <pre>(10, 17, 17)\n</pre> <pre>(10, 17, 17)\n</pre> In\u00a0[24]: Copied! <pre># Perform multiple steps together\ncropped_image, cropped_mask = (\n  RegionBox.from_mask_centroid(mask)\n    .expand_to_min_size(20)\n    .crop_image_and_mask(image, mask)\n)\n\nprint(cropped_image.GetSize())\nprint(cropped_mask.GetSize())\n</pre> # Perform multiple steps together cropped_image, cropped_mask = (   RegionBox.from_mask_centroid(mask)     .expand_to_min_size(20)     .crop_image_and_mask(image, mask) )  print(cropped_image.GetSize()) print(cropped_mask.GetSize()) <pre>(20, 20, 20)\n</pre> <pre>(20, 20, 20)\n</pre>"},{"location":"usage/CoreTypes/regionbox/#regionbox-a-simple-way-to-work-with-3d-image-regions","title":"RegionBox: A Simple Way to Work with 3D Image Regions\u00b6","text":""},{"location":"usage/CoreTypes/regionbox/#overview","title":"Overview\u00b6","text":"<p>The <code>RegionBox</code> class helps define, manipulate, and extract regions from 3D images. If you're working with medical images (like CT or MRI scans), you'll often need to isolate specific areas\u2014whether for visualization, processing, or deep learning tasks.</p> <p>With <code>RegionBox</code>, you can:</p> <ul> <li>Define a 3D box with minimum and maximum coordinates.</li> <li>Expand, pad, or adjust the box.</li> <li>Extract regions from images.</li> <li>Create a <code>RegionBox</code> from segmentation masks.</li> </ul>"},{"location":"usage/CoreTypes/regionbox/#getting-started","title":"Getting Started\u00b6","text":"<p>To create a <code>RegionBox</code>, all you need are two 3D points: the minimum (corner closest to the origin) and the maximum (opposite corner).</p>"},{"location":"usage/CoreTypes/regionbox/#working-with-regionbox","title":"Working with RegionBox\u00b6","text":""},{"location":"usage/CoreTypes/regionbox/#expanding-the-box","title":"Expanding the Box\u00b6","text":"<p>Sometimes, you need to make the box bigger\u2014whether to ensure it contains enough context or meets a minimum required size.</p>"},{"location":"usage/CoreTypes/regionbox/#creating-a-regionbox-from-a-mask","title":"Creating a RegionBox from a Mask\u00b6","text":"<p>If you have a segmentation mask (where a structure of interest is labeled), you can automatically create a <code>RegionBox</code> around it.</p>"},{"location":"usage/CoreTypes/regionbox/#cropping-an-image","title":"Cropping an Image\u00b6","text":"<p>Once you have a <code>RegionBox</code>, you can crop an image to the exact region. This is useful when extracting specific anatomical structures.</p>"},{"location":"usage/CoreTypes/regionbox/#summary","title":"Summary\u00b6","text":"<p>The <code>RegionBox</code> class makes it easy to define, manipulate, and extract regions from 3D images. Whether you're cropping scans or defining analysis regions, it provides a simple and flexible interface.</p> <p>Key features:</p> <ul> <li>Define regions with <code>RegionBox(min, max)</code>.</li> <li>Expand regions with <code>.pad()</code>, <code>.expand_to_cube()</code>, etc.</li> <li>Extract image regions using <code>.crop_image()</code>.</li> <li>Create boxes from masks with <code>.from_mask_bbox()</code> or <code>.from_mask_centroid()</code>.</li> </ul> <p>Try it out and make working with medical image regions easier!</p>"},{"location":"usage/Dicom/interlacer/","title":"Interlacer Module","text":"<p>The Interlacer module builds and searches a tree-like structure made from DICOM series using metadata links. </p> <p>This tool enables efficient grouping, querying, and vizualization of medical imaging series, making it easier to understand the complex relationships between various imaging modalities (CT, MR, PT) and derived objects (RTSTRUCT, RTDOSE, SEG)</p> <p>Note</p> <p>This module is available in <code>med-imagetools 2.0</code> and later versions. It replaces the now deprecated <code>DataGraph</code> module from <code>med-imagetools 1.0</code>.</p>"},{"location":"usage/Dicom/interlacer/#overview","title":"Overview","text":"<p>This module turns DICOM series into a set of trees (a forest), using metadata to connect related series. This helps users follow the relationships between series \u2014 for example, linking a <code>CT</code> scan to its <code>RTSTRUCT</code> and <code>RTDOSE</code> \u2014 and makes it easier to run queries or group series by type.</p>"},{"location":"usage/Dicom/interlacer/#main-classes","title":"Main Classes","text":""},{"location":"usage/Dicom/interlacer/#seriesnode","title":"<code>SeriesNode</code>","text":"<p>Represents an individual DICOM series and its hierarchical relationships:</p> <ul> <li>Attributes:</li> <li><code>SeriesInstanceUID</code></li> <li><code>Modality</code></li> <li><code>PatientID</code></li> <li><code>StudyInstanceUID</code></li> <li><code>folder</code>: Path to the folder containing the DICOM files</li> <li><code>ReferencedSeriesUID</code>: Series that this one references, if any</li> <li><code>children</code>: List of child nodes representing referenced series<ul> <li>i.e a <code>CT</code> series might have 1 or more links to <code>RTSTRUCT</code> and/or  <code>PT</code> series</li> </ul> </li> </ul>"},{"location":"usage/Dicom/interlacer/#interlacer","title":"<code>Interlacer</code>","text":"<p>Key features:</p> <ul> <li>Query validation: Ensures that modality queries follow DICOM standard requirements</li> <li>Interactive visualization: Creates HTML-based network graphs of relationships</li> <li>Rich text console display: Pretty-prints the hierarchy with color-coding</li> <li>Dependency validation: Enforces rules like \"RTSTRUCT requires CT, MR, or PT\"</li> </ul>"},{"location":"usage/Dicom/interlacer/#grouping-series","title":"Grouping Series","text":"<p>The Interlacer currently groups series using Referenced Series UID, which links series based on their metadata references (i.e the <code>ReferencedSeriesInstanceUID</code> tag in <code>RTSTRUCT</code>s). This creates a hierarchical structure showing the relationships between different series.</p> <p>Future Development</p> <p>In a future release, the Interlacer will support additional grouping methods:</p> <ul> <li>Study Instance UID \u2013 Group everything in the same study</li> <li>Patient ID \u2013 Group all series from the same patient</li> </ul> <p>This enhancement is being tracked in GitHub issue #318.</p>"},{"location":"usage/Dicom/interlacer/#usage-example","title":"Usage Example","text":"<pre><code>from pathlib import Path\nfrom imgtools.dicom.crawl import Crawler\nfrom imgtools.dicom.interlacer import Interlacer\n\n# Define path to DICOM directory\ndicom_dir = Path(\"data/\")\n\n# Create crawler and scan the directory\ncrawler = Crawler(\n    dicom_dir=dicom_dir,\n    n_jobs=5,\n    force=False,\n)\ncrawler.crawl()\n\n# Create the Interlacer from crawler results\ninterlacer = Interlacer(crawler.index)\n\n# Visualize the forest structure\ninterlacer.print_tree(dicom_dir)  # Console visualization\n\n# Query for specific modality combinations\n# Find CT series with associated RTSTRUCT objects\nct_rtstruct_results = interlacer.query(\"CT,RTSTRUCT\")\n\n# Get all possible series combinations\nall_results = interlacer.query(\"*\")  # or interlacer.query(\"all\")\n</code></pre>"},{"location":"usage/Dicom/interlacer/#query-rules-and-dependencies","title":"Query Rules and Dependencies","text":"<p>The Interlacer enforces the following modality dependency rules:</p> <ol> <li><code>RTSTRUCT</code> and <code>RTDOSE</code> require a <code>CT</code>, <code>MR</code>, or <code>PT</code> series</li> <li><code>SEG</code> requires a <code>CT</code> or <code>MR</code> series</li> </ol> <p>Examples of valid and invalid queries:</p> <ul> <li>\u2705 <code>\"CT,RTDOSE\"</code> - Valid: CT with associated RTDOSE</li> <li>\u2705 <code>\"CT,PT,RTSTRUCT\"</code> - Valid: CT and PT with associated RTSTRUCT</li> <li>\u274c <code>\"PT,SEG\"</code> - Invalid: SEG requires CT or MR, not PT</li> <li>\u274c <code>\"RTSTRUCT,RTDOSE\"</code> - Invalid: Both require a source imaging series</li> </ul>"},{"location":"usage/Dicom/interlacer/#example-output","title":"Example Output","text":"<p>The raw graph of all series in the DICOM directory:</p> <p></p> <p>The interlaced connections between series:</p> <p></p>"},{"location":"usage/Writers/BaseWriter/","title":"Abstract Base Writer","text":"<p>The <code>AbstractBaseWriter</code> class is the foundation for all writers in this library.</p> <p>It provides a standard interface, reusable methods, and tools that writers can extend to handle file writing tasks efficiently and consistently.</p> <p>If you're building a writer to manage file outputs with custom paths, filenames, or formats, this is where you start!</p> <p>For details on implementing the <code>AbstractBaseWriter</code> in your custom writer, see the Implementing Writers guide.</p>"},{"location":"usage/Writers/BaseWriter/#introduction","title":"Introduction","text":""},{"location":"usage/Writers/BaseWriter/#what-is-the-abstractbasewriter","title":"What is the <code>AbstractBaseWriter</code>?","text":"<p>The <code>AbstractBaseWriter</code> is:</p> <ul> <li>A reusable template: Manage file-writing tasks consistently across different writer implementations.  </li> <li>Customizable: Extend it to handle your file formats and workflows.  </li> <li>Safe and robust: Features context management, filename sanitization, and optional CSV indexing.  </li> </ul>"},{"location":"usage/Writers/BaseWriter/#when-should-you-extend-abstractbasewriter-for-your-custom-writer","title":"When should you extend <code>AbstractBaseWriter</code> for your custom writer?","text":"<p>If you write many files with dynamic paths and filenames, or need to manage file existence scenarios, you might consider extending <code>AbstractBaseWriter</code> (or even one of its subclasses) to simplify your implementation.</p> <p><code>AbstractBaseWriter</code> is useful when you need:</p> <ul> <li>Dynamic paths and filenames (e.g., <code>{subject_id}/{study_date}.nii.gz</code>).  </li> <li>Configurable handling of existing files (<code>OVERWRITE</code>, <code>SKIP</code>, etc.).  </li> <li>Logging of saved files via an optional CSV index.  </li> <li>Thread-safe and multiprocessing-compatible file writing.  </li> <li>A consistent interface across different types of writers.  </li> </ul>"},{"location":"usage/Writers/BaseWriter/#core-concepts","title":"Core Concepts","text":""},{"location":"usage/Writers/BaseWriter/#root-directory-and-filename-format-parameters","title":"Root Directory and Filename Format Parameters","text":"<p>Root Directory:</p> <ul> <li>Base folder for all saved files, automatically created if missing (via <code>create_dirs</code> parameter)</li> </ul> <p>Filename Format:</p> <ul> <li>A string template defining your file and folder names.  </li> <li>Uses placeholders like <code>{key}</code> to insert context values dynamically.  </li> </ul> <p>Example:</p> <pre><code>writer = ExampleWriter(\n    root_directory=\"./data\",\n    filename_format=\"{person_name}/{date}_{message_type}.txt\",\n)\n\n# Save a file with context variables\ndata = \"Hello, World!\"\nwriter.save(\n  data, \n  person_name=\"JohnDoe\",\n  date=\"2025-01-01\",\n  message_type=\"greeting\"\n)\n\n# Saved file path: \n# ./data/JohnDoe/2025-01-01_greeting.txt\n</code></pre>"},{"location":"usage/Writers/BaseWriter/#file-existence-modes","title":"File Existence Modes","text":"<p>Why It Matters:</p> <ul> <li>When your writer saves a file, it needs to decide what to do if a file with the same name already exists.</li> <li>This is especially important in batch operations or when writing to shared directories.</li> <li>The <code>AbstractBaseWriter</code> provides several options to handle this scenario through the use of   an <code>enum</code> called <code>ExistingFileMode</code>.</li> </ul> <p>It is important to handle these options carefully in your writer's <code>save()</code> method to avoid data loss or conflicts.</p>"},{"location":"usage/Writers/BaseWriter/#imgtools.io.writers.ExistingFileMode","title":"ExistingFileMode","text":"<p>Enum to specify handling behavior for existing files.</p> <p>Attributes:</p> Name Type Description <code>OVERWRITE</code> <code>str</code> <p>Overwrite the existing file. Logs as debug and continues with the operation.</p> <code>FAIL</code> <code>str</code> <p>Fail the operation if the file exists. Logs as error and raises a FileExistsError.</p> <code>SKIP</code> <code>str</code> <p>Skip the operation if the file exists. Meant to be used for previewing the path before any expensive computation. <code>preview_path()</code> will return None if the file exists. <code>resolve_path()</code> will still return the path even if the file exists. The writer's <code>save</code> method should handle the file existence if set to SKIP.</p>"},{"location":"usage/Writers/BaseWriter/#advanced-concepts","title":"Advanced Concepts","text":""},{"location":"usage/Writers/BaseWriter/#lifecycle-management","title":"Lifecycle Management","text":"<p>Context Manager Support:</p> <ul> <li>Writers can be used with <code>with</code> statements to ensure proper setup and cleanup.  </li> </ul> <p>What Happens on Exit?:</p> <ul> <li>Removes lock files used for the index file.  </li> <li>Deletes empty directories created during the writing process (if no files were written).  </li> </ul> <p>Example:</p> <pre><code>with TextWriter(root_directory=\"/data\", filename_format=\"{id}.txt\") as writer:\n  data = \"Hello, World!\"\n  writer.save(data, id=\"1234\")\n</code></pre>"},{"location":"usage/Writers/BaseWriter/#previewing-file-paths-and-caching-context","title":"Previewing File Paths and Caching Context","text":"<p>In the simplest usage of a writer, users can pass in the context information as keyword arguments to each <code>save()</code> call.</p> <p>However, this can become cumbersome when the same context variables are used across multiple save operations.</p> <p>Example:</p> <p>In the above example, the <code>date</code> and <code>message_type</code> context variables are the same for all students. Instead of passing them in every time, you can store these variables in the writer itself and update them as needed.</p> <p>Let's use the following example to illustrate this:</p> <p>Say we want to save greetings for students in a particular highschool class:</p> <pre><code>writer = TextWriter(\n    root_directory=\"./data\",\n    filename_format=\"{grade}/{class_subject}/{person_name}/{date}_{message_type}.txt\",\n)\n</code></pre> Basic UsageSetting Context Variables manuallySetting Context Variables during Initialization <p>We see here that the context variables for <code>grade</code>, <code>class_subject</code>, <code>date</code>, and <code>message_type</code> are the same for all students.</p> <p>This can become even worse with more context variables, allowing for mistakes, and making the code harder to read.</p> <pre><code>student, message = \"Alice\", \"Hello, Alice!\"\nwriter.save(\n    message,\n    person_name=student,\n    grade=\"12\",\n    class_subject=\"math\",\n    date=\"2025-01-01\",\n    message_type=\"greeting\"\n)\n\nstudent, message = \"Bob\", \"Good morning, Bob!\"\nwriter.save(\n    message,\n    person_name=student,\n    grade=\"12\",\n    class_subject=\"math\",\n    date=\"2025-01-01\",\n    message_type=\"greeting\"\n)\n</code></pre> <p>Instead of passing in the context variables every time, you can store these variables in the writer and update them as needed using the <code>set_context()</code> method.</p> <p>Then only pass in the unique context variables for each <code>.save()</code> operation.</p> <pre><code>writer.set_context(\n  grade=\"12\",\n  class_subject=\"math\",\n  date=\"2025-01-01\",\n  message_type=\"greeting\"\n)\n\nstudent, message = \"Alice\", \"Hello, Alice!\"\nwriter.save(message, person_name=student)\n\nstudent, message = \"Bob\", \"Good morning, Bob!\"\nwriter.save(message, person_name=student)\n</code></pre> <p>If majority of the context variables are the same across all save  operations, you can set context when initializing the writer.</p> <p>Note that here, we must pass as a dictionary to the <code>context</code> parameter  instead of individual keyword arguments.</p> <pre><code>writer = TextWriter(\n    root_directory=\"./data\",\n    filename_format=\"{class_subject}/{person_name}/{date}_{message_type}.txt\",\n    context={\"grade\": \"12\", \"class_subject\": \"math\", \"date\": \"2025-01-01\", \"message_type\": \"greeting\"}\n)\n\nstudent, message = \"Alice\", \"Hello, Alice!\"\nwriter.save(message, person_name=student)\n\nstudent, message = \"Bob\", \"Good morning, Bob!\"\nwriter.save(message, person_name=student)\n</code></pre>"},{"location":"usage/Writers/BaseWriter/#previewing-file-paths","title":"Previewing File Paths","text":"<p>Oftentimes, you may want to check if a file exists before performing an expensive computation. If you set the existence mode to <code>ExistingFileMode.SKIP</code>, the <code>preview_path()</code> method will return <code>None</code> if the file already exists, allowing you to skip the computation.</p> <p>This method also caches the additional context variables for future use.</p> <p>Here's an example of how you might handle this:</p> <pre><code># assuming writer is already initialized with `existing_file_mode=ExistingFileMode.SKIP`\n\n# set some context variables\nwriter.set_context(class_subject=\"math\", date=\"2025-01-01\", message_type=\"greeting\")\n\nif (path := writer.preview_path(person_name=\"Alice\")) is None:\n    print(\"File already exists, skipping computation.\")\nelse:\n    print(f\"Proceed with computation for {path}\")\n    ... \n    # perform expensive computation \n    ...\n    writer.save(content=\"Hello, world!\")\n</code></pre>"},{"location":"usage/Writers/BaseWriter/#index-file-management","title":"Index File Management","text":"<p>What is the Index File?:</p> <ul> <li>A CSV file used to log details about saved files, like their paths and context variables.  </li> <li>Helps track what files have been written, especially useful in batch operations.</li> <li>Additionally can save all the context variables used for each file, convienient for   saving additional metadata, while improving traceability.</li> </ul> <p>How It Works:</p> <ul> <li>The AbstractBaseWriter now uses the powerful <code>IndexWriter</code> class to handle all index operations</li> <li>By default, the index file is named <code>{root_directory.name}_index.csv</code></li> <li>You can customize the filename or provide an absolute path for more control</li> <li>When implementing a writer class, call <code>add_to_index(path)</code> in your <code>save()</code> method to record saved files</li> </ul> <p>Key Features:</p> <ul> <li>Customizable Filename: Use <code>index_filename</code> to set a custom name or absolute path.</li> <li>Absolute/Relative Paths: Control file paths in the index with <code>absolute_paths_in_index</code> (defaults to relative).</li> <li>Schema Evolution: Control schema evolution with the <code>merge_columns</code> parameter when calling <code>add_to_index()</code>.</li> <li>Safe Concurrent Access: Uses inter-process locking for thread-safe operations in multi-process environments.</li> <li>Robust Error Handling: Specific exceptions for index-related errors to help troubleshoot issues.</li> </ul> <p>Using the add_to_index Method:</p> <pre><code># In your writer's save method:\ndef save(self, content, **kwargs):\n    output_path = self.resolve_path(**kwargs)\n\n    # Write your content to the file...\n\n    # Record this file in the index, with optional parameters:\n    self.add_to_index(\n        path=output_path,\n        include_all_context=True,   # Include all context variables, not just those used in the filename\n        filepath_column=\"path\",     # Name of the column to store file paths\n        replace_existing=False,     # Whether to replace existing entries for the same file\n        merge_columns=True          # Whether to allow schema evolution\n    )\n\n    return output_path\n</code></pre> <p>Schema Evolution with merge_columns:</p> <p>The <code>merge_columns</code> parameter (defaults to <code>True</code>) controls how the IndexWriter handles changes to your data schema:</p> <ul> <li>When <code>True</code>: If your context has new fields that didn't exist in previous CSV entries, they'll be added as new columns. This is great for:</li> <li>Iterative development when you're adding new metadata fields</li> <li>Different processes writing files with slightly different context variables</li> <li> <p>Ensuring backward compatibility with existing index files</p> </li> <li> <p>When <code>False</code>: Strict schema enforcement is applied. The IndexWriter will raise an error if the columns don't match exactly what's already in the index file. This is useful when:</p> </li> <li>You want to enforce a consistent schema across all entries</li> <li>You're concerned about typos or unintended fields creeping into your index</li> <li>Data consistency is critical for downstream processing</li> </ul>"},{"location":"usage/Writers/BaseWriter/#sanitizing-filenames","title":"Sanitizing Filenames","text":"<p>Why Sanitize Filenames?:</p> <ul> <li>To ensure that filenames are safe and compatible across different operating systems.  </li> </ul> <p>How It Works:</p> <ul> <li>Replaces illegal characters (e.g., <code>&lt;</code>, <code>&gt;</code>, <code>:</code>, <code>\"</code>, <code>/</code>, <code>\\</code>, <code>|</code>, <code>?</code>, <code>*</code>) with underscores.  </li> <li>Trims leading or trailing spaces and periods to avoid issues.</li> </ul> <p>When Is It Applied?:</p> <ul> <li>Automatically applied when generating filenames, unless disabled by setting <code>sanitize_filenames=False</code>.</li> </ul>"},{"location":"usage/Writers/BaseWriter/#multiprocessing-compatibility","title":"Multiprocessing Compatibility","text":"<p>Why It Matters:</p> <ul> <li>In batch operations or high-performance use cases, multiple processes may write files simultaneously.  </li> </ul> <p>Key Features:</p> <ul> <li>Supports multiprocessing with inter-process locking to ensure thread-safe file writes.  </li> <li>Avoids conflicts or data corruption when multiple instances of a writer are running.</li> </ul>"},{"location":"usage/Writers/ImplementingWriters/","title":"Extending the <code>AbstractBaseWriter</code> class","text":"<p>The <code>AbstractBaseWriter</code> is designed to be extended, allowing you to create custom writers tailored to your specific needs. This guide will walk you through the steps to extend the class and implement your custom functionality.</p>"},{"location":"usage/Writers/ImplementingWriters/#setting-up-your-writer","title":"Setting Up Your Writer","text":"<p>To create a custom writer, you need to extend the <code>AbstractBaseWriter</code> and implement the <code>save</code> method. This method is the core of your writer, handling how and where data is saved.</p> <p>For a walkthrough of all key methods and features, see the Key Methods section below.</p>"},{"location":"usage/Writers/ImplementingWriters/#steps-to-set-up","title":"Steps to Set Up","text":"<ol> <li> <p>Inherit from <code>AbstractBaseWriter</code>:    Create a new class and extend <code>AbstractBaseWriter</code> with the appropriate type.    If you are saving text data, use <code>AbstractBaseWriter[str]</code>, for example.    If you are saving image data, use <code>AbstractBaseWriter[sitk.Image]</code>.</p> </li> <li> <p>Define the <code>save</code> Method:   Use <code>resolve_path()</code> or <code>preview_path()</code> to generate file paths.   Implement the logic for saving data.  </p> </li> <li> <p>Customize Behavior (Optional):   Override any existing methods for specific behavior.   Add additional methods or properties to enhance functionality.  </p> </li> </ol>"},{"location":"usage/Writers/ImplementingWriters/#simple-example","title":"Simple Example","text":"<pre><code>from pathlib import Path\nfrom imgtools.io import AbstractBaseWriter\n\nclass MyCustomWriter(AbstractBaseWriter[str]):\n    def save(self, content: str, **kwargs) -&gt; Path:\n        # Resolve the output file path\n        output_path = self.resolve_path(**kwargs)\n\n        # Write content to the file\n        with output_path.open(mode=\"w\", encoding=\"utf-8\") as f:\n            f.write(content)\n\n        # Log and track the save operation using the new IndexWriter\n        self.add_to_index(output_path)\n\n        return output_path\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#implementing-the-save-method","title":"Implementing the <code>save</code> Method","text":"<p>The <code>save</code> method is the heart of your custom writer. It determines how data is written to files and interacts with the core features of <code>AbstractBaseWriter</code>.</p>"},{"location":"usage/Writers/ImplementingWriters/#key-responsibilities-of-save","title":"Key Responsibilities of <code>save</code>","text":"<ol> <li> <p>Path Resolution:</p> <ul> <li>Use <code>resolve_path()</code> to dynamically generate file paths based on the provided     context and filename format.</li> <li>You can optionally use <code>preview_path()</code> as well.</li> <li>Ensure paths are validated to prevent overwriting or duplication.</li> </ul> </li> <li> <p>Data Writing:  </p> <ul> <li>Define how the content will be written to the resolved path.  </li> <li>Use file-handling best practices to ensure reliability.</li> </ul> </li> <li> <p>Logging and Tracking:  </p> <ul> <li>Log each save operation for debugging or auditing purposes.  </li> <li>Use <code>add_to_index()</code> to maintain a record of saved files and their associated     context variables.</li> </ul> </li> <li> <p>Return Value:  </p> <ul> <li>Return the <code>Path</code> object representing the saved file.  </li> <li>This allows users to access the file path for further processing or verification.</li> </ul> </li> </ol>"},{"location":"usage/Writers/ImplementingWriters/#example-implementation","title":"Example Implementation","text":"<p>Here's a minimal implementation of the <code>save</code> method for a custom writer.</p> <pre><code>from pathlib import Path\nfrom mypackage.abstract_base_writer import AbstractBaseWriter\n\nclass MyCustomWriter(AbstractBaseWriter[str]):\n    def save(self, content: str, **kwargs) -&gt; Path:\n        # Step 1: Resolve the output file path\n        # you can try-catch this in case set to \"FAIL\" mode\n        # or just let the error propagate\n        output_path = self.resolve_path(**kwargs) # resolve_path will always return the path\n\n        # OPTIONAL handling for \"SKIP\" modes\n        if output_path.exists():\n            # this will only be true if the file existence mode\n            # is set to SKIP\n            # - OVERWRITE will have already deleted the file\n            # - upto developer to choose to handle this if set to SKIP\n            pass\n\n        # Step 2: Write the content to the resolved path\n        with output_path.open(mode=\"w\", encoding=\"utf-8\") as f:\n            f.write(content)\n\n        # Step 3: Log and track the save operation\n        self.add_to_index(\n            path=output_path,\n            include_all_context=True,\n            filepath_column=\"filepath\", \n            replace_existing=False,\n            merge_columns=True,\n        )\n\n        # Step 4: ALWAYS Return the saved file path\n        return output_path\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#key-methods","title":"Key Methods","text":"<p>The <code>AbstractBaseWriter</code> provides several utility methods that simplify file writing and context management. These methods are designed to be flexible and reusable, allowing you to focus on your custom implementation.</p>"},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.resolve_path","title":"resolve_path","text":"<pre><code>resolve_path(**kwargs: object) -&gt; pathlib.Path\n</code></pre> <p>Generate a file path based on the filename format, subject ID, and additional parameters.</p> <p>Meant to be used by developers when creating a new writer class and used internally by the <code>save</code> method.</p> <p>What It Does:</p> <ul> <li>Dynamically generates a file path based on the provided context and filename format.</li> </ul> <p>When to Use It:</p> <ul> <li>This method is meant to be used in the <code>save</code> method to determine the file\u2019s target location, but can also be used by external code to generate paths.</li> <li>It ensures you\u2019re working with a valid path and can handle file existence scenarios.</li> <li>Only raises <code>FileExistsError</code> if the file already exists and the mode is set to <code>FAIL</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>typing.Any</code> <p>Parameters for resolving the filename and validating existence.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>resolved_path</code> <code>pathlib.Path</code> <p>The resolved path for the file.</p> Source code in <code>src/imgtools/io/writers/abstract_base_writer.py</code> <pre><code>def resolve_path(self, **kwargs: object) -&gt; Path:\n    \"\"\"\n    Generate a file path based on the filename format, subject ID, and\n    additional parameters.\n\n    Meant to be used by developers when creating a new writer class\n    and used internally by the `save` method.\n\n    **What It Does**:\n\n    - Dynamically generates a file path based on the provided context and\n    filename format.\n\n    **When to Use It**:\n\n    - This method is meant to be used in the `save` method to determine the\n    file\u2019s target location, but can also be used by external code to\n    generate paths.\n    - It ensures you\u2019re working with a valid path and can handle file\n    existence scenarios.\n    - Only raises `FileExistsError` if the file already exists and the mode\n    is set to `FAIL`.\n\n    Parameters\n    ----------\n    **kwargs : Any\n        Parameters for resolving the filename and validating existence.\n\n    Returns\n    -------\n    resolved_path: Path\n        The resolved path for the file.\n\n    Raises\n    ------\n    FileExistsError\n        If the file already exists and the mode is set to FAIL.\n    \"\"\"\n    out_path = self._generate_path(**kwargs)\n    if not out_path.exists():\n        if self.create_dirs:\n            self._ensure_directory_exists(out_path.parent)\n        # should we raise this error here?\n        # elif not out_path.parent.exists():\n        #     msg = f\"Directory {out_path.parent} does not exist.\"\n        #     raise DirectoryNotFoundError(msg)\n        return out_path\n    match self.existing_file_mode:\n        case ExistingFileMode.SKIP:\n            return out_path\n        case ExistingFileMode.FAIL:\n            msg = f\"File {out_path} already exists.\"\n            raise FileExistsError(msg)\n        case ExistingFileMode.OVERWRITE:\n            logger.debug(f\"Deleting existing {out_path} and overwriting.\")\n            out_path.unlink()\n            return out_path\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.resolve_path(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.preview_path","title":"preview_path","text":"<pre><code>preview_path(\n    **kwargs: object,\n) -&gt; typing.Optional[pathlib.Path]\n</code></pre> <p>Pre-checking file existence and setting up the writer context.</p> <p>Meant to be used by users to skip expensive computations if a file already exists and you dont want to overwrite it. Only difference between this and resolve_path is that this method does not return the path if the file exists and the mode is set to <code>SKIP</code>.</p> <p>This is because the <code>.save()</code> method should be able to return the path even if the file exists.</p> <p>What It Does:</p> <ul> <li>Pre-checks the file path based on context without writing the file.</li> <li>Returns <code>None</code> if the file exists and the mode is set to <code>SKIP</code>.</li> <li>Raises a <code>FileExistsError</code> if the mode is set to <code>FAIL</code>.</li> <li>An added benefit of using <code>preview_path</code> is that it automatically caches the context variables for future use, and <code>save()</code> can be called without passing in the context variables again.</li> </ul> <p>Examples:</p> <p>Main idea here is to allow users to save computation if they choose to skip existing files.</p> <p>i.e. if file exists and mode is <code>SKIP</code>, we return <code>None</code>, so the user can skip the computation.</p> <pre><code>&gt;&gt;&gt; if nifti_writer.preview_path(subject=\"math\", name=\"test\") is None:\n&gt;&gt;&gt;     logger.info(\"File already exists. Skipping computation.\")\n&gt;&gt;&gt;     continue # could be `break` or `return` depending on the use case\n</code></pre> <p>if the mode is <code>FAIL</code>, we raise an error if the file exists, so user doesnt have to perform expensive computation only to fail when saving.</p> Useful Feature <p>The context is saved in the instance, so running <code>.save()</code> after this will use the same context, and user can optionally update the context with new values passed to <code>.save()</code>.</p> <p><pre><code>&gt;&gt;&gt; if path := writer.preview_path(subject=\"math\", name=\"test\"):\n&gt;&gt;&gt;     ... # do some expensive computation to generate the data\n&gt;&gt;&gt;     writer.save(data)\n</code></pre> <code>.save()</code> automatically uses the context for <code>subject</code> and <code>name</code> we passed to <code>preview_path</code></p> <p>Parameters:</p> Name Type Description Default <code>typing.Any</code> <p>Parameters for resolving the filename and validating existence.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pathlib.Path | None</code> <p>If the file exists and the mode is <code>SKIP</code>, returns <code>None</code>. if the file exists and the mode is FAIL, raises a <code>FileExistsError</code>. If the file exists and the mode is OVERWRITE, logs a debug message and returns the path.</p> Source code in <code>src/imgtools/io/writers/abstract_base_writer.py</code> <pre><code>def preview_path(self, **kwargs: object) -&gt; Optional[Path]:\n    \"\"\"\n    Pre-checking file existence and setting up the writer context.\n\n    Meant to be used by users to skip expensive computations if a file\n    already exists and you dont want to overwrite it.\n    Only difference between this and resolve_path is that this method\n    does not return the path if the file exists and the mode is set to\n    `SKIP`.\n\n    This is because the `.save()` method should be able to return\n    the path even if the file exists.\n\n    **What It Does**:\n\n    - Pre-checks the file path based on context without writing the file.\n    - Returns `None` if the file exists and the mode is set to `SKIP`.\n    - Raises a `FileExistsError` if the mode is set to `FAIL`.\n    - An added benefit of using `preview_path` is that it automatically\n    caches the context variables for future use, and `save()` can be called\n    without passing in the context variables again.\n\n    Examples\n    --------\n\n    Main idea here is to allow users to save computation if they choose to\n    skip existing files.\n\n    i.e. if file exists and mode is **`SKIP`**, we return\n    `None`, so the user can skip the computation.\n    &gt;&gt;&gt; if nifti_writer.preview_path(subject=\"math\", name=\"test\") is None:\n    &gt;&gt;&gt;     logger.info(\"File already exists. Skipping computation.\")\n    &gt;&gt;&gt;     continue # could be `break` or `return` depending on the use case\n\n    if the mode is **`FAIL`**, we raise an error if the file exists, so user\n    doesnt have to perform expensive computation only to fail when saving.\n\n    **Useful Feature**\n    ----------------------\n    The context is saved in the instance, so running\n    `.save()` after this will use the same context, and user can optionally\n    update the context with new values passed to `.save()`.\n\n    ```python\n    &gt;&gt;&gt; if path := writer.preview_path(subject=\"math\", name=\"test\"):\n    &gt;&gt;&gt;     ... # do some expensive computation to generate the data\n    &gt;&gt;&gt;     writer.save(data)\n    ```\n    `.save()` automatically uses the context for `subject` and `name` we\n    passed to `preview_path`\n\n    Parameters\n    ----------\n    **kwargs : Any\n        Parameters for resolving the filename and validating existence.\n\n    Returns\n    ------\n    Path | None\n        If the file exists and the mode is `SKIP`, returns `None`. if the file\n        exists and the mode is FAIL, raises a `FileExistsError`. If the file\n        exists and the mode is OVERWRITE, logs a debug message and returns\n        the path.\n\n    Raises\n    ------\n    FileExistsError\n        If the file exists and the mode is FAIL.\n    \"\"\"\n    out_path = self._generate_path(**kwargs)\n\n    if not out_path.exists():\n        return out_path\n    elif out_path.is_dir():\n        msg = f\"Path {out_path} is already a directory that exists.\"\n        msg += \" Use a different filename format or context to avoid this.\"\n        raise IsADirectoryError(msg)\n\n    match self.existing_file_mode:\n        case ExistingFileMode.SKIP:\n            return None\n        case ExistingFileMode.FAIL:\n            msg = f\"File {out_path} already exists.\"\n            raise FileExistsError(msg)\n        case ExistingFileMode.OVERWRITE:\n            logger.debug(\n                f\"File {out_path} exists. Deleting and overwriting.\"\n            )\n            out_path.unlink()\n\n    return out_path\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.preview_path(**kwargs)","title":"<code>**kwargs</code>","text":""},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter.clear_context","title":"clear_context","text":"<pre><code>clear_context() -&gt; None\n</code></pre> <p>Clear the context for the writer.</p> <p>Useful for resetting the context after using <code>preview_path</code> or <code>save</code> and want to make sure that the context is empty for new operations.</p> Source code in <code>src/imgtools/io/writers/abstract_base_writer.py</code> <pre><code>def clear_context(self) -&gt; None:\n    \"\"\"\n    Clear the context for the writer.\n\n    Useful for resetting the context after using `preview_path` or `save`\n    and want to make sure that the context is empty for new operations.\n    \"\"\"\n    self.context.clear()\n</code></pre>"},{"location":"usage/Writers/ImplementingWriters/#add_to_index","title":"add_to_index","text":"<p>What It Does:</p> <ul> <li>Records file information in a centralized CSV index file using the powerful IndexWriter</li> <li>Safely handles concurrent writes with inter-process locking</li> <li>Supports schema evolution to handle changing metadata fields</li> </ul> <p>When to Use It:</p> <ul> <li>Call this method from your <code>save()</code> implementation to track files</li> <li>Great for batch operations where you need to maintain records of processed files</li> </ul> <p>Usage Example:</p> <pre><code>def save(self, content, **kwargs):\n    path = self.resolve_path(**kwargs)\n    # ... write content to file ...\n\n    # Add entry to index with all context variables\n    self.add_to_index(\n        path=path,\n        include_all_context=True,  # Include ALL context vars (not just those in filename)\n        filepath_column=\"path\",    # Column name for file paths\n        replace_existing=False     # Whether to replace existing entries\n    )\n\n    return path\n</code></pre> <p>Important Parameters:</p> <ul> <li><code>include_all_context</code>: Controls whether to save all context variables or only those used in the filename</li> <li><code>filepath_column</code>: Customizes the column name for file paths</li> <li><code>replace_existing</code>: Whether to replace or append entries for the same file</li> </ul> <p>Error Handling:</p> <p>The method uses robust error handling with specific exceptions like <code>WriterIndexError</code> that wrap any underlying IndexWriter errors, making troubleshooting easier.</p> <p>What It Does:</p> <ul> <li>A helper method for resolving file paths based on the current context and   filename format.  </li> <li>Automatically sanitizes filenames if <code>sanitize_filenames=True</code>.</li> </ul> <p>When to Use It:</p> <ul> <li>Typically called internally by <code>resolve_path()</code> and <code>preview_path()</code>, which handle   additional validation and error handling.</li> <li>Can be called by your class methods to generate paths without the additional   context checks.</li> </ul> <p>Example:</p> <pre><code>custom_path = writer._generate_path(subject=\"math\", name=\"example\")\nprint(f\"Generated path: {custom_path}\")\n</code></pre> <p>By using these key methods effectively, you can customize your writer to handle a wide range of file-writing scenarios while maintaining clean and consistent logic.</p>"},{"location":"usage/Writers/ImplementingWriters/#imgtools.io.writers.AbstractBaseWriter._generate_path","title":"_generate_path","text":"<pre><code>_generate_path(**kwargs: object) -&gt; pathlib.Path\n</code></pre> <p>Helper for resolving paths with the given context.</p> Source code in <code>src/imgtools/io/writers/abstract_base_writer.py</code> <pre><code>def _generate_path(self, **kwargs: object) -&gt; Path:\n    \"\"\"\n    Helper for resolving paths with the given context.\n    \"\"\"\n    save_context = {\n        **self.context,\n        **kwargs,\n        \"saved_time\": datetime.now(timezone.utc).strftime(\n            \"%Y-%m-%d:%H-%M-%S\"\n        ),\n    }\n    self.set_context(**save_context)\n    try:\n        filename = self.pattern_resolver.resolve(save_context)\n    except MissingPlaceholderValueError as e:\n        # Replace the class name in the error message dynamically\n        raise MissingPlaceholderValueError(\n            e.missing_keys,\n            class_name=self.__class__.__name__,\n            key=e.key,\n        ) from e\n    if self.sanitize_filenames:\n        filename = self._sanitize_filename(filename)\n    out_path = self.root_directory / filename\n    # logger.debug(\n    #     f\"Resolved path: {out_path} and {out_path.exists()=}\",\n    #     handling=self.existing_file_mode,\n    # )\n    return out_path\n</code></pre>"}]}